{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=gpu2,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "%env THEANO_FLAGS=device=gpu2,floatX=float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 2: Tesla K80 (CNMeM is enabled with initial size: 19.0% of memory, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!mkdir sasha_rnn \n",
    "# !wget https://www.dropbox.com/s/fxbjs8gebdm7lkv/sp.json?dl=0 -O sp.json\n",
    "# !wget https://www.dropbox.com/s/ongjlpx798h8ysq/tinytitles.txt?dl=0 -O tinytitles.txt\n",
    "# !wget https://www.dropbox.com/s/fqhq3v7h1d67e4e/tokens.txt?dl=0 -O tokens.txt\n",
    "# !wget https://www.dropbox.com/s/l72wr3fqk3wio44/weights_persona.pcl?dl=0 -O weights_persona.pcl\n",
    "# !wget https://www.dropbox.com/s/pfg0lx5c17r68tw/weights.pcl?dl=0 -O weights.pkl\n",
    "# !wget https://www.dropbox.com/s/6igoxt5cji02m5e/names_new.txt?dl=0 -O names_new.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NAMES_FILENAME = \"names_new.txt\"\n",
    "TOKENS_FILENAME = \"tokens.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(NAMES_FILENAME) as fin:\n",
    "    names = list(filter(len, fin.read().split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dr._oz',\n",
       " 'human_wendy',\n",
       " 'whoopi',\n",
       " 'kkk_leader',\n",
       " 'an_official',\n",
       " 'woodsy_owl',\n",
       " 'captain',\n",
       " 'ozzy',\n",
       " 'geraldo',\n",
       " 'male_anchor']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(TOKENS_FILENAME) as fin:\n",
    "    tokens = list(filter(len, fin.read().split('\\n')))\n",
    " \n",
    "tokens = tokens[:33646] + [name.strip('_').lower() for name in tokens[33646:]]\n",
    "\n",
    "tokens.append(\"_BOS_\") #beginning of sentence. Omitted in danet\n",
    "tokens.append(\"_PAD_\") #padding. Omitted in danet\n",
    "\n",
    "#tokens += names\n",
    "\n",
    "UNK_ix, BOS_ix, EOS_ix, PAD_ix = list(map(tokens.index, [\"_UNK_\",\"_BOS_\",\"_EOS_\",\"_PAD_\"]))\n",
    "n_tokens = len(tokens)\n",
    "\n",
    "from collections import defaultdict\n",
    "token_to_ix = defaultdict(lambda : UNK_ix, {t:i for i, t in enumerate(tokens)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_to_ix = defaultdict(lambda : UNK_ix, {t:i for i, t in enumerate(names)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import regex\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(lines, max_len=20, speaker=None, add_eos=True):\n",
    "    if type(lines) == (str):\n",
    "        lines = [lines]\n",
    "    \n",
    "    context=[]\n",
    "    for line in lines:\n",
    "        line = line.lower()\n",
    "        line = regex.sub(r'(\\p{P}|`|~)', r' \\1 ', line)\n",
    "        line_ix = list(map(token_to_ix.__getitem__, filter(len, line.split())))\n",
    "        if add_eos:\n",
    "            line_ix.append(EOS_ix)\n",
    "        context += line_ix\n",
    "            \n",
    "    if speaker is not None:\n",
    "        context.append(speaker)\n",
    "        \n",
    "    return context\n",
    "\n",
    "def ix_to_matrix(phrases_ix, max_len=None):\n",
    "    max_len = max_len or max(map(len,phrases_ix))\n",
    "    \n",
    "    matrix = np.zeros((len(phrases_ix),max_len),dtype='int32') + PAD_ix\n",
    "    \n",
    "    for i,phrase_ix in enumerate(phrases_ix):\n",
    "        matrix[i,:min(len(phrase_ix),max_len)] = phrase_ix[:max_len]\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "def phrase_to_matrix(contexts, max_len=None, **kwargs):\n",
    "            \n",
    "    return ix_to_matrix([preprocess(phrases,**kwargs) for phrases in contexts], max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36071"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13885, 34723,    14,    14,    14,     0]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_to_matrix([\"Hello dude!!!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(data_rows, batch_size=32, speakers_list=None, context_length=3, max_len=20, n_iter=np.inf):\n",
    "    i=0\n",
    "\n",
    "    while True:\n",
    "        batch_ix = np.random.randint(0, len(data_rows) - context_length - 1, batch_size)\n",
    "        context_ix = batch_ix[:, None] + np.arange(context_length)[None, :]\n",
    "        answer_ix = batch_ix + context_length\n",
    "        batch_x = ix_to_matrix(list(map(np.concatenate, data_rows[context_ix])), max_len=max_len)\n",
    "        batch_y = ix_to_matrix(data_rows[answer_ix], max_len=max_len)\n",
    "        if speakers_list == None:\n",
    "            yield batch_x, batch_y\n",
    "        else:\n",
    "            respondent = speakers_list[answer_ix]\n",
    "            yield batch_x, batch_y, respondent\n",
    "        i+=1\n",
    "        if i >= n_iter:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('sp.json', 'r') as fn:    \n",
    "    data = json.load(fn, encoding='cp1251')\n",
    "    \n",
    "    \n",
    "import re\n",
    "numbers_regex = re.compile('#?[0-9]+')\n",
    "\n",
    "def preprocess_speaker_name(name):\n",
    "    try:\n",
    "        str(name)\n",
    "    except:\n",
    "        return ''\n",
    "    name_parts = map(str.lower, str(name).split())\n",
    "    filtered = filter(lambda part: not re.match(numbers_regex, part), name_parts)\n",
    "    return '_'.join(filtered)\n",
    "\n",
    "data_rows = np.array([preprocess(lines=[phrase[1]])\n",
    "                      for part in data for phrase in part['conversation'] if phrase[0] and phrase[1] \n",
    "                      and len(phrase[0]) > 2])\n",
    "\n",
    "speakers_list = np.array([name_to_ix[preprocess_speaker_name(phrase[0][:-2])]\n",
    "                      for part in data for phrase in part['conversation'] if phrase[0] and phrase[1] \n",
    "                          and len(phrase[0]) > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "import numpy as np\n",
    "import theano\n",
    "theano.config.floatX='float32'\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theano.config.exception_verbosity='high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grad_clipping = 5\n",
    "lstm_units = 1024\n",
    "emb_size = 512\n",
    "bottleneck_units = 256\n",
    "person_emb_size = 100\n",
    "seq_len = 20\n",
    "sampling_num = 5\n",
    "n_persons = len(names)\n",
    "temperature = theano.shared(np.float32(1.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sasha_rnn.wrong_lstm_layer import WrongLSTMLayer\n",
    "from lasagne.layers import *\n",
    "\n",
    "class encoder:\n",
    "        \n",
    "    input_phrase = T.imatrix(\"encoder phrase tokens\")\n",
    "    \n",
    "    l_in = InputLayer((None,None), input_phrase, name='context input')\n",
    "    l_mask = InputLayer((None,None), T.neq(input_phrase, PAD_ix), 'context mask')\n",
    "    \n",
    "    l_emb = EmbeddingLayer(l_in, n_tokens, emb_size, name=\"context embedding\")\n",
    "    \n",
    "    \n",
    "    ####LSTMLayer with incorrect outputgate####\n",
    "    \n",
    "    l_lstm = WrongLSTMLayer(\n",
    "                        l_emb,\n",
    "                        lstm_units,\n",
    "                        name='encoder_lstm',\n",
    "                        grad_clipping=grad_clipping,\n",
    "                        mask_input=l_mask,\n",
    "                        only_return_final=True,\n",
    "                        peepholes=False)\n",
    "    \n",
    "    output = l_lstm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_persons = len(names)\n",
    "person_id_var = T.ivector(\"personality idxs\")\n",
    "l_person_id = InputLayer((None,), person_id_var)\n",
    "l_person_emb = EmbeddingLayer(l_person_id, n_persons, person_emb_size, name=\"persona_based.emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LATENT_SIZE = n_persons\n",
    "latent_c = T.imatrix(\"latent variable for InfoGAN\")\n",
    "#l_latent = InputLayer((None, LATENT_SIZE), input_var=latent_c)\n",
    "\n",
    "def sample_c(respondents):\n",
    "    return np.eye(LATENT_SIZE)[respondents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sasha_rnn.wrong_lstm_cell import WrongLSTMCell\n",
    "from agentnet import Recurrence\n",
    "from agentnet.resolver import  ProbabilisticResolver\n",
    "\n",
    "class decoder:\n",
    "    prev_cell = InputLayer((None,lstm_units), name='cell')\n",
    "    prev_out = InputLayer((None,lstm_units), name='out')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #input\n",
    "    inp_word = InputLayer((None,))\n",
    "    word_embedding = EmbeddingLayer(inp_word, n_tokens, emb_size,\n",
    "                                         W=encoder.l_emb.W, name='emb')\n",
    "    encoder_lstm = InputLayer((None, lstm_units), name='encoder')\n",
    "    person_emb = InputLayer((None, person_emb_size), name='persona_based.each_tick')\n",
    "\n",
    "    #recurrent units\n",
    "    new_cell,new_out = WrongLSTMCell(prev_cell, prev_out,\n",
    "                                     input_or_inputs=[word_embedding, encoder_lstm, person_emb],#, inp_c],\n",
    "                                     name='decoder_lstm', peepholes=False\n",
    "                                    )\n",
    "    \n",
    "\n",
    "    bottleneck = DenseLayer(new_out, bottleneck_units,\n",
    "                              nonlinearity=T.tanh,\n",
    "                              name='decoder intermediate')\n",
    "\n",
    "    \n",
    "    next_word_probs = DenseLayer(bottleneck, n_tokens,\n",
    "                                 nonlinearity=lambda probs: T.nnet.softmax(probs/temperature),\n",
    "                                 name='decoder next word probas')\n",
    "\n",
    "    next_words = ProbabilisticResolver(next_word_probs, assume_normalized=True)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mask_from_end_indicator(end_indicator):\n",
    "    return T.concatenate([T.ones_like(end_indicator[:,:1]),\n",
    "                          T.eq(T.cumsum(end_indicator,axis=1), 0)[:,:-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class generator:\n",
    "    \n",
    "    n_steps = T.iscalar()\n",
    "    \n",
    "    bos_input_layer = InputLayer((None,),T.zeros((encoder.input_phrase.shape[0],), 'int32')+BOS_ix, name=\"first input\")\n",
    "\n",
    "    recurrence = Recurrence(\n",
    "                           input_nonsequences={decoder.encoder_lstm: encoder.output,\n",
    "                                               decoder.person_emb: l_person_emb},\n",
    "                                               #decoder.inp_c: l_latent},\n",
    "                           state_variables={decoder.new_cell: decoder.prev_cell,\n",
    "                                            decoder.new_out: decoder.prev_out,\n",
    "                                            decoder.next_words: decoder.inp_word},\n",
    "                           tracked_outputs=[decoder.next_words, decoder.next_word_probs, decoder.new_cell, \n",
    "                                            decoder.new_out],\n",
    "                           state_init={decoder.next_words: bos_input_layer},\n",
    "                           n_steps=n_steps,\n",
    "                           unroll_scan=False,)\n",
    "    \n",
    "    weights = get_all_params(recurrence, trainable=True)    \n",
    "    \n",
    "    rec_output = get_output(recurrence)\n",
    "\n",
    "    out, probs, cell_seq, out_seq=rec_output[decoder.next_words],T.maximum(rec_output[decoder.next_word_probs],1e-10),\\\n",
    "                                               rec_output[decoder.new_cell], rec_output[decoder.new_out]\n",
    "    \n",
    "    mask = get_mask_from_end_indicator(T.eq(out, EOS_ix))\n",
    "    auto_updates = recurrence.get_automatic_updates()\n",
    "    \n",
    "    generate = theano.function([encoder.input_phrase, person_id_var, n_steps], out,\n",
    "                                updates=auto_updates, allow_input_downcast=True)\n",
    "    \n",
    "    #Greedy mode\n",
    "    greedy_out = get_output(recurrence[decoder.next_words], recurrence_flags={\"greedy\": True})\n",
    "    \n",
    "    greedy_auto_updates = recurrence.get_automatic_updates()\n",
    "    greedy_mask = get_mask_from_end_indicator(T.eq(greedy_out, EOS_ix))\n",
    "    \n",
    "    generate_greedy = theano.function([encoder.input_phrase, person_id_var, n_steps], greedy_out,\n",
    "                                       updates=greedy_auto_updates, allow_input_downcast=True)\n",
    "    \n",
    "    # Perplexity \n",
    "    from agentnet.learning.generic import get_values_for_actions\n",
    "    choosen_probs = get_values_for_actions(probs, out)\n",
    "    perplexity = T.mean(T.power(2, -T.sum(T.log(choosen_probs), axis=-1) / n_steps))\n",
    "    \n",
    "    get_perplexity_fn = theano.function([encoder.input_phrase, person_id_var, n_steps], perplexity,\n",
    "                                updates=auto_updates, allow_input_downcast=True)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def reply(phrase, person_id, max_len=20, **kwargs):\n",
    "        phrase_ix = phrase_to_matrix([phrase], **kwargs)\n",
    "\n",
    "#         latent = sample_c([person_id])\n",
    "        answer_ix = generator.generate(phrase_ix, [person_id], max_len)[0]\n",
    "        if EOS_ix in answer_ix:\n",
    "            answer_ix = answer_ix[:list(answer_ix).index(EOS_ix)]\n",
    "        return ' '.join(map(tokens.__getitem__, answer_ix))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "one_batch = generate_data(data_rows, speakers_list=speakers_list, n_iter=1, max_len=seq_len).next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def phrase_from_idx(idxs, crop_by_eos=False):\n",
    "    if crop_by_eos and EOS_ix in idxs:\n",
    "        idxs = idxs[:list(idxs).index(EOS_ix)]\n",
    "        \n",
    "    phrase_tokens = map(tokens.__getitem__, idxs)\n",
    "    return phrase_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_batch =  phrase_to_matrix([[\"Hello\", \"Hello\", \"What is your name ? \"]], max_len=20)\n",
    "\n",
    "conversation_names = set(names) & set(tokens)\n",
    "\n",
    "conversation_name_idxs = map(name_to_ix.get, conversation_names)\n",
    "conversation_token_idxs = map(token_to_ix.get, conversation_names)\n",
    "\n",
    "name_batch_repeated = np.repeat(name_batch, len(conversation_names), axis=0)\n",
    "\n",
    "latent_for_name_batch = sample_c(conversation_name_idxs)\n",
    "\n",
    "\n",
    "def accuracy_in_names():\n",
    "    #model_answers = generator.generate(name_batch_repeated, conversation_name_idxs, 20, latent_for_name_batch)\n",
    "    model_answers = [generator.generate(name_batch, [name_idx], 20) \n",
    "                                        for name_idx in conversation_name_idxs]\n",
    "    def crop_by_eos(answer):\n",
    "        if  EOS_ix in answer:\n",
    "            return answer[:list(answer).index(EOS_ix)]\n",
    "        return answer\n",
    "        \n",
    "    res = map(lambda answer, name_idx: name_idx in set(crop_by_eos(answer[0])), model_answers, conversation_token_idxs)   \n",
    "    matched_idxs = np.where(res)[0]\n",
    "    name_idxs = [conversation_name_idxs[idx] for idx in matched_idxs]\n",
    "    matched_names = [names[idx] for idx in name_idxs]\n",
    "    \n",
    "    matched_answers = [' '.join(phrase_from_idx(model_answers[idx][0], crop_by_eos=True)) for idx in matched_idxs] \n",
    "    return matched_names, matched_answers\n",
    "    return sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"weights_persona.pcl\", 'rb') as f:\n",
    "#     d = pickle.load(f)\n",
    "    \n",
    "# d[0] = (np.random.normal(size=n_persons * person_emb_size).reshape((n_persons, person_emb_size)) * 1e-10).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"generator_ent_weights.pkl\", 'rb') as f:\n",
    "    d1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_params = get_all_params(generator.recurrence)\n",
    "for i in range(1, 16):\n",
    "    gen_params[i].set_value(d1[i - 1])\n",
    "gen_params[0].set_value(d1[15])\n",
    "i = 16\n",
    "for param in gen_params[16:]:\n",
    "    if param.get_value().shape == d1[i].shape:\n",
    "        param.set_value(d1[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is harry and i ' m the president ' s old pal , but i ' m sure\n",
      "my name is dan snyder . i ' m a very special little boy .\n",
      "my name is dr . biber .\n",
      "my name is dr . biber .\n",
      "my name is dr . biber .\n"
     ]
    }
   ],
   "source": [
    "temperature.set_value(np.float32(0.5))\n",
    "for i in range(5):\n",
    "    print(generator.reply([\"Hello!\", \"Hello\", \"What is your name ?\"], 2484))\n",
    "    \n",
    "temperature.set_value(np.float32(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb_weights = d1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36071, 512)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from custom_layers import SrcTrgToMatrixLayer\n",
    "from lasagne.nonlinearities import *\n",
    "\n",
    "class conv_discriminator:\n",
    "#     questions_var = T.imatrix(name='questions var')\n",
    "    reference_answers_var = T.imatrix(name='reference answers var')\n",
    "\n",
    "    question = InputLayer((None, 20), name='question')\n",
    "    answer = InputLayer((None, 20), name='answer')\n",
    "\n",
    "    question_emb = EmbeddingLayer(question, emb_weights.shape[0], emb_weights.shape[1], W=emb_weights)\n",
    "    answer_emb = EmbeddingLayer(answer, emb_weights.shape[0], emb_weights.shape[1], W=emb_weights)\n",
    "\n",
    "    cnn_input = SrcTrgToMatrixLayer(question_emb, answer_emb)\n",
    "\n",
    "    nn = Conv2DLayer(cnn_input, 20, (3, 3), nonlinearity=None)\n",
    "    nn = Pool2DLayer(nn, (2, 2))\n",
    "    nn = Conv2DLayer(nn, 20, (3, 3), nonlinearity=None)\n",
    "    nn = Pool2DLayer(nn, (2, 2))\n",
    "    \n",
    "    dense = DenseLayer(nn, 20, nonlinearity=None)\n",
    "    l_prob = DenseLayer(dense, 2, nonlinearity=softmax)\n",
    "    \n",
    "    #dense_q = DenseLayer(nn, LATENT_SIZE * 2, nonlinearity=None)\n",
    "    #dense_q = ReshapeLayer(dense_q, (LATENT_SIZE, 2), nonlinearity=softmax)\n",
    "    l_Q = DenseLayer(nn, LATENT_SIZE, nonlinearity=softmax)\n",
    "\n",
    "    \n",
    "    output_on_fake, q_out = get_output([l_prob, l_Q], {question: encoder.input_phrase, answer: generator.out})\n",
    "    #q_probs = q_out[:, :, 1]\n",
    "    q_entropy = (latent_c * T.log(q_out)).sum(axis=-1).mean()\n",
    "\n",
    "    info_approximation = q_entropy                              \n",
    "    output_on_greedy_fake = get_output(l_prob, {question: encoder.input_phrase, answer: generator.greedy_out})\n",
    "    output_on_real = get_output(l_prob, {question: encoder.input_phrase, answer: reference_answers_var})\n",
    "    \n",
    "    loss = -T.log(output_on_fake[:, 0]).sum() - T.log(output_on_real[:, 1]).sum() - 0.001 * info_approximation\n",
    "\n",
    "    weights = get_all_params(l_prob, trainable=True) + get_all_params(l_Q, trainable=True)\n",
    "    weights.remove(question_emb.W)\n",
    "    weights.remove(answer_emb.W)\n",
    "\n",
    "    updates = generator.auto_updates + lasagne.updates.adam(loss, weights, learning_rate=0.0001) \n",
    "    \n",
    "    train_step = theano.function([encoder.input_phrase, reference_answers_var, person_id_var, generator.n_steps, latent_c], \n",
    "                                 [loss, info_approximation], \n",
    "                                 updates=updates,\n",
    "                                allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_discr_out_on_fake = theano.function([encoder.input_phrase, person_id_var, generator.n_steps],\n",
    "                                        conv_discriminator.output_on_fake[:, 1], updates=generator.auto_updates,\n",
    "                                        allow_input_downcast=True)\n",
    "\n",
    "get_discr_out_on_real = theano.function([encoder.input_phrase, conv_discriminator.reference_answers_var], \n",
    "                                        conv_discriminator.output_on_real[:, 1],\n",
    "                                        allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.utils.persistence import save, load\n",
    "save(conv_discriminator.l_prob, 'conv_infoent_discr_l_prob.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save(conv_discriminator.l_Q, 'conv_infoent_discr_l_Q.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_discr_fn = theano.function([encoder.input_phrase, person_id_var, generator.n_steps], \n",
    "                                [generator.out, conv_discriminator.output_on_fake], updates=generator.auto_updates,\n",
    "                               allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class trainer:\n",
    "    reference_answers = T.imatrix(\"decoder reference answers\")\n",
    "    \n",
    "    bos_column = T.zeros((reference_answers.shape[0], 1), 'int32') + BOS_ix\n",
    "    reference_answers_bos = T.concatenate((bos_column, reference_answers), axis=1)  #prepend BOS\n",
    "        \n",
    "    l_ref = InputLayer((None, None), reference_answers_bos, name='context input')\n",
    "    l_ref_mask = InputLayer((None,None), T.neq(reference_answers_bos, PAD_ix), 'context mask')\n",
    "\n",
    "    recurrence = Recurrence(input_sequences={decoder.inp_word:l_ref},\n",
    "                           input_nonsequences={decoder.encoder_lstm:encoder.output,\n",
    "                                               decoder.person_emb:l_person_emb},\n",
    "                           state_variables={decoder.new_cell:decoder.prev_cell,\n",
    "                                            decoder.new_out:decoder.prev_out,},\n",
    "                           tracked_outputs=[decoder.next_word_probs],\n",
    "                           mask_input=l_ref_mask,\n",
    "                           unroll_scan=False,)\n",
    "    \n",
    "    \n",
    "    P_seq = get_output(recurrence[decoder.next_word_probs])\n",
    "    #V_seq = whateveryouadded\n",
    "    \n",
    "    ############################\n",
    "    ###loglikelihood training###\n",
    "    ############################\n",
    "    predicted_probas = P_seq[:, :-1].reshape((-1, n_tokens)) + 1e-6\n",
    "    target_values = reference_answers.ravel()\n",
    "\n",
    "    llh = lasagne.objectives.categorical_crossentropy(predicted_probas, target_values)\n",
    "    llh_loss = llh.mean()\n",
    "    llh_updates = lasagne.updates.adam(llh_loss, generator.weights, 0.001)\n",
    "\n",
    "    train_llh_step = theano.function([encoder.input_phrase, person_id_var, reference_answers],\n",
    "                                     llh_loss, updates=llh_updates, allow_input_downcast=True)\n",
    "    get_llh = theano.function([encoder.input_phrase, person_id_var, reference_answers], llh_loss,\n",
    "                             allow_input_downcast=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_smoothed(x, n=10):\n",
    "    smoothed_x = [np.mean(x[i-n:i]) for i in range(n, len(x))]\n",
    "    plt.plot(smoothed_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrain_discr_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrain_latent_gen = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infolosses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002415594976401036"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.73 ** -6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.33558 -8.07154\n",
      "48.27124 -8.06815\n",
      "47.90277 -8.05942\n",
      "46.26079 -8.06295\n",
      "45.94870 -8.05252\n",
      "44.54993 -8.03546\n",
      "43.29191 -8.07861\n",
      "43.50407 -8.03985\n",
      "42.57881 -8.01925\n",
      "42.49622 -8.04096\n",
      "40.92238 -8.04824\n",
      "38.74004 -8.04672\n",
      "40.17352 -8.04155\n",
      "37.20708 -8.01773\n",
      "37.72484 -8.04177\n",
      "35.93889 -8.03603\n",
      "36.21176 -8.02493\n",
      "35.76099 -8.02646\n",
      "34.16207 -8.05278\n",
      "32.66802 -8.00296\n",
      "33.62802 -8.00822\n",
      "32.24629 -8.02215\n",
      "34.05779 -8.01364\n",
      "31.77098 -8.03592\n",
      "31.86721 -8.04650\n",
      "24.94081 -8.02475\n",
      "32.85449 -8.02077\n",
      "25.30106 -8.01766\n",
      "28.92288 -7.99068\n",
      "24.86328 -8.00241\n",
      "28.81413 -7.98713\n",
      "28.63487 -7.99489\n",
      "32.33042 -7.94362\n",
      "27.50740 -8.00305\n",
      "28.97284 -7.95000\n",
      "30.56905 -7.99693\n",
      "26.86299 -7.98297\n",
      "27.88584 -8.00121\n",
      "26.63042 -8.01051\n",
      "24.10823 -7.96388\n",
      "28.08673 -7.95902\n",
      "28.53225 -7.99655\n",
      "26.71026 -8.00650\n",
      "29.28932 -8.02359\n",
      "33.88100 -7.95676\n",
      "30.54907 -7.97613\n",
      "31.60169 -7.96014\n",
      "29.34288 -7.95254\n",
      "21.61700 -7.92179\n",
      "25.48066 -7.96908\n",
      "27.05620 -7.95920\n",
      "22.52760 -7.92384\n",
      "31.94356 -7.93392\n",
      "27.69799 -7.92234\n",
      "30.20638 -7.88975\n",
      "24.85527 -7.90882\n",
      "28.03900 -7.89911\n",
      "22.86757 -7.92396\n",
      "25.23524 -7.89617\n",
      "26.99964 -7.90521\n",
      "20.98900 -7.87448\n",
      "25.50068 -7.90775\n",
      "24.87933 -7.81916\n",
      "27.65377 -7.89142\n",
      "32.63140 -7.87295\n",
      "21.14476 -7.87658\n",
      "23.81984 -7.93050\n",
      "25.55281 -7.91541\n",
      "28.34820 -7.82662\n",
      "29.32523 -7.86483\n",
      "24.51752 -7.86038\n",
      "24.19742 -7.86457\n",
      "27.45624 -7.86613\n",
      "27.14224 -7.92108\n",
      "23.31093 -7.85292\n",
      "25.40102 -7.86551\n",
      "21.75078 -7.75839\n",
      "22.20937 -7.94842\n",
      "16.91100 -7.92342\n",
      "23.86492 -7.78681\n",
      "29.17999 -7.82163\n",
      "24.51889 -7.79422\n",
      "30.17919 -7.84564\n",
      "18.81002 -7.75013\n",
      "27.80668 -7.82974\n",
      "27.44977 -7.82491\n",
      "31.98338 -7.78717\n",
      "25.49437 -7.77141\n",
      "26.52612 -7.80877\n",
      "30.29405 -7.80522\n",
      "25.69864 -7.85611\n",
      "32.88470 -7.71067\n",
      "19.34282 -7.67477\n",
      "21.78362 -7.75539\n",
      "27.15432 -7.73732\n",
      "19.06097 -7.78984\n",
      "24.60770 -7.77945\n",
      "25.16479 -7.79051\n",
      "28.58893 -7.78755\n",
      "23.58038 -7.72073\n",
      "20.91527 -7.70935\n",
      "28.40716 -7.76381\n",
      "23.23484 -7.69203\n",
      "20.58082 -7.73341\n",
      "22.96831 -7.71471\n",
      "26.78247 -7.68233\n",
      "26.14906 -7.74389\n",
      "24.84685 -7.67431\n",
      "28.90200 -7.80609\n",
      "24.23349 -7.72031\n",
      "25.25399 -7.69728\n",
      "20.16282 -7.72932\n",
      "21.66006 -7.74347\n",
      "22.93086 -7.65893\n",
      "21.92236 -7.73157\n",
      "25.67070 -7.62594\n",
      "28.46608 -7.73301\n",
      "28.52153 -7.68621\n",
      "14.94121 -7.69662\n",
      "21.17324 -7.61564\n",
      "21.82337 -7.62789\n",
      "21.50471 -7.63346\n",
      "23.22347 -7.59799\n",
      "21.78618 -7.62585\n",
      "19.15036 -7.64733\n",
      "26.84563 -7.64829\n",
      "17.69825 -7.64387\n",
      "17.24138 -7.62073\n",
      "23.80803 -7.61727\n",
      "19.72130 -7.65104\n",
      "15.08135 -7.58264\n",
      "20.25819 -7.65213\n",
      "22.16962 -7.64664\n",
      "21.80752 -7.55205\n",
      "24.93750 -7.62307\n",
      "23.02571 -7.53991\n",
      "20.45975 -7.53885\n",
      "30.84084 -7.52296\n",
      "22.26003 -7.55562\n",
      "26.87349 -7.55907\n",
      "17.15590 -7.43199\n",
      "19.99424 -7.50744\n",
      "18.27721 -7.57910\n",
      "19.16209 -7.61730\n",
      "21.38841 -7.48093\n",
      "20.22859 -7.59573\n",
      "20.45347 -7.62608\n",
      "20.48329 -7.67044\n",
      "21.67002 -7.46336\n",
      "23.74825 -7.57644\n",
      "19.13172 -7.62494\n",
      "22.15489 -7.39449\n",
      "20.93013 -7.38051\n",
      "20.07787 -7.55030\n",
      "20.85361 -7.52954\n",
      "20.40188 -7.51584\n",
      "19.52086 -7.41991\n",
      "14.57641 -7.58945\n",
      "25.39208 -7.57304\n",
      "20.08236 -7.53973\n",
      "19.05793 -7.44601\n",
      "18.07630 -7.30566\n",
      "20.41800 -7.42090\n",
      "19.38641 -7.48372\n",
      "20.63840 -7.30690\n",
      "22.07001 -7.35951\n",
      "14.93567 -7.39177\n",
      "18.63536 -7.38035\n",
      "24.87342 -7.41971\n",
      "27.20328 -7.55333\n",
      "17.34034 -7.48555\n",
      "17.00520 -7.58013\n",
      "17.46145 -7.35692\n",
      "20.89540 -7.44928\n",
      "17.98142 -7.37729\n",
      "19.91921 -7.36156\n",
      "18.20537 -7.33217\n",
      "17.59826 -7.35180\n",
      "25.04553 -7.40274\n",
      "19.50753 -7.52163\n",
      "17.74977 -7.55722\n",
      "22.30207 -7.38041\n",
      "21.81570 -7.42447\n",
      "25.62039 -7.27196\n",
      "21.03259 -7.54497\n",
      "19.44883 -7.37045\n",
      "16.49119 -7.31185\n",
      "26.47741 -7.32827\n",
      "12.27321 -7.32252\n",
      "25.26573 -7.36135\n",
      "22.00291 -7.35118\n",
      "20.09934 -7.41122\n",
      "19.07169 -7.40105\n",
      "21.73857 -7.25425\n",
      "20.70552 -7.19456\n",
      "15.99444 -7.16200\n",
      "18.15100 -7.28574\n",
      "12.64590 -7.38913\n",
      "16.05920 -7.27960\n",
      "24.26524 -7.20520\n",
      "18.81799 -7.32235\n",
      "32.15903 -7.34115\n",
      "20.61334 -7.48611\n",
      "21.76354 -7.23704\n",
      "21.37092 -7.23369\n",
      "22.18620 -7.22537\n",
      "17.78546 -7.10909\n",
      "19.89061 -7.32681\n",
      "24.69669 -7.23665\n",
      "19.18846 -7.25302\n",
      "20.48563 -7.36222\n",
      "24.22639 -7.34420\n",
      "18.56297 -7.40094\n",
      "22.79480 -7.32354\n",
      "17.27943 -7.15413\n",
      "15.85147 -7.14525\n",
      "27.33978 -7.16987\n",
      "22.78214 -7.32905\n",
      "15.75540 -6.92551\n",
      "18.48060 -7.19264\n",
      "17.50146 -7.19166\n",
      "16.01102 -7.43883\n",
      "23.67608 -7.17492\n",
      "21.83199 -7.10570\n",
      "17.59924 -7.20069\n",
      "22.86183 -7.35051\n",
      "23.02835 -7.28019\n",
      "26.61268 -7.31666\n",
      "21.22646 -7.10808\n",
      "17.13894 -7.21322\n",
      "17.24753 -7.17129\n",
      "19.23873 -7.25609\n",
      "15.63072 -7.41079\n",
      "27.77022 -7.18593\n",
      "17.80684 -7.04745\n",
      "17.53617 -7.26346\n",
      "19.73992 -7.22804\n",
      "17.67792 -7.00297\n",
      "25.34816 -7.27829\n",
      "33.18449 -7.12827\n",
      "18.00982 -7.26550\n",
      "22.31893 -7.31867\n",
      "14.46068 -7.25257\n",
      "27.73500 -7.42415\n",
      "17.23683 -7.06705\n",
      "20.19441 -6.92738\n",
      "16.39361 -7.30504\n",
      "21.59415 -7.32904\n",
      "21.59698 -7.07391\n",
      "26.01673 -7.14849\n",
      "18.10620 -7.17966\n",
      "26.59569 -7.29174\n",
      "18.75576 -7.12483\n",
      "20.93642 -7.12460\n",
      "24.84681 -7.04184\n",
      "16.58303 -7.18693\n",
      "25.34974 -7.24611\n",
      "18.70343 -7.09456\n",
      "20.89622 -7.17469\n",
      "22.29369 -6.98521\n",
      "18.47328 -6.95415\n",
      "20.33951 -7.12790\n",
      "13.47497 -7.09820\n",
      "17.05867 -7.08030\n",
      "17.92616 -6.87868\n",
      "21.62954 -7.18931\n",
      "21.03526 -7.08720\n",
      "19.58766 -7.23488\n",
      "15.81627 -7.03624\n",
      "20.24537 -7.28823\n",
      "20.72878 -6.98782\n",
      "21.16394 -6.95274\n",
      "21.26407 -7.41468\n",
      "12.71095 -6.93697\n",
      "16.52068 -7.09880\n",
      "18.16648 -7.31957\n",
      "18.42300 -7.04764\n",
      "20.59490 -6.96863\n",
      "19.46135 -7.06680\n",
      "24.27190 -7.03847\n",
      "22.17612 -7.16243\n",
      "14.22921 -6.92509\n",
      "23.31081 -7.07114\n",
      "19.29214 -7.04655\n",
      "20.72937 -7.20466\n",
      "23.17951 -6.92948\n",
      "13.26465 -6.92463\n",
      "22.00754 -6.82812\n",
      "19.51317 -6.53414\n",
      "15.58799 -7.02843\n",
      "18.69834 -7.04154\n",
      "21.52226 -6.90136\n",
      "20.80907 -7.33783\n",
      "19.32947 -6.69891\n",
      "19.13305 -6.74669\n",
      "20.57770 -7.04043\n",
      "19.27198 -7.10729\n",
      "15.84997 -6.76546\n",
      "16.17461 -6.97189\n",
      "20.38200 -7.04151\n",
      "18.58789 -7.10192\n",
      "17.07312 -6.60258\n",
      "16.30962 -6.97810\n",
      "18.07731 -6.70557\n",
      "13.49547 -7.14528\n",
      "18.88084 -6.94652\n",
      "13.63342 -7.02272\n",
      "22.02580 -7.11655\n",
      "19.28038 -6.77305\n",
      "16.99594 -6.94978\n",
      "28.53767 -7.26520\n",
      "26.44844 -6.94004\n",
      "26.17827 -6.79700\n",
      "14.20499 -6.86229\n",
      "18.32286 -6.54361\n",
      "19.63168 -6.90381\n",
      "23.08948 -6.88061\n",
      "18.53603 -6.81643\n",
      "20.03814 -6.90336\n",
      "27.57651 -7.09102\n",
      "20.94843 -6.99887\n",
      "16.70857 -6.87741\n",
      "25.10877 -6.91371\n",
      "10.52127 -6.98712\n",
      "18.70761 -6.85149\n",
      "12.46610 -6.69558\n",
      "19.22142 -6.76518\n",
      "17.40986 -6.79626\n",
      "17.34677 -6.96572\n",
      "24.44481 -6.98055\n",
      "10.77637 -6.59720\n",
      "14.57397 -6.96900\n",
      "12.98517 -6.92487\n",
      "20.95602 -6.94648\n",
      "15.56920 -6.42903\n",
      "22.60252 -6.94613\n",
      "18.79225 -6.78747\n",
      "17.61051 -6.62225\n",
      "9.80159 -6.56503\n",
      "21.91483 -6.64711\n",
      "15.88044 -6.87634\n",
      "17.78596 -6.87473\n",
      "18.19311 -6.79132\n",
      "13.90326 -7.05665\n",
      "14.82399 -6.90767\n",
      "18.22406 -6.87669\n",
      "17.55111 -6.71116\n",
      "17.00697 -6.74477\n",
      "16.58569 -6.69728\n",
      "16.48117 -6.83291\n",
      "18.56217 -7.03566\n",
      "15.28393 -6.72665\n",
      "17.11539 -7.08244\n",
      "16.21683 -6.91209\n",
      "20.90274 -7.00397\n",
      "16.25594 -6.82433\n",
      "21.51696 -7.06880\n",
      "18.36601 -6.47690\n",
      "13.93425 -7.04940\n",
      "17.68270 -6.74262\n",
      "22.02347 -6.60000\n",
      "15.47631 -6.48473\n",
      "11.98863 -6.73027\n",
      "17.76536 -7.12856\n",
      "23.86245 -6.85250\n",
      "22.40717 -6.86803\n",
      "15.15073 -6.96921\n",
      "16.69776 -7.01696\n",
      "18.24981 -7.04535\n",
      "19.30526 -7.13313\n",
      "17.82702 -6.87970\n",
      "16.80397 -6.34985\n",
      "17.78198 -6.85110\n",
      "21.86831 -6.67416\n",
      "19.67817 -6.68803\n",
      "27.32925 -6.79461\n",
      "18.64457 -6.86427\n",
      "18.16831 -6.67638\n",
      "18.97190 -6.55281\n",
      "21.29638 -6.54009\n",
      "18.78562 -6.68785\n",
      "12.42810 -6.56924\n",
      "20.22531 -6.87957\n",
      "21.86048 -7.12479\n",
      "11.35223 -6.45666\n",
      "19.66761 -6.79467\n",
      "14.29377 -6.56648\n",
      "14.87029 -6.75258\n",
      "13.29271 -6.67031\n",
      "21.98450 -6.83533\n",
      "15.91252 -6.55372\n",
      "18.93476 -6.27137\n",
      "17.85406 -6.75583\n",
      "15.79090 -6.82501\n",
      "9.51385 -6.24218\n",
      "21.68529 -6.66191\n",
      "16.55837 -6.33482\n",
      "22.42697 -6.86368\n",
      "20.64921 -6.62264\n",
      "16.22409 -6.41907\n",
      "10.71173 -6.66615\n",
      "15.80824 -6.76965\n",
      "13.33967 -6.61152\n",
      "18.01363 -6.93294\n",
      "15.54880 -6.65527\n",
      "13.13324 -6.08831\n",
      "18.00688 -6.54142\n",
      "17.91575 -6.23382\n",
      "15.20216 -6.64043\n",
      "18.82949 -6.21547\n",
      "21.20751 -6.42854\n",
      "17.70903 -6.80758\n",
      "15.36371 -6.45517\n",
      "16.32839 -6.44321\n",
      "13.97928 -6.57632\n",
      "11.48699 -6.24286\n",
      "19.45609 -6.67558\n",
      "14.69972 -6.76890\n",
      "19.11704 -6.34793\n",
      "19.03782 -6.63382\n",
      "19.61737 -6.54458\n",
      "13.98969 -6.45181\n",
      "20.44716 -6.40434\n",
      "14.24114 -5.96184\n",
      "15.48168 -5.92634\n",
      "17.37918 -6.57118\n",
      "20.76194 -6.75303\n",
      "17.79070 -6.30493\n",
      "16.72685 -6.42499\n",
      "23.19365 -6.55860\n",
      "22.11439 -6.29056\n",
      "21.33569 -6.31547\n",
      "14.40526 -5.83731\n",
      "19.16152 -6.64814\n",
      "14.25987 -6.08201\n",
      "18.43299 -6.34232\n",
      "16.26913 -6.38665\n",
      "21.26606 -6.60947\n",
      "16.60344 -6.56768\n",
      "14.97713 -6.42888\n",
      "23.74274 -6.83158\n",
      "17.93765 -6.67516\n",
      "19.07062 -6.50238\n",
      "16.67701 -6.72670\n",
      "16.17141 -6.54050\n",
      "15.75864 -6.13137\n",
      "14.16878 -6.48184\n",
      "11.50842 -6.05525\n",
      "19.27105 -6.76030\n",
      "8.46847 -5.85129\n",
      "15.60229 -6.53181\n",
      "14.14688 -5.95363\n",
      "17.98486 -6.46878\n",
      "16.19133 -6.82132\n",
      "16.09719 -6.28366\n",
      "15.34366 -6.29775\n",
      "13.27559 -6.40429\n",
      "6.70439 -6.54331\n",
      "22.43035 -6.56508\n",
      "15.33634 -6.13190\n",
      "15.33056 -6.08079\n",
      "12.52689 -6.40742\n",
      "17.94244 -6.33609\n",
      "15.95894 -6.24798\n",
      "19.40630 -6.07724\n",
      "14.66162 -6.60744\n",
      "17.98261 -6.41126\n",
      "11.21456 -6.42340\n",
      "15.19609 -6.27324\n",
      "12.24686 -6.31714\n",
      "17.86578 -6.08480\n",
      "20.35791 -6.31759\n",
      "17.30080 -6.00722\n",
      "14.92832 -6.52490\n",
      "11.56034 -6.37373\n",
      "23.43573 -6.00281\n",
      "18.69877 -6.64103\n",
      "13.29640 -6.20848\n",
      "17.83169 -6.28771\n",
      "15.74261 -6.79281\n",
      "15.00890 -6.14525\n",
      "15.73786 -6.48314\n",
      "20.04888 -6.03938\n",
      "17.32661 -5.97652\n",
      "17.90315 -6.36340\n",
      "14.32559 -6.24512\n",
      "10.45151 -6.54248\n",
      "19.05322 -6.25507\n",
      "13.94293 -6.38417\n",
      "24.74430 -6.01046\n",
      "19.32669 -6.06443\n",
      "15.12200 -6.23472\n",
      "14.45125 -6.28316\n",
      "14.01978 -6.61318\n",
      "14.44700 -6.06278\n",
      "20.36491 -6.53071\n",
      "15.13149 -6.36708\n",
      "15.48855 -5.84738\n",
      "19.93383 -6.56094\n",
      "13.27980 -6.12657\n",
      "23.56699 -6.16965\n",
      "16.96139 -5.95104\n",
      "11.94312 -6.03648\n",
      "14.08621 -6.38116\n",
      "12.22771 -5.97576\n",
      "11.52395 -6.58173\n",
      "18.45177 -6.39096\n",
      "9.30434 -5.91765\n",
      "16.91939 -6.30922\n",
      "13.70620 -6.16816\n",
      "18.80218 -6.18704\n",
      "18.37066 -6.20117\n",
      "28.34292 -6.66697\n",
      "20.37763 -6.54593\n",
      "24.30259 -6.55361\n",
      "18.05022 -6.12386\n",
      "18.29287 -6.02203\n",
      "29.06056 -6.54791\n",
      "12.21366 -6.04139\n",
      "22.45188 -6.23758\n",
      "14.16459 -6.65066\n",
      "20.79399 -6.36142\n",
      "18.64130 -6.47148\n",
      "15.90426 -6.04987\n",
      "20.26466 -6.39642\n",
      "17.29181 -6.37044\n",
      "14.03412 -5.92919\n",
      "18.71390 -6.44336\n",
      "16.72651 -5.95956\n",
      "18.03020 -6.59065\n",
      "18.37040 -5.71290\n",
      "12.20778 -5.94427\n",
      "18.08060 -5.92052\n",
      "21.03720 -6.50639\n",
      "15.83659 -5.85457\n",
      "16.29068 -6.24945\n",
      "12.65223 -6.43255\n",
      "20.81336 -6.15773\n",
      "17.15121 -6.31130\n",
      "12.49500 -6.68102\n",
      "16.79269 -6.15490\n",
      "18.83481 -5.89221\n",
      "15.14721 -6.30951\n",
      "13.31550 -5.95105\n",
      "14.82280 -6.35861\n",
      "17.25782 -6.10075\n",
      "16.34700 -5.80379\n",
      "14.04213 -6.82671\n",
      "22.64049 -6.13062\n",
      "14.60091 -6.36535\n",
      "21.66423 -6.04373\n",
      "17.57628 -5.95160\n",
      "19.88036 -6.51196\n",
      "12.27644 -6.17760\n",
      "21.67458 -5.96253\n",
      "12.31672 -6.30104\n",
      "14.44136 -6.25475\n",
      "13.84541 -6.01304\n",
      "19.15141 -5.92674\n",
      "14.00993 -6.03555\n",
      "19.78010 -6.09711\n",
      "19.36640 -5.98512\n",
      "17.71905 -5.82209\n",
      "18.18172 -5.88774\n",
      "17.88319 -6.17167\n",
      "23.09579 -6.16928\n",
      "14.70738 -5.81570\n",
      "15.40617 -5.99035\n",
      "15.14238 -6.29281\n",
      "23.85585 -6.32636\n",
      "17.56118 -5.88903\n",
      "15.85890 -5.52917\n",
      "19.50349 -5.91731\n",
      "16.03319 -5.81925\n",
      "14.40473 -6.18573\n",
      "14.13160 -6.64809\n",
      "10.72836 -6.68769\n",
      "17.78884 -5.56312\n",
      "12.40646 -6.01704\n",
      "21.67607 -6.15178\n",
      "12.35902 -6.35165\n",
      "19.27132 -6.49626\n",
      "15.40319 -6.02077\n",
      "23.63608 -5.72984\n",
      "11.00372 -5.78795\n",
      "19.72094 -6.64999\n",
      "13.57012 -5.58816\n",
      "10.77423 -6.38474\n",
      "18.33321 -5.94124\n",
      "13.95934 -6.19936\n",
      "14.99756 -6.39548\n",
      "14.44583 -5.94482\n",
      "13.17973 -6.70829\n",
      "13.40316 -6.21104\n",
      "15.31011 -6.11147\n",
      "12.50207 -5.76513\n",
      "19.17050 -5.92628\n",
      "22.78566 -5.95100\n",
      "12.54457 -6.33550\n",
      "12.62187 -5.69901\n",
      "14.69284 -6.48801\n",
      "12.73497 -6.04980\n",
      "16.64035 -6.06526\n",
      "12.00517 -5.86120\n",
      "17.21973 -6.43968\n",
      "18.61642 -5.58751\n",
      "15.43736 -5.58590\n",
      "15.97278 -6.92325\n",
      "12.51564 -6.15588\n",
      "13.59269 -5.85406\n",
      "14.34725 -6.12389\n",
      "17.38048 -6.56096\n",
      "12.30515 -6.40506\n",
      "14.71114 -5.82452\n",
      "16.87296 -5.33281\n",
      "19.58867 -6.29450\n",
      "13.79671 -5.97259\n",
      "12.56969 -6.31425\n",
      "12.50862 -5.90979\n",
      "16.14943 -6.75318\n",
      "16.52396 -5.85839\n",
      "18.52561 -5.99731\n",
      "17.25998 -6.09984\n",
      "20.15853 -5.95406\n",
      "20.83965 -6.03376\n",
      "15.15193 -6.07332\n",
      "11.71517 -6.20106\n",
      "9.83031 -5.91762\n",
      "11.35912 -5.42340\n",
      "17.58175 -6.05625\n",
      "15.91717 -6.28566\n",
      "15.89872 -5.50523\n",
      "8.01789 -5.76323\n",
      "15.91512 -6.32770\n",
      "23.12424 -5.92658\n",
      "17.19596 -5.42509\n",
      "17.33596 -6.39534\n",
      "23.48569 -5.90339\n",
      "11.15275 -5.44182\n",
      "19.23025 -6.03782\n",
      "9.51573 -6.39367\n",
      "14.27841 -6.66861\n",
      "11.59061 -6.19983\n",
      "14.16063 -5.90783\n",
      "16.30184 -6.06913\n",
      "20.49909 -6.02559\n",
      "13.56198 -6.07592\n",
      "13.06134 -5.58102\n",
      "17.02704 -6.81983\n",
      "16.08851 -5.93694\n",
      "16.88197 -6.00712\n",
      "14.60997 -5.99588\n",
      "18.85927 -6.12046\n",
      "17.84615 -5.63701\n",
      "18.64527 -5.63224\n",
      "15.93196 -5.95744\n",
      "6.06844 -6.46237\n",
      "9.07363 -6.59150\n",
      "21.26453 -5.91356\n",
      "15.27329 -5.75733\n",
      "16.52155 -6.05708\n",
      "10.61367 -5.39474\n",
      "18.48849 -5.83983\n",
      "18.39577 -6.32665\n",
      "10.03580 -6.12173\n",
      "24.09183 -6.01884\n",
      "14.55086 -5.42505\n",
      "12.13419 -6.06956\n",
      "13.59508 -5.71605\n",
      "14.70316 -5.69746\n",
      "13.63144 -5.68870\n",
      "17.00366 -5.90164\n",
      "14.66438 -5.90412\n",
      "14.98438 -5.41993\n",
      "13.62670 -5.89621\n",
      "21.55193 -6.19609\n",
      "15.41301 -5.41805\n",
      "15.32634 -5.84989\n",
      "10.71954 -5.85199\n",
      "16.76482 -6.05213\n",
      "17.29495 -5.79911\n",
      "18.39134 -5.65127\n",
      "12.72757 -5.85072\n",
      "15.31089 -6.05104\n",
      "13.03705 -6.20893\n",
      "13.51927 -5.77044\n",
      "17.28560 -6.80037\n",
      "18.06877 -6.15994\n",
      "11.54117 -6.03892\n",
      "19.34498 -5.54289\n",
      "16.64371 -6.06552\n",
      "12.35551 -5.74125\n",
      "14.96660 -5.93742\n",
      "12.53625 -5.79462\n",
      "9.15856 -5.59908\n",
      "12.30316 -5.74443\n",
      "16.21506 -5.61370\n",
      "15.23902 -6.09857\n",
      "13.27450 -5.62335\n",
      "18.92529 -6.02786\n",
      "12.27248 -5.73276\n",
      "13.38990 -5.52007\n",
      "12.94925 -5.40574\n",
      "16.42081 -6.49990\n",
      "13.02892 -6.13321\n",
      "17.55978 -5.67652\n",
      "15.52959 -6.29191\n",
      "17.39687 -6.11034\n",
      "10.91766 -5.76398\n",
      "19.07837 -6.09972\n",
      "19.12746 -5.80212\n",
      "19.25283 -6.04007\n",
      "12.02591 -5.95502\n",
      "9.67490 -5.15298\n",
      "15.14272 -5.98604\n",
      "17.64268 -6.77653\n",
      "11.80694 -5.46711\n",
      "18.53205 -6.37927\n",
      "15.16213 -6.64464\n",
      "14.84627 -5.72789\n",
      "16.11910 -5.77542\n",
      "16.00174 -5.93323\n",
      "16.31619 -5.80217\n",
      "12.56113 -5.98129\n",
      "11.69107 -6.19739\n",
      "16.00265 -6.05283\n",
      "12.56654 -5.55382\n",
      "15.10150 -5.46435\n",
      "11.81085 -5.83223\n",
      "13.10440 -5.16173\n",
      "16.91113 -6.00443\n",
      "16.87610 -6.03129\n",
      "13.48738 -5.64729\n",
      "15.77282 -5.19883\n",
      "17.54721 -5.49676\n",
      "9.54050 -5.46211\n",
      "20.78965 -6.45389\n",
      "16.14131 -6.39885\n",
      "11.00884 -5.37041\n",
      "18.45127 -6.06114\n",
      "12.60670 -5.79623\n",
      "9.33119 -6.66842\n",
      "11.96675 -5.10275\n",
      "10.72977 -5.12808\n",
      "20.78269 -5.87376\n",
      "10.03383 -5.78549\n",
      "12.77545 -5.84241\n",
      "16.87055 -5.70483\n",
      "11.84570 -6.16768\n",
      "19.33830 -5.25606\n",
      "13.03483 -5.68150\n",
      "21.06147 -5.95961\n",
      "14.10616 -5.59916\n",
      "14.81777 -6.04792\n",
      "11.89538 -5.55808\n",
      "11.71157 -5.90906\n",
      "14.64822 -6.17794\n",
      "9.66366 -5.77271\n",
      "16.02964 -5.71564\n",
      "15.97807 -5.47317\n",
      "11.17792 -6.22859\n",
      "14.52620 -5.16127\n",
      "10.64796 -5.76720\n",
      "16.87127 -6.39620\n",
      "12.64700 -5.53375\n",
      "16.51663 -6.07869\n",
      "12.90937 -5.05566\n",
      "15.19645 -6.33680\n",
      "15.90885 -5.82533\n",
      "11.05490 -5.29095\n",
      "13.19380 -5.56674\n",
      "21.34546 -6.04155\n",
      "10.44985 -6.08062\n",
      "13.27687 -5.44810\n",
      "12.85076 -5.76336\n",
      "16.17386 -6.05700\n",
      "13.03765 -5.15260\n",
      "13.87177 -5.90007\n",
      "22.03223 -6.36444\n",
      "15.87884 -6.05645\n",
      "17.59011 -5.21271\n",
      "12.87630 -5.46055\n",
      "18.96306 -5.52044\n",
      "18.80332 -5.77997\n",
      "12.17902 -6.53060\n",
      "15.01018 -5.89918\n",
      "7.51819 -5.62095\n",
      "16.28113 -6.32008\n",
      "18.39092 -5.93013\n",
      "14.05337 -5.86607\n",
      "18.37920 -5.72598\n",
      "14.52870 -5.65005\n",
      "18.11736 -5.99577\n",
      "13.22600 -5.52771\n",
      "9.45639 -6.37216\n",
      "7.67091 -5.71143\n",
      "18.45448 -5.94759\n",
      "12.71833 -5.92384\n",
      "12.98233 -5.65715\n",
      "12.62560 -6.62412\n",
      "11.49200 -5.81577\n",
      "10.85345 -6.02283\n",
      "15.69811 -6.37664\n",
      "18.12733 -6.11091\n",
      "12.68770 -5.35502\n",
      "13.02799 -4.85670\n",
      "12.64005 -6.68695\n",
      "14.44946 -6.19866\n",
      "18.27376 -6.12454\n",
      "16.30078 -5.53955\n",
      "11.25470 -5.50448\n",
      "11.07340 -6.15246\n",
      "14.21462 -5.61099\n",
      "20.01381 -5.70297\n",
      "11.58568 -6.18476\n",
      "18.87171 -5.95331\n",
      "12.82502 -5.85188\n",
      "12.44844 -5.83301\n",
      "11.35003 -4.79424\n",
      "14.83599 -6.11167\n",
      "13.82005 -5.89947\n",
      "16.61647 -5.50803\n",
      "16.81815 -5.90034\n",
      "13.51340 -6.32213\n",
      "18.15481 -6.41527\n",
      "18.90422 -6.30157\n",
      "18.81973 -5.50437\n",
      "11.37291 -5.58208\n",
      "13.90184 -5.98452\n",
      "15.20443 -5.36208\n",
      "13.68599 -5.91312\n",
      "13.96655 -5.95846\n",
      "20.16477 -5.43508\n",
      "18.28020 -5.84716\n",
      "17.94358 -5.78693\n",
      "14.60255 -5.42208\n",
      "12.91341 -6.39059\n",
      "19.77657 -5.81323\n",
      "16.30972 -5.64865\n",
      "18.80404 -5.32139\n",
      "19.86614 -6.18694\n",
      "14.31615 -5.67886\n",
      "10.36305 -6.02077\n",
      "10.25668 -5.21377\n",
      "17.67995 -6.21362\n",
      "9.42246 -5.81108\n",
      "16.02545 -5.74978\n",
      "7.34852 -6.32197\n",
      "9.58400 -6.21237\n",
      "16.37129 -5.51161\n",
      "11.86982 -6.33870\n",
      "14.25271 -5.84724\n",
      "11.44369 -5.68099\n",
      "14.37506 -5.34742\n",
      "10.80891 -5.83394\n",
      "12.10163 -5.55627\n",
      "12.73616 -6.16885\n",
      "22.55483 -5.68619\n",
      "13.87206 -6.13538\n",
      "10.67473 -5.47103\n",
      "13.46440 -5.89959\n",
      "12.72132 -6.09884\n",
      "13.02918 -5.39247\n",
      "12.52098 -6.14085\n",
      "16.57392 -5.94849\n",
      "9.31006 -5.36843\n",
      "14.50394 -6.05582\n",
      "20.35021 -6.08936\n",
      "15.31439 -4.97743\n",
      "14.76032 -6.00912\n",
      "19.94548 -4.96367\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d4e20c3d9c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrespondent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeakers_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspeakers_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfoloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrespondent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrespondent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#gen_err = trainer.train_llh_step(bx, respondent, by)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpretrain_discr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minfolosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfoloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for bx, by, respondent in generate_data(data_rows, speakers_list=speakers_list, n_iter=10000, max_len=seq_len):\n",
    "    err, infoloss = conv_discriminator.train_step(bx, by, respondent, 20, sample_c(respondent))\n",
    "    #gen_err = trainer.train_llh_step(bx, respondent, by)\n",
    "    pretrain_discr_loss.append(err)\n",
    "    infolosses.append(infoloss)\n",
    "    print \"%.5f\"%err, \"%.5f\"%infoloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWZAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe722a21bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_smoothed(pretrain_discr_loss, n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VOXZ+PHvncm+kD2EsCXsKApCQEQRRURFK10ttvpq\nxVJbtVr7trXV2s1fbW211r62r77WpWrBtVgVpKJFsMi+BgirQBICCYTs++T5/XFmJjPJTBKYJJPM\n3J/rysXZZs6Tc5Fzn2c59yPGGJRSSoWesEAXQCmlVGBoAFBKqRClAUAppUKUBgCllApRGgCUUipE\naQBQSqkQpQFAKaVClAYApZQKURoAlFIqRIX782ER+TnwTaDUseknxphlXo47DFQBdqDZGJPble9P\nS0sz2dnZ/hRRKaVCyubNm08aY9K7cqxfAcDhD8aY33fhuMuNMSfP5Iuzs7PZtGnTWRZLKaVCj4gc\n6eqx2gSklFIhqjsCwN0iskNEnhORZB/HGGCliGwWkUUdfZmILBKRTSKyqbS0tKNDlVJK+UE6ywYq\nIiuBTC+7HgDWASexbvC/AgYZY27z8h2DjTFFIpIBfADcbYxZ3VnhcnNzjTYBKaVU14nI5q72s3ba\nB2CMmdPFk/4f8K6P7yhy/FsiIv8ApgGdBgCllFI9x68mIBEZ5Lb6BSDPyzFxIpLgXAbmejtOKaVU\n7/J3FNCjIjIJqwnoMPAtABHJAp41xswDBgL/EBHn+f5ujHnfz/MqpZTyk18BwBhzs4/tx4B5juVD\nwER/zqOUUqr76TBQpVTQeT/vOCVV9YEuRp+nAUApFVRqG5u54+XN3PbCxkAXpc/TAKCUCiqna5sA\nKCirC3BJ+j4NAEqpoHK6phGACJve3jqjV0gpFVRO11oBICpcb2+d0SuklAoqziagyDYBwN5iyD9e\nGYgi9VkaAJRSQaWizgoAtjDx2P6XVQe4+ok17DpWEYhi9UkaAJRSQaWq3hEAxDMAbC+0bvzaOdxK\nA4BSKqhU1TcDYG+T6DLS0SncaG/p1fI8+n4+X/zzf3r1nF2lAUApFVScNYC6RrvHdmefQLmjk9hd\nfZOdCkffAcDe41Xc/uJG6pvs7Y49U39edZAtR8v9/p6eoAFAKRVUKuusGkB1Q7PHdmefwKnq9gHg\n+v/5hIm//BcAe4oreejtPFbuKWHj4bIun7eitoniiv7VvKQBQCnV5932wkau+kPXMsg7awAVdU0U\nnq51ba9xBIQat8BgbzHc/Nf17DtRDcBH+Se45o9rWP+ZdeMvd6sVdGbuEx9z0SMf+dxvb+l47pVA\n0ACglOrzPsovYe+Jqi4d6+wDALj2yU8AeD+vmOV5xwGocWsaKqtpZM3+1qnKb3vBcwKqovKuP9Gf\nqGzocH9NY3OH+wNBA4BSKqi4BwDnkNA7Xt7i2lbrdiNu6qRD2Pn5M/H4v/Z63V7bYGfXsQoOllZ3\n+Pnfvp/P2gMnOzymu2gAUEr1G11pRqms7/im/fa2Y9hbjNXx28kNvrr+zJ/an/zogNfAMv2RD7n2\nyU+44rGP2+0rqazn8X/t5URlPX9ZdZCvPbv+jM97NvydEEYppc7a8Yp6XttUQHFFPb/+wgSkzdh9\nwKMdv7KuieS4SJ/fd7C0msouPLWP/MmyLpWvqpNgAlZn84bPTnlsO1pWy8j0eJ+fue5Pa3j37pmu\n9Wm//hCArQW9O1pIawBKqYC5/n8+4fEP9rF4w1FXR6y7grJaLvntv13r5R3c3D87WcMVj31MTaOd\nWy4aDsCkoUln1PmaGhfJ1Oxk1/qmI6c7/cx9r25r13dwtMwKWr6GkeYVeU9JUXUWNQ5/aABQSgVM\nSVVrx+niDUfZ36ajt8Dt6R+8j+F3Olnd+l1DU2IZnBTDtoJypj/yYZfL02RvISE6wrVeeLqOvKKO\nU0ds8/LU7nynoCt9CC1uASohuncbZTQAKKUCwrR5U/eFtYe57UXPSVzaDsPsqAbg/iLX2MwE1wie\nUrcg88cFk7x+1rm9sr6ZNimEOFhaTWOz787itu8bWOVu9Cj/V3OH8sC88R7HOGsm+0qq2m3rLRoA\nlFIB4UzJ8IOrxrq2tc3Ts69NjaCjGkCZY9/ojHim5aQwMj2u3TEzRqbxi+vPbbd9zMAE13JNg9Vs\nM39SFgD3LNnGPUu2+jxvbWP7Zh5noHKW9/pJWcw9d6DX3+Wxf+0jPiqcSFsYaw9afQl/+GrvTKOu\nAUAp1evsLYZZj64CIC7SxsABUQDERto8jlux6wTQ+hbv0x8f8vmdzolglt55MVHhNpYsushj/59u\nvID0hChumZHN3bNHeeyLjwrnS5OH8JevT3Y129yQO9S13/kOQVlNo0dTU1sLL8khITqc3ccqeWnd\nEVcgSIyJYHhqHP+862LXsWU1jRhj2FFYztxzB3JO1gC38kS0++6eoAFAKdXrSqrqOV5pTdoeFxXO\n23deQnpCFLWNdo8bbHVDE/POyyTv51cBkH/c98tgFXVNhIeJK4ikthktNH5Q61P+qAxrhM7Fo1K5\nd85ohiTH8NgNE7nmvEFE2KxgMyQ5xnW8M4/Q5F99QO7DK32WIToijPSEKP61+wQ/XZrH4ZM1Vlni\nrbKcNziRK8+xagInqxt5YGkeJyobSImN5FRN6+8dbms/GqonaABQSvW6otOtTT1xUeFkJkZz83Rr\n5I77Dba+qYXEmEhiIm1MHJrU4XfWNDQTFxXuGkoa1qYxf0BM61P1VedmcuO0ofzhhkncO2eMx/DT\nP904mR9ePZZhKbGubZFdnF4yITqC8ZmtT/LOTuzUOKuGIyLcd+UYwKoB/H39UQAiwsO45aJs1+e6\nMpS1O2gAUEr1uh2FrSNr4qKskS8pXsb31zfaiY6wblNXjs8A8NkhW91gJz7KcxTNY1+ZSHqCdfNN\ndAsA0RE2Hvni+WQMiG73PcNSY/nOZaM8goK9xbBmf6lrvaKuibsXb6WsxrNPYnBSDGMzW2saR8vq\nSI6N8JidzFkzKXN74q9vsrPwkhz+96bJAEwe1joUtSfpi2BKKb8dK6/jjc2F3Hn5qHYzcXnz1tZC\n17Kzycb9idupvtlOTIS13/kEX1HXRHJsBEXldQxPbe3otWoAnn0IX5oyhGvPH0Th6Vqiwj33dcWg\nxGiKK+qpa7Jz8183uLa/9Olh3tl+jHd3HPM4fnByjEeAWr2v1KMpCaxAFxkexoGS1vce7C0GEeHq\nCYM4/Jtrz7icZ0trAEopvz383m4e/2AfL316uNP8OnWNdvYUt7blD0q0nsIHt7lRNttbaLIboh0B\nINEVABq5e/FWZv1ulUfO/2pHE1Bb0RE2RmUktNveFcu+O9P1VO7OOVqzzUhW0uOj2pWhvsnzeoTb\nwsgdnsyLnx5xbburTad0b9EAoJTyW2ykddP7+TtWIOjI8cp67C2Gx2+YyPafzWVIsvXkPyLNc9hm\nveNJ2lkDSI+3mnL+9ukR16gc9zH41Q3N7ZqA/JUcF8nU7JR22+t8vOEbHxXO5ePS2wxBbT+2f8bI\nVNfyU1+bTEZC+6ao3qABQCnll8LTtby9rci1/r7j5uzNZydr2OsYyZMaH+XRLi8iLLwkx3UTdz7d\nO/sApo9IZdLQJFbsav3+mY+25t+vaWgmLrL7W7WTY1v7JiYPszqij5yqcW279rxBruW4qHCiwm08\n+uXWcfxtawkAF41Mcy1fPSGzO4t7RjQAKKX8cstzG2iyGxKiw7lx2lCvb8Y6Xf77Vdzx8mag/TBN\ngKjwMBqarRu/M4+OswkoLEy4/5pxHnn33ZtXanw0AfnLfTTRi7dNwxYmfLD7hGub+7sLzs5eZ9AC\nWDCt9X0Cp/OHJAJw28U5Xeoz6SnaCayU8ovz7d3aRjvRETafCdBq2gQG59h4d1HhNprsBnuLYXex\nlTAtxu0GO31EKmMHJnhMDlNR20RibATVDc09lkvnJ/PGMSQ5loToCDIHRHtMFBMT6btzeWhKDN+/\ncmy77RG2MPJ/dXWXh5f2FA0ASqmzVlHb5ErpAFZ7va8AcNit2QQ8h2U6RTmenBua7XzqSIswa0y6\nxzGp8ZHQ+gBOaXU9MZE2ahrt7UYBdZdFl450LQ9Oiuk0ADj7LSYPS273PoKTs2YTSH4HABG5G7gT\nsAPvGWN+6OWYq4E/AjbgWWPMb/w9r1Iq8P7rudaJS15aOI1Nh0/TZDc02VuIcHu6LatpbDcZe7SX\nYZnRjiaUhqYWKuqaGJoS45GdE9q/L/CFp9ZS5ahd9EQTUFtZSZ4dtjFebuQj0uN57tZcpo9Ibbev\nL/HraonI5cB8YKIxpkFEMrwcYwOeAq4ECoGNIvJPY8xuf86tlDpztY3NxETYvE68cja2O17o+sqU\nIcwYmcYuR577+ia7KwD84YN9/PHD/R5J32IibF6fjKMcN9NtheWU1zaSFNO+mahtAKhya1rq7lFA\n3mQleQ5XjQwPY8W9l7ar+cwe55n8rS/y92p9G/iNMaYBwBhT4uWYacABY8whABFZghU0NAAo1Uvu\nWbKVVXtLXYnOXlo4jZmj0zv5VNfZHUNdoh3NIfVNLThHNj6z2krgttltchVfHZ/Op+lvPG+lhZ45\nOq3dMR3d5HtiFFBbbQNAXaPd4+3f/sTfHogxwEwRWS8iH4vIVC/HDAYK3NYLHdu8EpFFIrJJRDaV\nlpb6OkwpdQbe3nbMY3KSf+d37W/r7W1FPP3xwU6PS3EMlXQ24bg/DTtv9h/ltz4f+krn0PZlsKTY\n9jWAjpp5uqli0yHni2tOvT2LV3fqNACIyEoRyfPyMx+rBpECTAd+ALwmftYtjTHPGGNyjTG56end\n94SiVKhq9vJmbkcpjZ3Kaxu5Z8k2Hlme7/OYcx0pjO+bayU4c3aI+npRyqnRx9vC2ameL4O1bW+H\n1hrAnPHtm1icmTZ7Uts5iSN6KXNnT+g0ABhj5hhjJnj5eRvraf4tY9kAtABt62xFgPtA2CGObUqp\nXnDRbz7yWE+MifCYJetASZVHXhqnyb/6wGN9R2G56wWotQdOUl7bSHVDM/MnZbneBHY24Sx0zOxV\n29js8V7ADblDOixrWpuhocNT2k/q0loD8HzDKiEqvF2HcU9wfzHsR1eP4545Y3r8nD3F3yagpcDl\nACIyBogETrY5ZiMwWkRyRCQSWAD808/zKqW6oL7J7nGzB+slpE8PnSL7/vfIP17JnMdXM+fxj9t9\ntu3shNf/z3+Y9btV1DQ087Vn13PD059yqrrR44bo7KAtKKsj+/73eHbNZx7fcdHIjkfFiIhrLP/1\nE9vPogUwYbBV67hi/EDuv2aca6rF3mj+gdbmLoBvXzayVzqee4q/JX8OeE5E8oBG4BZjjBGRLKzh\nnvOMMc0ichewAmsY6HPGmF1+nlcp1QVHTtW225aV2NrOvmZf6/NafZOdSFsYYWHSrtnIff13K/YC\nsO+EVWsY6JZSeWCb9Mpt8wKdPySJ+Khw5p3nO/3BJz+aTV2jncxE7/lxxmUOYNODc0iNi0REXJ3L\nNV6mZuwJvT1xe0/y6zcxxjQCN3nZfgyY57a+DFjmz7mUUmfOOevWX2/JpbqhGVuYsOVIuWu/+1Pz\nuJ++z9cvHMb/+8J5nGwzZn/UA8tdyy+sPeyxzzmdI+DKve8uJy2OzxwzYyXGRLDtoSs7TH+QGBPh\n9SUxd2nxredxzvTVWxOqh4UJ/z13TKe1mf5AcwEpFcScM0sNTYll/qTBXHd+lsfbsm2bh15xzFBV\nXmcFgGk57TNhtuX+1B9hC/O4OUPr9ItgdeCG28K67T0EsDKRPjBvPEsWTe+27+zMXbNHM2V459em\nr9MAoFQQq3CblNzJfRhlqY/RQOW17T/nS0abp/6ND1zhse7+HVHhPXPL+ealI/r8W7d9kQYApfqp\nAyVVFJS1b+N3V1lv3cgHuI2OaXHLT1zb0L7dvLqhmQXPrAO8pzloq+20im2f7tumfFZ9hwYApfoh\ne4thzuOrueaPa3we89nJGh593+qwdU9PXO324lJNY/uXmCb8bIVr+btXjOLBa8d3WJYBXjpFn7l5\nimu5K7UIFRgaAJTqhx74x07Aelo/5paZ0t3ag60jfNyfvOPdbthtJzVvKysphttnjvA61DE1LpJb\nZ2R7faqfe27rKJ/EmAhW3jeLV26/sMNzqd4XPOOZlAohSza2Zlf50Zs7eGlh+5tr4WkrMLx79yUe\n2xdekkNKbCQf7D7Bh470DL+cfy5Fp+t42pG3B+Cfd13sesErITrc44WuSFsYm396ZZfKmp4QxaiM\neI/OYNU3aA1AqX7GtJlj0D3Hj7vPSmsYkRbHhMGJHtujwm0smDbMoyYwYXBiu7w7Ywa2JjhbMHUY\nYOXCB1h06Ygul7dt7hzVd2gNQKl+prLOs93e2QDzyf6TDE2JYbgjn872wnKvE5o7OacyHDggisnD\nktl3vHWWrf+6aLjHhCXfvmwkt87IJjE2gsr6JhLO4O3XttkzVd+hAUCpPqamoZm3thbxxQsGe818\nWVbb2m7/tQuHsWTDUcpqGrnpr9bkLKMz4vn59edSXFHfYZpiZ/POIMebwc4aQGJMBL+cP8Hj2Mjw\nMNd8twPOMN9O22Giqu/QAKBUH/L6pgKe+89h9hRX8ubmQpbeeXG7Y045xu7fdfkoJg5N4u/rj7J6\nX2t65/0l1Xz9WSsYeBuh4+R8Mk+KtW7oztQLVfXem5TO1D++M4OYyO6bfEZ1Pw0ASgVIs72FXccq\nmTg0CYDTNY384I0drv07iypoaLYT1WbqRGd6h+smDqKhycrRc++r27yeI76DAPDlKUPYcuS0K5Xz\n8JRYoH0SuLN1wbDk7vki1WO0E1ipAHn8g33Mf+o/5B+3plHMO2ZNr5gWH0VspA17i3Hl0HF3vMIK\nAJkDotslX2srPsp3c01iTARPfX0yI9Ot0TnOmoAz26YKfloDUCpANnxWBsD+E9WMHZjAXkcn7Ip7\nZ3KwtMaVbrmtkqoGosLDSIyJcE276C4pNsKVyuFMUhWLCB//4DKvs3Cp4KQ1AKUCwN5iKDhtpXF4\nb0cxOT9exivrj5IWH0VqfJTr7VnnjdxdZV0TSbERiAi2MGH2uAyP/f/+/mWu5cgzzL0zPDVO39wN\nIRoAlAqAkqp6TlRanbkr95wArNQNYzM9m2OcWTnd1TTaPSY/T3fLvrnsuzNJjotkwVRrEr6eSr6m\ngoM2ASnVwxqbW9h1rAIR4fzBiYSFiUc+nma3Xlfny1fOp/BP9p+koq6J71w2ynVMbUMzsW4pnX8y\nbzwJ0eEsmjWCDEeb0M+vP5fZ4zLavQSmlDsNAEr1oFPVDUx5eKVr/d45o7l3zhgq69snYYPWiU6i\nI2zERNhYnnec5XnH+dalI7GFCcYYNh4uY9yg1o7axNgIHrzuHI/viY6weeTjUcobrR8q1QXVDc08\n9HaeRz6cztQ12lm9v9Rj274TVfzg9e28sbmw3fHfvWI0N1043LV+blbrTb6yrok7X9lCzo+XUVnf\nTH5x5Vn8Fkp50hqAUl3w7JpD/O3TI2QmRns0x/jy4Z4T/GHlPvKKPG/Ua/adpMpLELnlouHcd+UY\nj23nD0lik2O+2ydW7uO9ncWufb5qEEqdCQ0ASnVBXZM1ccqLaw8zKj2+w+aV+iY7C1/c1G57XKSt\n3c1/5X2zSI2LdHX6ukuJa9324qdHzrboSvmkTUBKdUGLo6P2RGUDi17a3G7/8Yp63nQ06+zx0Tzj\n3m7vNCQ5huS4SK/pEhK85Ny5fmIW4WFyRtk4lfJFawBKdUFzm/wI9U12j2yZX/rLWorK69heWM6F\nOa1z0/7sc+cwLCWWb7+yhYeuO4f5T/0HgL0PX01EWBhhYb7z5LQ9J1hZOp+88QJ/fx2lAK0BKNUl\nbWfOmv37Va7l1zYWUOSYletvnx7hzr9vAeC2i3P46tShXDF+IPsevobzhyQSHRFGcmwEUeG2Dm/+\nAGnx1hu5X80d6tqWGq+ZNVX30RqAUp0wxrBm/0mPbccc+XigNYdPW/dfM87jTVwRYetP53Z5JNH1\nE7OIjrBxYU4Kr26yZgDLStLJVVT30QCgVCeKyus8agDpCVG4T8pVVd/M0JQYJg5J4t0drSN1vKVh\niIm0ERNpa7fdGxHhKrfO5uiIsHaZQZXyhwYApXwwxvD8fw7zy3d3A/Dol84nJtLGzqIKXlx7GGMM\nIkJlXRMDoiN6NO/95gfnaF591e20D0ApHwpP17lu/gBfmDyYz03MIiUukobmFmobraGhlfVWAPjp\ndeNdx07N7t5c+KnxUaTEaZZO1b20BqCUD+5t9f9702QibNbzUqYjB39xRT2jMuKpqm9mWEosGQnR\nbHvoSvaXVHOe5uBR/YDWAJTyoaKuNRWz+8Qrg5OtqRSdI39O1za6krclxUYyNTvFY4ioUn2VBgCl\n3Ly+qYBHlu0BPAPAUMd0iWC9vAVQeLqWukY7JyobPPYr1V9oE5BSDsYY15y8t88cQYVjMpZ3777E\nlaUTIDXOWj5d08iRMmvKxpy0uF4urVL+87sGICJ3i0i+iOwSkUd9HHNYRHaKyDYRaZ8kRak+oLKu\ntc3/3/klrslYstvc3CPDw4iJsFFR1+San3dQoo7PV/2PXzUAEbkcmA9MNMY0iEhGB4dfbow52cF+\npQKqtLrBtbzl6GkSosOJjggjzsu4/cSYCCrqmlxTNuoIHdUf+VsD+DbwG2NMA4AxpsT/IikVGCfd\nAsASR3qHtPgor+PvnQHg147+Ag0Aqj/yNwCMAWaKyHoR+VhEpvo4zgArRWSziCzy85xK9Yi1B095\nrC/bedyj7d9dYkwEp2uaKKmygsYAL5k7lerrOm0CEpGVgLfk5w84Pp8CTAemAq+JyAhjTNs0hpcY\nY4ocTUQfiEi+MWa1j/MtAhYBDBs2rOu/iVJ+qKht4skP97fbPn5Qgtfjxw1K4G9uOfo7S+ymVF/U\naQ3AGDPHGDPBy8/bQCHwlrFsAFqANC/fUeT4twT4BzCtg/M9Y4zJNcbkpqenn+3vpdQZ2VlkJXT7\n7uxR5A5vfYv3c+dneT3+srGt/zfvvHxkzxZOqR7ibxPQUuByABEZA0QCHh29IhInIgnOZWAukOfn\neZXqVs4AcNslOTz/jdaWTF/j+zMSWkf95Gan9GzhlOoh/gaA54ARIpIHLAFuMcYYEckSkWWOYwYC\nn4jIdmAD8J4x5n0/z6uU3x5cupNlO4upb7Lz2/fzHVMzRpIQHcHscdaAtkwfwzvTE1r7BnQIqOqv\n/BoGaoxpBG7ysv0YMM+xfAiY6M95lOpuzfYWXl53lJfXHeWj788CYLzblI1P3zyF0qoGV/6ftlId\no35mjk5jXGb7qR6V6g/0TWAVkk5Wt+b3P11rLS+cmePaFmELIyspxufnw21h7Pz5XGIj9U9I9V/6\nv1eFnJYWw/RHPnStv+GYzD0p5syGcnqbtF2p/kSTwamQ89mpGo/1xRus6RaTYvVlLhVaNACokLPt\naDkAV5070GN74hnWAJTq7zQAqJDzUX4JAwdE8eSNFzDYrZ0/OVYDgAotGgBUyNl1rILc4SlEhdu4\nd85oAD4/KUvn3FUhRwOACil1jXaOlNUyemA80NruHx+t4yFU6NEAoILa29uK+J+PWnP8HCipxhgY\nO9DK8XPFuAx+fM04fnj1uEAVUamA0cceFdTuWbINgK/kDuVQaQ1HHTN4jXYEgLAw4VuzNJePCk0a\nAFTQarK3uJYv/LU17n9IcgyDk2IYoVM4KqVNQCp4na5pbLet8HQd03JSNH2zUmgAUEHslJcAADqB\nu1JOGgBU0CrzEQDck74pFco0AKg+r77Jzo/f2sHK3Sc82vU74wwAETaruedPN15AalwkM0e3m7NI\nqZCkncCqz1u9r5TFGwpYvKGAWy4azi/mT+jS55wBYMW9l2ILE4anxvG5id5n+FIqFGkAUH1eXZPd\ntbxqX2mXP3eqphERGJ4ah007fZVqR5uAVJ9XeLrurD5XVtNAUkyE3vyV8kEDgOrzisrrSI6NYOEl\nORw5VctT/z7gsb/J3kL2/e+Rff97LHjmU9f2sppGUuI0xbNSvmgAUH3ay+uOsCLvOIOTY1xP8r9b\nsZeKuibXMcXl9a7ldYfKXMsllQ2kxbfO3auU8qQBQPVZLS2GB5fmcaqmkcFJMVx1bibO1pwVecdd\nxxWcrvX4XL2jz6DgdC1DU2J7rbxK9TcaAFSfVVbbOo5/XOYApgxP5uCv5zEoMZrlecU0O4aEHi2z\nAsCtM7IBq/O3rtHOicoGhmkAUMonDQCqTzp6qpabnl3vWp/rmL1LRLgwJ4V/7y3lR2/uBCC/uJK4\nSBvTR6QCsHxnMW9useb5nZqd0sslV6r/0GGgqk96Y0sh+cerAFh+z0yPt3fHZg4AjvHmlkIamu2U\n1TQyJjOBSUOTANhaUM6e4komDU1i+ggNAEr5ojUA1SfsPV7FaxsL+MHr2zHGuJp3Hr9hYrvUDd+4\nONu1/O6OYtYePEVWUgyZidFcOiadLUdOc6i0huvOH6SzfCnVAa0BqICztxiuemK1a/1rFw5j7/Eq\nBifF8MXJQ9odHx1h4407LuJbL212JXzLSLBG+wxNjmG142WxkenxvVB6pfovrQGoXrFqbwm1jc1e\n9x0r93zR6wt/XsuH+SWkJfgewpmbncJjN0x0rQ8cEA3g0emb3sHnlVIaAFQvOF5Rz63Pb+S2FzZy\nqrqBRX/bxJr9rSkdDpZWe/3cg9eO7/B7nZ2+ALnDkwHISopxbcsYoAFAqY5oAFA97nil9aLWukNl\nvL65kH/tPsFj/9rn2v/ujmIibWG8eNs0kmMjAHjz2zM6HcETHWFj+8/m8tLCaeQ6jh3jmOoRIDVO\nA4BSHdEAoHpcSWXrm7q/WZ4PwLaCcu5evJUdheW8uaWQeedlMmtMOrfPHAHAuVldy9mfGBPBzNHp\nrvWxmQls+emVHPr1PM0BpFQntBNY9bjjbgHA3Tvbj/HO9mMATMuxmnO+c9lIvnXpCMJtZ/9sovl/\nlOoarQGoHvXG5kIeensXAOMyE3we52z6ERG/bv5Kqa7z6y9NRF4VkW2On8Miss3HcVeLyF4ROSAi\n9/tzTtWZIpP4AAAREklEQVR/lFTV89+vb3etD0m2RuhMzU5mzvgMj2MTHQFAKdV7/AoAxpivGmMm\nGWMmAW8Cb7U9RkRswFPANcA5wI0ico4/51X9Q35xlcf6fVeOISk2gs9fMJjHbpjEw59vndkrIUoD\ngFK9rVv6AMR63fIGYLaX3dOAA8aYQ45jlwDzgd3dcW7VdzmnZPx/X5jAhKxEzskawNafXul6O/fz\nFwzmwaV5AIzK0Je2lOpt3dUJPBM4YYzZ72XfYKDAbb0QuLCbzqv6MOdbuteeN4ikWKtj1j01Q3xU\nOJ89Mk/TNSgVIJ0GABFZCWR62fWAMeZtx/KNwOLuKJCILAIWAQwbNqw7vlIFSFlNA7YwYUC07+Yd\nvfkrFTidBgBjzJyO9otIOPBFYIqPQ4qAoW7rQxzbfJ3vGeAZgNzcXNNZ+VTftaOwguGpsYTpeHyl\n+qTuGG83B8g3xhT62L8RGC0iOSISCSwA/tkN51V92KnqBtYePMW8CYMCXRSllA/dEQAW0Kb5R0Sy\nRGQZgDGmGbgLWAHsAV4zxuzqhvOqPmzj4TLsLYbZbYZ7KqX6Dr87gY0xt3rZdgyY57a+DFjm77lU\n32KM4cb/W8euoko+uX82iTFWW/8n+09yx8tbAHRKRqX6MH3lUp21xRsKWHeojKqGZu76+xaa7C2U\n1zZy76tbXcekaloGpfoszQWkztqLaw+7ltfsP8nL646wvaCck9XW8M/k2Agd5aNUH6Y1AHVWXl53\nhL0nqvjJvHGubb94ZzdLt1nJ3TIHRPPpj68IVPGUUl2gAUCdMWMMf/poP+dmDeC/Lsrmkx9d3u6Y\nd+6+hOgIWwBKp5TqKg0A6owdq6jnRGUDN+QOJTrCxpDkWB6Y1zp714ffn6XTMSrVD2gAUGds0+Ey\nAKY4pmEEuH1mDucMGkBafCTDdeSPUv2CdgKrLtteUM4DS3eSV1QJeOb3FxFe/dZ0IsPDNJ+/Uv2E\nBgDVZQ8uzXPd/L3d6BM6yPmjlOp79FEtxDU2t/DsmkOU1zZ2emx9k921vF5H+CjV72kACHFr9pfy\n8Ht7uHtx68tbOwsryL7/PZ5dc4jfvp/PeT9fweGTNRScrgXg0S+fT7K+4KVUv6dNQCFuZ1EFAPtO\ntM7etXp/KQAPv7fHte2y368C4O+3X8iMUWm9V0ClVI/RABDCSqrqeWKlNYfPicoGfro0j+YWQ1S4\n94rh5ydlcdHI1N4solKqB2kACGFLNlgTtdnCBHuL4aV1R1z7pmWncM+c0Xz92fWubb/7ykRN7aBU\nENEAEKKMMSzdas3L88H3LmXV3lJ++W7rNM0Pfe4cJgxOJO8XV7F8ZzHGQIQO71QqqGgACFEnqxs5\ndLKGB68dz4j0eIalxDIsJZbb/7YJgHOzBgDWvL1fyR3a0VcppfopDQAhpLy2kcOnaqltaObm5zYA\nMDIjHoBwWxhzzhnI5gfnUN/cok09SoUADQAh4N/5JYzJTOCW5zZwoKTaY9/4zAEe66nxmsNHqVCh\nASDIvbapgB++scO1Hh8VTnVDM9+cmcM9c8YQH6X/BZQKVfrXH8SWbi3yuPkDbH3oSu3MVUoBGgCC\n1oGSKu59dRsAv/vy+VwyOo3jFfV681dKuWgACFJbjpQD8MC88Xx5yhBEhEGJMQEulVKqL9HHwSC1\nv6SKqPAwFl6SoyN6lFJeaQAIUoWn6xiSHENYmN78lVLeaQAIQo8s28PyvOMMSdaZuZRSvmkACDIV\ntU08vfoQAHfMGhng0iil+jLtBA4S9hbDwdJqCsqsnP1LFk1n+gjN3KmU8k0DQD+0fGcx6z8r4765\nYxjgmIbxhqc/ZfOR08wYmUqkLYxJQ5MCXEqlVF+nAaAfevyDfewvqSYhOpzvzx3Lsp3FbD5yGoC1\nB09x3fmDiI6wBbiUSqm+TgNAP1Ne28h+Rz6fP310gJfWHaG8tgmAmAgbd80exS0zsgNYQqVUf6EB\noJ9x5vB3Kq9t4sKcFEZmxPPw/Ak67FMp1WUaAPqZv607woj0OP56y1RKqxpIi49kRHp8oIullOqH\n/AoAIvIqMNaxmgSUG2MmeTnuMFAF2IFmY0yuP+cNVaeqGzhUWsOPrh5HTlocOWlxgS6SUqof8ysA\nGGO+6lwWkceAig4Ov9wYc9Kf84W6F9ceBiA3OzmwBVFKBYVuaQISK9nMDcDs7vg+1d6qvSU8+dEB\nAM4bnBjg0iilgkF3vQk8EzhhjNnvY78BVorIZhFZ1E3nDBnv5xVz6/MbAXjrOzN0iKdSqlt0WgMQ\nkZVAppddDxhj3nYs3wgs7uBrLjHGFIlIBvCBiOQbY1b7ON8iYBHAsGHDOite0DPGcMfLWwCYNSad\nycO0+Ucp1T06DQDGmDkd7ReRcOCLwJQOvqPI8W+JiPwDmAZ4DQDGmGeAZwByc3NNZ+ULNi0thnd2\nHGPO+IHERYWz5aiV1z9zQDSPfPG8AJdOKRVMuqMPYA6Qb4wp9LZTROKAMGNMlWN5LvDLbjhv0Glp\nMVz8248orqhn5ug0fjV/Al/6y1oAXr79QrKSdEIXpVT36Y4+gAW0af4RkSwRWeZYHQh8IiLbgQ3A\ne8aY97vhvEHn4/2lFFfUA7Bm/0ku+/0qAL41awSjMnSsv1Kqe/ldAzDG3Opl2zFgnmP5EDDR3/OE\ngpW7TxAVHsb/3jSFb7yw0bX9x9eMD2CplFLBSucD6COa7S18uKeEy8amc/m4DJ688QIArj1vUIBL\nppQKVpoKoo94ed0RjlfW86spEwC4fmIWI9PjtOlHKdVjNAD0AY3NLfx51UFmjExlzvgM1/Zzs/SF\nL6VUz9EmoD5geV4xJVUNfHPmCKyXqpVSqudpDSBAjDF8d8k23tl+DICctDhmjUkPcKmUUqFEawAB\n8sr6o66bf2JMBH/++mTN5a+U6lVaAwiAd7Yf48GleWSnxrLyvlmICDa9+SulepkGgF5W12jn/jd3\nAPD0zbmE27QSppQKDL379LKP8kuoabTz0sJpjM1MCHRxlFIhTANAL7K3GJ5YuY/hqbHMGJkW6OIo\npUKcBoBe9ObmQvaXVPPfc8dqm79SKuC0D6AHGWNY/1kZ2wvKeWR5PgDpCVFcPcHb9ApKKdW7NAD0\noKXbivjeq9td67PHZXDPFaOJ0I5fpVQfoAGgB+w7UUVFXRO/fGc3AM9/YyppcVGcN0RTOyil+g4N\nAD3g6idW0+KYy+z1Oy5ianZKYAuklFJeaADoRnuKK/m/1YdoMdbbvU98dZLe/JVSfZYGgG6SV1TB\ndX/6BIDRGfEsvfNi4qL08iql+i69Q3WTJz/cD8Bb35nB5GHJAS6NUkp1TgOAn5rsLXzpL2vZUVjB\ngqlD9eavlOo3dDyin1bvK2VHYQUAt16cHdjCKKXUGdAagB8On6xh4YubANj38DVEhms8VUr1H3rH\n8sN3l2wF4JaLhuvNXynV72gN4CzkFVVQUlXPjsIK7rtyDN+9YnSgi6SUUmdMA8AZ2FNcyZFTtdzx\n8mbAmsbx5unDA1wqpZQ6OxoAuuB0TSOPfbCXl9cd9dj+wjemkhwXGaBSKaWUfzQAdKDJ3sJDb+9i\n8Qbrxj8iLY7MxGiun5jF7HEZZAyIDnAJlVLq7GkA6MAzqw+xeMNRZoxMZfa4DBZekoOI5vFXSgUH\nDQA+5B+v5PEP9jFpaBIvL7yQMJ3ARSkVZHTsohfbC8r56tPrGBAdzvO3TtWbv1IqKGkAaKOh2c73\nXt1GfFQ4r98xQzt5lVJBS5uA2liyoYBDJ2t4/htTGZURH+jiKKVUj/GrBiAik0RknYhsE5FNIjLN\nx3FXi8heETkgIvf7c86eYoxh2c5ifrM8n4tGpHLZmPRAF0kppXqUvzWAR4FfGGOWi8g8x/pl7geI\niA14CrgSKAQ2isg/jTG7/Ty33/afqOKNzYWMSI8jKTaS77yyBYCfXX+OjvZRSgU9fwOAAQY4lhOB\nY16OmQYcMMYcAhCRJcB8IGABoNnewv1v7eSNzYUe2wclRrP4m9PJTosLUMmUUqr3+BsA7gVWiMjv\nsZqTZng5ZjBQ4LZeCFzo53n98sLaw7yxuZAvTR7CTdOHsb2gnMr6Zm6aPpwU7fRVSoWITgOAiKwE\nMr3segC4AvieMeZNEbkB+Cswx58CicgiYBHAsGHD/PkqDw3Ndmoa7Pxx5T5eWneEmaPT+N2Xzycs\nTLhAJ3FRSoWgTgOAMcbnDV1E/gbc41h9HXjWy2FFwFC39SGObb7O9wzwDEBubq7prHwdaba3sPbg\nKRZvOMryvOOu7Z+bmMXD8yfo+H6lVEjztwnoGDALWAXMBvZ7OWYjMFpEcrBu/AuAr/l53g4ZY1ix\n6zi/XpbP0bJaAL5wwWAGJUZz2dgMpuWk9OTplVKqX/A3AHwT+KOIhAP1OJpuRCQLeNYYM88Y0ywi\ndwErABvwnDFml5/n9amirolbntvAtoJyhqbEcOuMbD43MYspw7WZRyml3PkVAIwxnwBTvGw/Bsxz\nW18GLPPnXF01IDqc4amxLJg6lC9PGUK4TV92Vkopb4LuTWAR4Y8LLgh0MZRSqs/Tx2OllApRGgCU\nUipEaQBQSqkQpQFAKaVClAYApZQKURoAlFIqRGkAUEqpEKUBQCmlQpQY41e+tR4lIqXAkbP8eBpw\nshuLE0z02nin18U3vTa+9bVrM9wY06UpDft0APCHiGwyxuQGuhx9kV4b7/S6+KbXxrf+fG20CUgp\npUKUBgCllApRwRwAngl0AfowvTbe6XXxTa+Nb/322gRtH4BSSqmOBXMNQCmlVAeCLgCIyNUisldE\nDojI/YEuT28TkaEi8m8R2S0iu0TkHsf2FBH5QET2O/5NdvvMjx3Xa6+IXBW40vc8EbGJyFYRedex\nrtcFEJEkEXlDRPJFZI+IXKTXxiIi33P8LeWJyGIRiQ6aa2OMCZofrCknDwIjgEhgO3BOoMvVy9dg\nEDDZsZwA7APOAR4F7ndsvx/4rWP5HMd1igJyHNfPFujfowevz33A34F3Het6Xazf90XgdsdyJJCk\n18YADAY+A2Ic668BtwbLtQm2GsA04IAx5pAxphFYAswPcJl6lTGm2BizxbFcBezB+k88H+uPHMe/\nn3cszweWGGMajDGfAQewrmPQEZEhwLXAs26b9bqIJAKXAn8FMMY0GmPK0WvjFA7EOOY+jwWOESTX\nJtgCwGCgwG290LEtJIlINnABsB4YaIwpduw6Dgx0LIfSNXsC+CHQ4rZNr4v1pFoKPO9oHntWROLQ\na4Mxpgj4PXAUKAYqjDH/IkiuTbAFAOUgIvHAm8C9xphK933GqquG1PAvEbkOKDHGbPZ1TCheF4dw\nYDLwF2PMBUANVrOGS6heG0fb/nysIJkFxInITe7H9OdrE2wBoAgY6rY+xLEtpIhIBNbN/xVjzFuO\nzSdEZJBj/yCgxLE9VK7ZxcD1InIYq2lwtoi8jF4XsJ5SC40x6x3rb2AFBL02MAf4zBhTaoxpAt4C\nZhAk1ybYAsBGYLSI5IhIJLAA+GeAy9SrRESw2nL3GGMed9v1T+AWx/ItwNtu2xeISJSI5ACjgQ29\nVd7eYoz5sTFmiDEmG+v/xUfGmJsI8esCYIw5DhSIyFjHpiuA3ei1AavpZ7qIxDr+tq7A6lcLimsT\nHugCdCdjTLOI3AWswBoR9JwxZleAi9XbLgZuBnaKyDbHtp8AvwFeE5GFWBlWbwAwxuwSkdew/uCb\ngTuNMfbeL3bA6HWx3A284nhwOgR8A+sBMaSvjTFmvYi8AWzB+l23Yr35G08QXBt9E1gppUJUsDUB\nKaWU6iINAEopFaI0ACilVIjSAKCUUiFKA4BSSoUoDQBKKRWiNAAopVSI0gCglFIh6v8D7U3g8XH4\n5bgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe722a21f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_smoothed(infolosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00240157\n",
      "GENERATED:  my name is randy marsh . this is my special battery protocol .\n",
      "0.525611\n",
      "GENERATED:  my name is butters , and i ' m _UNK_ ' . i had a guy invited me to my\n",
      "0.379213\n",
      "GENERATED:  my name is bubbe marsh , and i ' m pretty special and small and jewish . mysterion , don\n",
      "0.384388\n",
      "GENERATED:  my name . . . used to be . . . i know joseph smith . oh god , what\n",
      "0.0999485\n",
      "GENERATED:  oh , jesus ! ah you crazy , it ' s the most unbelievable thing !\n",
      "0.00222513\n",
      "GENERATED:  jimmy marsh .\n",
      "0.00657407\n",
      "GENERATED:  satan . your new priest friend has something to remember with his name .\n",
      "0.00066202\n",
      "GENERATED:  butters ?\n",
      "0.607849\n",
      "GENERATED:  it ' s my darling mackey . i ' m just making it a holiday special . the answer is\n",
      "0.0346378\n",
      "GENERATED:  my name is clyde frog . i ' m special olympics grampa .\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    name_id = 439\n",
    "    name_batch =  phrase_to_matrix([[\"Hello\", \"Hello\", \"What is your name ? \"]], max_len=20)\n",
    "    #att_seqs = attention_discriminator.get_attention_fake(name_batch, [name_id], 20)\n",
    "    gen_answer, gen_reward = test_discr_fn(name_batch, [name_id], 20)\n",
    "    gen_answer = ' '.join(phrase_from_idx(gen_answer[0], crop_by_eos=True))\n",
    "    print gen_reward[0, 1]\n",
    "    print \"GENERATED: \", gen_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00116132\n",
      "shhh . _EOS_ shut up , cartman ! just face it . we lost this one . _EOS_ kenny .\n",
      "REAL:  ( okay . )\n",
      "GENERATED:  ( you . . . really did don ' t ! )\n",
      "0.0753187\n",
      "you ' re the best player at our school , dude . you ' ll make the team for sure\n",
      "REAL:  all students trying out for the all - state team to center court !\n",
      "GENERATED:  correct me . if you ' re a man , then we ' re on the side of your team\n",
      "0.708377\n",
      "okay , people . i know we all want to get down to the docks for the halloween haunt ,\n",
      "REAL:  yes , we know it ' s horrible . it ' s probably best you not look at it .\n",
      "GENERATED:  come on , general disarray , to start the race ! it ' s the extreme plague .\n",
      "0.00927394\n",
      "well , apparently , he thinks he ' s a vietnamese prostitute named ming li . _EOS_ . . oh\n",
      "REAL:  what ?\n",
      "GENERATED:  please don ' t .\n",
      "1.42587e-05\n",
      "_EOS_ _EOS_ _EOS_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_\n",
      "REAL:  \n",
      "GENERATED:  \n",
      "0.408761\n",
      "please , ma . i don ' t think kenny has anywhere else to be tonight . _EOS_ oh ,\n",
      "REAL:  come on , ike !\n",
      "GENERATED:  come on , dude ! we can ' t just stand here ! we have little sinned , and don\n",
      "0.0211801\n",
      "that was real cool , kids . hey , kyle , there ' s a different controller in my car\n",
      "REAL:  really ? that ' d be sweet .\n",
      "GENERATED:  it ' s a _UNK_ . it ' s a\n",
      "0.000119493\n",
      "_UNK_ chewbacca ? _EOS_ ms . struthers , don ' t forget the gift we gave you : the child\n",
      "REAL:  ms . struthers . you helped so many people , and you ' ve taught us that helping people is\n",
      "GENERATED:  what ?\n",
      "0.23791\n",
      ". . . ' scuse me . . . am i being fired ? _EOS_ jared , it ' s\n",
      "REAL:  well , your new slogan , for instance .\n",
      "GENERATED:  yes , but it sounds like people like you , understand ? they ' re your lawyers , haha .\n",
      "0.00510181\n",
      "okay kids , everyone in the pool ! _EOS_ nuh - uh . _EOS_ just jump in . _EOS_ _PAD_\n",
      "REAL:  i don ' t wanna .\n",
      "GENERATED:  good ! you ' re a spring chicken !\n",
      "0.0644618\n",
      "dude , what do you mean \" we don ' t have a coach . \" ? _EOS_ look ,\n",
      "REAL:  i ' m sorry . my dad is taking professional sarcastaball really seriously .\n",
      "GENERATED:  i ' m glad we had water , another methane replaced .\n",
      "4.58632e-11\n",
      "new , from _UNK_ , it ' s crank prank time phone ! _EOS_ i just dial a random number\n",
      "REAL:  \n",
      "GENERATED:  \n",
      "0.00284332\n",
      "dude , no way . _EOS_ yeah , i hate you , but i ' m not going to help\n",
      "REAL:  principal victoria , we are a devout catholic family ! do you mind telling me why my daughter now thinks\n",
      "GENERATED:  wait a minute . what happened to me ?\n",
      "0.00661852\n",
      "yeah , it ' s cool . _EOS_ why sure , that sounds hellafun . _EOS_ hahahahahaha . . .\n",
      "REAL:  yeah .\n",
      "GENERATED:  yeah , that ' d be sweet .\n",
      "0.0134632\n",
      "yeah ! ! _EOS_ hey mr . reiner , why don ' t you butt out ! _EOS_ i '\n",
      "REAL:  i don ' t _UNK_ you anymore , asshole !\n",
      "GENERATED:  everyone thinks i have diarrhea and turds , asshole !\n",
      "0.000634495\n",
      "( oh boy . ) _EOS_ oh , it makes me sick ! those damned psychologists prescribe all kinds of\n",
      "REAL:  no , not at all .\n",
      "GENERATED:  . . . wa bu - whoawhoa _UNK_ ? ?\n",
      "3.63163e-05\n",
      "why are you looking at me ? _EOS_ why are you looking at me ? _EOS_ why isn ' t\n",
      "REAL:  hey , fuck you .\n",
      "GENERATED:  goddamnit , stop what you ' re talking about !\n",
      "0.0291184\n",
      "hello ? _EOS_ how ' s the clubhouse coming , stan ? _EOS_ we ' re working on it .\n",
      "REAL:  well , i just thought i ' d tell you that me and kenny have finished our clubhouse , and\n",
      "GENERATED:  you ' re not gonna don ' t take us back , chef .\n",
      "0.432367\n",
      "yes , what is this about ? _EOS_ we need your expertise , sir . _EOS_ have you ever heard\n",
      "REAL:  another species ? what are you talking about ?\n",
      "GENERATED:  could not make you with the awwww or some kind of paranormal matter ?\n",
      "1.6011e-09\n",
      "yay ! _EOS_ but does that mean you aren ' t baptized ? _EOS_ no . i ' m jewish\n",
      "REAL:  yay ! yay !\n",
      "GENERATED:  yay !\n",
      "0.461863\n",
      "i will find sources to concrete . _EOS_ using the wood that krishna cut down as a beaver , jesus\n",
      "REAL:  meanwhile , in the ocean depths , seaman seeks out water to mix with the concrete .\n",
      "GENERATED:  and now , the enhanced version - of the stem cells , using recycled plastic , and built the meth\n",
      "5.92615e-08\n",
      "there . i got rid of the problem for you . now there ' s no conflict . _EOS_ no\n",
      "REAL:  wagghh . . !\n",
      "GENERATED:  no !\n",
      "0.0482213\n",
      "yes , your two hundred american dollars will last _EOS_ wow , what a great country . everybody ' s\n",
      "REAL:  hello , girls . i ' m the easter bunny .\n",
      "GENERATED:  we ' ve been here for many years putting these calves together from the world .\n",
      "0.291833\n",
      "i looked through your stupid book ! it ' s five hundred and forty pages of ripping on wendy and\n",
      "REAL:  you didn ' t read the rest , dude .\n",
      "GENERATED:  page is banned in the paper starring you .\n",
      "0.000319682\n",
      "oh , uh . . . _EOS_ hahaha , and they ' re probably just realizing that now ! quick\n",
      "REAL:  look ! look ! i ' ve made the news ! i - i ' ve _UNK_ havoc !\n",
      "GENERATED:  ugh . oh , okay .\n",
      "0.0727929\n",
      "uh , it ' s okay . we know the owner . _EOS_ oh , really ? let ' s\n",
      "REAL:  hey gino , these kids say they know you .\n",
      "GENERATED:  i only have two years going to people once and for all !\n",
      "0.00067849\n",
      "i would like to take this opportunity to explain why farts are funny and queefs are not . men have\n",
      "REAL:  for instance , we have the sneezing unicorn .\n",
      "GENERATED:  may i have your wife and _UNK_ , please ?\n",
      "0.000333005\n",
      "come back here , dammit ! _EOS_ whoa , wait ! _EOS_ just a little higher . _EOS_ _PAD_ _PAD_\n",
      "REAL:  mom ! dad !\n",
      "GENERATED:  all right , all right !\n",
      "0.00497748\n",
      "yeah ! _EOS_ they sure are getting to know each other . _EOS_ i ' ts amazing ! you know\n",
      "REAL:  his friend lives on a farm ?\n",
      "GENERATED:  yes , me too .\n",
      "0.000291604\n",
      "nice . _EOS_ nissse _EOS_ i know my actions were wrong , but i cannot be fully to blame .\n",
      "REAL:  ohhhh .\n",
      "GENERATED:  what idea ? !\n",
      "0.000155418\n",
      "and now , time for _EOS_ m - whoa , i ' m scared . _EOS_ well , be sure\n",
      "REAL:  mm - good night .\n",
      "GENERATED:  spare a box of purple _UNK_ .\n",
      "0.00164991\n",
      "_UNK_ , oooh ! _EOS_ ( yaaaaah ! ) _EOS_ ( aaaaaah ! ) _EOS_ _PAD_ _PAD_ _PAD_ _PAD_ _PAD_\n",
      "REAL:  today , on dr . phil . the tragic story of a little boy whose mother constantly tries to fuck\n",
      "GENERATED:  make it come out the other bus !\n"
     ]
    }
   ],
   "source": [
    "gen_answers, gen_rewards = test_discr_fn(one_batch[0], one_batch[2], 20)\n",
    "gen_answers = [' '.join(phrase_from_idx(gen_answers[j], crop_by_eos=True)) for j in range(len(one_batch[1]))]\n",
    "answers =  [' '.join(phrase_from_idx(one_batch[1][j], crop_by_eos=True)) for j in range(len(one_batch[1]))]\n",
    "discr_reward = gen_rewards[:, 1]\n",
    "#att_seqs = attention_discriminator.get_attention_real(one_batch[0], one_batch[1])\n",
    "for i in range(one_batch[0].shape[0]):\n",
    "    print discr_reward[i]\n",
    "    print ' '.join(phrase_from_idx(one_batch[0][i]))\n",
    "    print \"REAL: \", answers[i]\n",
    "    print \"GENERATED: \", gen_answers[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.learning.generic import get_values_for_actions\n",
    "\n",
    "class pg_trainer:    \n",
    "    \n",
    "    rewards = conv_discriminator.output_on_fake[:, 1]\n",
    "    baseline = conv_discriminator.output_on_greedy_fake[:, 1]\n",
    "\n",
    "    advantage = rewards - baseline\n",
    "\n",
    "    policy = get_values_for_actions(generator.probs, generator.out)\n",
    "    #policy = T.maximum(policy, 1e-10)\n",
    "    log_policy = T.log(policy)\n",
    "    neg_entropy = (generator.probs * T.log(generator.probs)).sum(axis=-1)\n",
    "\n",
    "    loss = ((-log_policy * advantage[:,None] + 0.01 * neg_entropy) * generator.mask).sum() / generator.mask.sum()\n",
    "\n",
    "    grads = T.grad(loss, generator.weights)\n",
    "    grads = lasagne.updates.total_norm_constraint(grads, 10)\n",
    "\n",
    "    updates = generator.auto_updates + generator.greedy_auto_updates\n",
    "    updates += lasagne.updates.adam(grads, generator.weights, learning_rate=1e-5) \n",
    "\n",
    "    train_step = theano.function([encoder.input_phrase, person_id_var, generator.n_steps], loss,\n",
    "                                 updates=updates,\n",
    "                                 allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pg_train_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bx, by, respondent in generate_data(data_rows, speakers_list=speakers_list, n_iter=100, max_len=seq_len):\n",
    "    err = pg_trainer.train_step(bx, respondent, 20)\n",
    "    pg_train_loss.append(err)\n",
    "    print(\"%.5f\"%err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcb42733b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_smoothed(pg_train_loss, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_train_errors = []\n",
    "discr_train_errors = []\n",
    "info_train_errors = []\n",
    "llh_train_errors = []\n",
    "accuracies_in_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 52428800 bytes of device memory (CNMEM_STATUS_OUT_OF_MEMORY).\nApply node that caused the error: GpuContiguous(GpuDimShuffle{0,3,1,2}.0)\nToposort index: 539\nInputs types: [CudaNdarrayType(float32, 4D)]\nInputs shapes: [(32, 1024, 20, 20)]\nInputs strides: [(409600, 1, 20480, 1024)]\nInputs values: ['not shown']\nInputs type_num: ['']\nOutputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]\n\nDebugprint of the apply node: \nGpuContiguous [id A] <CudaNdarrayType(float32, 4D)> ''   \n |GpuDimShuffle{0,3,1,2} [id B] <CudaNdarrayType(float32, 4D)> ''   \n   |GpuJoin [id C] <CudaNdarrayType(float32, 4D)> ''   \n     |TensorConstant{3} [id D] <TensorType(int8, scalar)>\n     |GpuReshape{4} [id E] <CudaNdarrayType(float32, 4D)> ''   \n     | |GpuAlloc [id F] <CudaNdarrayType(float32, 4D)> ''   \n     | | |GpuDimShuffle{0,1,x,2} [id G] <CudaNdarrayType(float32, (False, False, True, False))> ''   \n     | | | |GpuReshape{3} [id H] <CudaNdarrayType(float32, 3D)> ''   \n     | | |   |GpuAdvancedSubtensor1 [id I] <CudaNdarrayType(float32, matrix)> ''   \n     | | |   | |W [id J] <CudaNdarrayType(float32, matrix)>\n     | | |   | |Elemwise{Cast{int64}} [id K] <TensorType(int64, vector)> ''   \n     | | |   |   |Reshape{1} [id L] <TensorType(int32, vector)> ''   \n     | | |   |     |encoder phrase tokens [id M] <TensorType(int32, matrix)>\n     | | |   |     |TensorConstant{(1,) of -1} [id N] <TensorType(int64, (True,))>\n     | | |   |MakeVector{dtype='int64'} [id O] <TensorType(int64, vector)> ''   \n     | | |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n     | | |     | |encoder phrase tokens [id M] <TensorType(int32, matrix)>\n     | | |     |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n     | | |     | |encoder phrase tokens [id M] <TensorType(int32, matrix)>\n     | | |     |Shape_i{1} [id R] <TensorType(int64, scalar)> ''   \n     | | |       |W [id J] <CudaNdarrayType(float32, matrix)>\n     | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n     | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n     | | |TensorConstant{20} [id S] <TensorType(int8, scalar)>\n     | | |Shape_i{1} [id R] <TensorType(int64, scalar)> ''   \n     | |TensorConstant{[ -1  20  20 512]} [id T] <TensorType(int64, vector)>\n     |GpuReshape{4} [id U] <CudaNdarrayType(float32, 4D)> ''   \n       |GpuAlloc [id V] <CudaNdarrayType(float32, 4D)> ''   \n       | |GpuDimShuffle{0,1,x,2} [id W] <CudaNdarrayType(float32, (False, False, True, False))> ''   \n       | | |GpuReshape{3} [id X] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |GpuAdvancedSubtensor1 [id Y] <CudaNdarrayType(float32, matrix)> ''   \n       | |   | |W [id Z] <CudaNdarrayType(float32, matrix)>\n       | |   | |Elemwise{Cast{int64}} [id BA] <TensorType(int64, vector)> ''   \n       | |   |   |Reshape{1} [id BB] <TensorType(int32, vector)> ''   \n       | |   |     |InplaceDimShuffle{1,0} [id BC] <TensorType(int32, matrix)> ''   \n       | |   |     | |Subtensor{int64:int64:int8} [id BD] <TensorType(int32, matrix)> ''   \n       | |   |     |   |forall_inplace,gpu,scan_fn&scan_fn}.3 [id BE] <TensorType(int32, matrix)> ''   \n       | |   |     |   | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | |GpuIncSubtensor{InplaceSet;:int64:} [id BG] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | |GpuAllocEmpty [id BH] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id BI] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i7 + i2), (i8 + i2), i4, i5), i4, (i7 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i7 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i7 + i2), (i8 + i2), i4, i5), i4, (i7 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i7 + i2), i4))) + i2), i6))}} [id BJ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6), i5), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6))}} [id BK] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{le,no_inplace} [id BL] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{sub,no_inplace} [id BM] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}} [id BN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{le,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i4, i2), i4, i2))}} [id BP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{lt,no_inplace} [id BQ] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |Elemwise{Identity} [id BR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | | | | | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id BT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | |Elemwise{sub,no_inplace} [id BV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id BW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id BZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id BW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Identity} [id BR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |Elemwise{Identity} [id BR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i4, i2), i4, i2))}} [id BP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id BT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{sub,no_inplace} [id BV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}} [id CB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |   |Elemwise{le,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |   |TensorConstant{0} [id CC] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |   |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id BT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |   |Elemwise{sub,no_inplace} [id BV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}} [id BN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id BZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{add,no_inplace} [id CD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id BW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}} [id CB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{sub,no_inplace} [id CE] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i1, i2, (i3 - i4), i5, i6, i7, i8), i2, i9), i2, i10), i9), i9, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i1, i2, (i3 - i4), i5, i6, i7, i8), i2, i9), i2, i10))) - i11) // i12)}} [id CG] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6), i5), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6))}} [id BK] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{le,no_inplace} [id BL] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{add,no_inplace} [id CD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}} [id BN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{sub,no_inplace} [id BM] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{sub,no_inplace} [id CH] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |TensorConstant{-2} [id CI] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id BZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id CK] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{lt,no_inplace} [id CL] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id CM] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{le,no_inplace} [id CN] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{sub,no_inplace} [id CO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{add,no_inplace} [id CQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id CR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   |Elemwise{le,no_inplace} [id CS] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i5, i6), i5, i6))}} [id CT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | |Elemwise{lt,no_inplace} [id BQ] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | | |Elemwise{lt,no_inplace} [id BQ] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | | | |Elemwise{Identity} [id BR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id CW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | | |Elemwise{add,no_inplace} [id CX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | |   |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | |   |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | |Elemwise{Identity} [id BR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | |Elemwise{sub,no_inplace} [id CY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id CW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id CW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id CZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id CX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10)}} [id DA] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id CQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id CR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |Elemwise{le,no_inplace} [id CS] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id CZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i5, i6), i5, i6))}} [id CT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | |   |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id CW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |TensorConstant{0} [id CC] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id CM] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{sub,no_inplace} [id CE] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5), i3), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5))) - i6) // i7)}} [id DB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id CK] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   |Elemwise{lt,no_inplace} [id DC] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | |   | |Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}} [id DD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   | | |Elemwise{le,no_inplace} [id CN] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | |   | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |   | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10)}} [id DA] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   | | |Elemwise{sub,no_inplace} [id CO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   | | |Elemwise{sub,no_inplace} [id CH] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   | | |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |   |Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}} [id DD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |   |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |   |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |TensorConstant{1024} [id DE] <TensorType(int64, scalar)>\n       | |   |     |   | | |GpuFromHost [id DF] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | |Rebroadcast{0} [id DG] <TensorType(float32, 3D)> ''   \n       | |   |     |   | | |   |Alloc [id DH] <TensorType(float32, (True, False, False))> ''   \n       | |   |     |   | | |     |TensorConstant{0.0} [id DI] <TensorType(float32, scalar)>\n       | |   |     |   | | |     |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     |TensorConstant{1024} [id DJ] <TensorType(int16, scalar)>\n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |GpuIncSubtensor{InplaceSet;:int64:} [id DL] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | |GpuAllocEmpty [id DM] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}} [id DN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |Elemwise{Composite{((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i8, i9, i3), i4, i5), i3, i6, i7), i4, i6), i4, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i6), i4), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i8, i9, i3), i4, i5), i3, i6, i7), i4, i6), i4, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i6), i4), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i4))) + i7)}} [id DO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | |Elemwise{lt,no_inplace} [id CL] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id CM] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |Elemwise{add,no_inplace} [id DP] <TensorType(int32, scalar)> ''   \n       | |   |     |   | | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{1} [id DQ] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |Elemwise{lt,no_inplace} [id DC] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | |Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}} [id DD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |TensorConstant{1024} [id DE] <TensorType(int64, scalar)>\n       | |   |     |   | | |GpuFromHost [id DF] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |IncSubtensor{InplaceSet;:int64:} [id DR] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | |AllocEmpty{dtype='int32'} [id DS] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}} [id DN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |Rebroadcast{0} [id DT] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | | |Alloc [id DU] <TensorType(int32, row)> ''   \n       | |   |     |   | | |   |TensorConstant{(1, 1) of 36069} [id DV] <TensorType(int32, (True, True))>\n       | |   |     |   | | |   |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | |   |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |IncSubtensor{InplaceSet;:int64:} [id DW] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | |AllocEmpty{dtype='int32'} [id DX] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}} [id DY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |Elemwise{Composite{((i0 - Switch(LT(i1, i2), i1, i2)) + i1)}} [id DZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |Elemwise{add,no_inplace} [id DP] <TensorType(int32, scalar)> ''   \n       | |   |     |   | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |Rebroadcast{0} [id DT] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |GpuIncSubtensor{InplaceSet;:int64:} [id EA] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | |GpuAllocEmpty [id EB] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}} [id DY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |TensorConstant{36071} [id EC] <TensorType(int64, scalar)>\n       | |   |     |   | | |GpuFromHost [id ED] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | |Rebroadcast{0} [id EE] <TensorType(float32, 3D)> ''   \n       | |   |     |   | | |   |Alloc [id EF] <TensorType(float32, (True, False, False))> ''   \n       | |   |     |   | | |     |TensorConstant{0.0} [id DI] <TensorType(float32, scalar)>\n       | |   |     |   | | |     |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     |TensorConstant{36071} [id EG] <TensorType(int32, scalar)>\n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |GpuIncSubtensor{InplaceSet;:int64:} [id EH] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | |GpuAllocEmpty [id EI] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |TensorConstant{1024} [id DE] <TensorType(int64, scalar)>\n       | |   |     |   | | |GpuFromHost [id EJ] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | | |Alloc [id DH] <TensorType(float32, (True, False, False))> ''   \n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |DeepCopyOp [id EK] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | |GpuIncSubtensor{InplaceSet;:int64:} [id EH] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | |IncSubtensor{InplaceSet;:int64:} [id EL] <TensorType(int32, row)> ''   \n       | |   |     |   | | |AllocEmpty{dtype='int32'} [id EM] <TensorType(int32, row)> ''   \n       | |   |     |   | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |TensorConstant{(1, 1) of 36069} [id DV] <TensorType(int32, (True, True))>\n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |DeepCopyOp [id EN] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | |IncSubtensor{InplaceSet;:int64:} [id DW] <TensorType(int32, matrix)> ''   \n       | |   |     |   | |<RandomStateType> [id EO] <RandomStateType>\n       | |   |     |   | |context embedding.W [id EP] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |decoder intermediate.W [id EQ] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |decoder next word probas.W [id ER] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |GpuDot22 [id ES] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | |GpuAdvancedSubtensor1 [id ET] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | |persona_based.emb.W [id EU] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | |Elemwise{Cast{int64}} [id EV] <TensorType(int64, vector)> ''   \n       | |   |     |   | | |   |personality idxs [id EW] <TensorType(int32, vector)>\n       | |   |     |   | | |GpuJoin [id EX] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | |   |decoder_lstm.W_persona_based.each_tick_to_ingate [id EY] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_persona_based.each_tick_to_forgetgate [id EZ] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_persona_based.each_tick_to_cell [id FA] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_persona_based.each_tick_to_outgate [id FB] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |GpuDot22 [id FC] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | |GpuSubtensor{int64} [id FD] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | |forall_inplace,gpu,scan_fn}.1 [id FE] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | |Elemwise{maximum,no_inplace} [id FF] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |Elemwise{Composite{minimum(maximum(maximum((i0 - i1), (i0 - i1)), ((i2 + i3) - i1)), i4)}} [id FG] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id FH] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{add,no_inplace} [id FI] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id FJ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{lt,no_inplace} [id FK] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id FL] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{le,no_inplace} [id FM] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |Elemwise{sub,no_inplace} [id FN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id FO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |Elemwise{add,no_inplace} [id FP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id FQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   |Elemwise{le,no_inplace} [id FR] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id FS] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | | |Elemwise{sub,no_inplace} [id FT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id FU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |     |TensorConstant{0} [id CC] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |   | |     |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id FU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id FV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |   | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11)}} [id FW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id FP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id FQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{le,no_inplace} [id FR] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id FV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id FS] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{sub,no_inplace} [id FX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | |   | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id FU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id FO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id FO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |TensorConstant{0} [id CC] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id FL] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{add,no_inplace} [id FY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(i0, (i1 + i2), i1)}} [id FZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{lt,no_inplace} [id GA] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT((i0 - i1), i2), i3, Switch(GE((i0 - i1), i4), (i5 + i0), Switch(LE(i4, i2), (i5 + i0), i0)))}} [id GB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id GC] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | |Elemwise{add,no_inplace} [id FY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |Elemwise{sub,no_inplace} [id GD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |TensorConstant{-2} [id CI] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{sub,no_inplace} [id GE] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{add,no_inplace} [id FY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id GC] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |Elemwise{Composite{Switch(LT((i0 - i1), i2), i3, Switch(GE((i0 - i1), i4), (i5 + i0), Switch(LE(i4, i2), (i5 + i0), i0)))}} [id GB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{add,no_inplace} [id FY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | |GpuSubtensor{int64:int64:int8} [id GF] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | |GpuElemwise{add,no_inplace} [id GG] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | |GpuReshape{3} [id GH] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | | |GpuDot22 [id GI] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | | | | |GpuReshape{2} [id GJ] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | | | | | |GpuDimShuffle{1,0,2} [id GK] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | | | | | |GpuReshape{3} [id GL] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | | | | |   |GpuAdvancedSubtensor1 [id GM] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | | | | | |   | |context embedding.W [id EP] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | | | |   | |Elemwise{Cast{int64}} [id K] <TensorType(int64, vector)> ''   \n       | |   |     |   | | | | | | | | | |   |MakeVector{dtype='int64'} [id GN] <TensorType(int64, vector)> ''   \n       | |   |     |   | | | | | | | | | |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |     |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |     |Shape_i{1} [id GO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |       |context embedding.W [id EP] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | | | |MakeVector{dtype='int64'} [id GP] <TensorType(int64, vector)> ''   \n       | |   |     |   | | | | | | | | |   |Elemwise{mul,no_inplace} [id GQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |   | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |   | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |   |Shape_i{1} [id GO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |GpuJoin [id GR] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | | | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |   |encoder_lstm.W_in_to_ingate [id GS] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | |   |encoder_lstm.W_in_to_forgetgate [id GT] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | |   |encoder_lstm.W_in_to_cell [id GU] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | |   |encoder_lstm.W_in_to_outgate [id GV] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | |MakeVector{dtype='int64'} [id GW] <TensorType(int64, vector)> ''   \n       | |   |     |   | | | | | | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |   |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |   |Elemwise{add,no_inplace} [id GX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |     |Shape_i{1} [id GY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |     | |encoder_lstm.W_in_to_ingate [id GS] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | |     |Shape_i{1} [id GZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |     | |encoder_lstm.W_in_to_forgetgate [id GT] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | |     |Shape_i{1} [id HA] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |     | |encoder_lstm.W_in_to_cell [id GU] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | |     |Shape_i{1} [id HB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |       |encoder_lstm.W_in_to_outgate [id GV] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | |GpuDimShuffle{x,x,0} [id HC] <CudaNdarrayType(float32, (True, True, False))> ''   \n       | |   |     |   | | | | | |   |GpuJoin [id HD] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | | | | | |     |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |     |encoder_lstm.b_ingate [id HE] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | | | | | |     |encoder_lstm.b_forgetgate [id HF] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | | | | | |     |encoder_lstm.b_cell [id HG] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | | | | | |     |encoder_lstm.b_outgate [id HH] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | | | | | |ScalarFromTensor [id HI] <int64> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}} [id HJ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |   |TensorConstant{0} [id CC] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |ScalarFromTensor [id HK] <int64> ''   \n       | |   |     |   | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |Constant{1} [id HL] <int8>\n       | |   |     |   | | | | |Subtensor{int64:int64:int8} [id HM] <TensorType(bool, (False, False, True))> ''   \n       | |   |     |   | | | | | |Elemwise{neq,no_inplace} [id HN] <TensorType(bool, (False, False, True))> ''   \n       | |   |     |   | | | | | | |InplaceDimShuffle{1,0,x} [id HO] <TensorType(int32, (False, False, True))> ''   \n       | |   |     |   | | | | | | | |encoder phrase tokens [id M] <TensorType(int32, matrix)>\n       | |   |     |   | | | | | | |TensorConstant{(1, 1, 1) of 36070} [id HP] <TensorType(int32, (True, True, True))>\n       | |   |     |   | | | | | |ScalarFromTensor [id HI] <int64> ''   \n       | |   |     |   | | | | | |ScalarFromTensor [id HK] <int64> ''   \n       | |   |     |   | | | | | |Constant{1} [id HL] <int8>\n       | |   |     |   | | | | |GpuIncSubtensor{InplaceSet;:int64:} [id HQ] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | |GpuAllocEmpty [id HR] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}} [id HS] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{Composite{((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}(i1, (i2 + i3), i4, i5), i4, i1, i5), i4), i6), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}(i1, (i2 + i3), i4, i5), i4, i1, i5), i4), i6)) + i3)}} [id HT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{maximum,no_inplace} [id FF] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{add,no_inplace} [id FI] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5), i3), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5))) - i6) // i7)}} [id HU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id FJ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{lt,no_inplace} [id HV] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(i0, i1, Switch(i2, i3, i4))}} [id HW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{le,no_inplace} [id FM] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}} [id HX] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |Elemwise{add,no_inplace} [id HY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11)}} [id FW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | |Elemwise{sub,no_inplace} [id FN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{sub,no_inplace} [id GD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{minimum,no_inplace} [id HZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |   |Elemwise{add,no_inplace} [id HY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(i0, i1, Switch(i2, i3, i4))}} [id HW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{add,no_inplace} [id FY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id FH] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Shape_i{1} [id IA] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |encoder_lstm.cell_init [id IB] <CudaNdarrayType(float32, row)>\n       | |   |     |   | | | | | |Rebroadcast{0} [id IC] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | |GpuDimShuffle{x,0,1} [id ID] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | | | | |   |GpuGer{inplace} [id IE] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | |     |GpuAlloc{memset_0=True} [id IF] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | |     | |CudaNdarrayConstant{0.0} [id IG] <CudaNdarrayType(float32, scalar)>\n       | |   |     |   | | | | | |     | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |     | |Shape_i{1} [id IA] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |     |TensorConstant{1.0} [id IH] <TensorType(float32, scalar)>\n       | |   |     |   | | | | | |     |GpuDimShuffle{0} [id II] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | | | | | |     | |GpuAlloc [id IJ] <CudaNdarrayType(float32, col)> ''   \n       | |   |     |   | | | | | |     |   |CudaNdarrayConstant{1.0} [id IK] <CudaNdarrayType(float32, scalar)>\n       | |   |     |   | | | | | |     |   |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |     |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |     |GpuDimShuffle{1} [id IL] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | | | | | |       |encoder_lstm.cell_init [id IB] <CudaNdarrayType(float32, row)>\n       | |   |     |   | | | | | |Constant{1} [id DK] <int64>\n       | |   |     |   | | | | |GpuIncSubtensor{InplaceSet;:int64:} [id IM] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | |GpuAllocEmpty [id IN] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id IO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{Composite{maximum(maximum(((i0 - Switch(i1, (i2 + i3), i2)) + i4), i5), maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8))) + i4), i5))}} [id IP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{maximum,no_inplace} [id FF] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{lt,no_inplace} [id GA] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT((i0 - i1), i2), i3, Switch(GE((i0 - i1), i4), (i5 + i0), Switch(LE(i4, i2), (i5 + i0), i0)))}} [id GB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{add,no_inplace} [id IQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{lt,no_inplace} [id FK] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id FL] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{sub,no_inplace} [id IR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{add,no_inplace} [id IQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{lt,no_inplace} [id HV] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(i0, i1, Switch(i2, i3, i4))}} [id HW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Shape_i{1} [id IS] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |encoder_lstm.hid_init [id IT] <CudaNdarrayType(float32, row)>\n       | |   |     |   | | | | | |Rebroadcast{0} [id IU] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | |GpuDimShuffle{x,0,1} [id IV] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | | | | |   |GpuGer{inplace} [id IW] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | |     |GpuAlloc{memset_0=True} [id IX] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | |     | |CudaNdarrayConstant{0.0} [id IG] <CudaNdarrayType(float32, scalar)>\n       | |   |     |   | | | | | |     | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |     | |Shape_i{1} [id IS] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |     |TensorConstant{1.0} [id IH] <TensorType(float32, scalar)>\n       | |   |     |   | | | | | |     |GpuDimShuffle{0} [id II] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | | | | | |     |GpuDimShuffle{1} [id IY] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | | | | | |       |encoder_lstm.hid_init [id IT] <CudaNdarrayType(float32, row)>\n       | |   |     |   | | | | | |Constant{1} [id DK] <int64>\n       | |   |     |   | | | | |GpuJoin [id IZ] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | |   |encoder_lstm.W_hid_to_ingate [id JA] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | |   |encoder_lstm.W_hid_to_forgetgate [id JB] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | |   |encoder_lstm.W_hid_to_cell [id JC] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | |   |encoder_lstm.W_hid_to_outgate [id JD] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | |ScalarFromTensor [id JE] <int64> ''   \n       | |   |     |   | | |   |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id JF] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     |Elemwise{Composite{Switch(i0, (i1 + i2), i1)}} [id FZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     |Elemwise{maximum,no_inplace} [id JG] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     | |Elemwise{Composite{minimum(maximum(maximum((i0 - i1), (i0 - i1)), ((i2 + i3) - i1)), i4)}} [id FG] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |     |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |     |Elemwise{Composite{maximum(maximum(((i0 - Switch(i1, (i2 + i3), i2)) + i4), i5), maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8))) + i4), i5))}} [id IP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |GpuJoin [id JH] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | |   |decoder_lstm.W_encoder_to_ingate [id JI] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_encoder_to_forgetgate [id JJ] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_encoder_to_cell [id JK] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_encoder_to_outgate [id JL] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |GpuJoin [id JM] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |decoder_lstm.W_emb_to_ingate [id JN] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_emb_to_forgetgate [id JO] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_emb_to_cell [id JP] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_emb_to_outgate [id JQ] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |GpuJoin [id JR] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |decoder_lstm.W_out_to_ingate [id JS] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_out_to_forgetgate [id JT] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_out_to_cell [id JU] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_out_to_outgate [id JV] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |GpuDimShuffle{x,0} [id JW] <CudaNdarrayType(float32, row)> ''   \n       | |   |     |   | | |GpuJoin [id JX] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | |   |decoder_lstm.b_to_ingate [id JY] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | |   |decoder_lstm.b_to_forgetgate [id JZ] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | |   |decoder_lstm.b_to_cell [id KA] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | |   |decoder_lstm.b_to_outgate [id KB] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | |GpuDimShuffle{x,x} [id KC] <CudaNdarrayType(float32, (True, True))> ''   \n       | |   |     |   | | |GpuFromHost [id KD] <CudaNdarrayType(float32, scalar)> ''   \n       | |   |     |   | |   |<TensorType(float32, scalar)> [id KE] <TensorType(float32, scalar)>\n       | |   |     |   | |GpuDimShuffle{x,0} [id KF] <CudaNdarrayType(float32, row)> ''   \n       | |   |     |   | | |decoder next word probas.b [id KG] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | |GpuDimShuffle{x,0} [id KH] <CudaNdarrayType(float32, row)> ''   \n       | |   |     |   |   |decoder intermediate.b [id KI] <CudaNdarrayType(float32, vector)>\n       | |   |     |   |ScalarFromTensor [id KJ] <int64> ''   \n       | |   |     |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id KK] <TensorType(int64, scalar)> ''   \n       | |   |     |   |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id KL] <TensorType(int64, scalar)> ''   \n       | |   |     |   |   | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   |   | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   |   |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   |   |Elemwise{maximum,no_inplace} [id KM] <TensorType(int64, scalar)> ''   \n       | |   |     |   |     |Elemwise{Composite{((i0 - Switch(LT(i1, i2), i1, i2)) + i1)}} [id DZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   |     |TensorConstant{2} [id KN] <TensorType(int8, scalar)>\n       | |   |     |   |ScalarFromTensor [id KO] <int64> ''   \n       | |   |     |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id KP] <TensorType(int64, scalar)> ''   \n       | |   |     |   |   |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   |   |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   |   |Elemwise{maximum,no_inplace} [id KM] <TensorType(int64, scalar)> ''   \n       | |   |     |   |Constant{1} [id HL] <int8>\n       | |   |     |TensorConstant{(1,) of -1} [id N] <TensorType(int64, (True,))>\n       | |   |MakeVector{dtype='int64'} [id KQ] <TensorType(int64, vector)> ''   \n       | |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |     |Elemwise{sub,no_inplace} [id KR] <TensorType(int64, scalar)> ''   \n       | |     | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |     | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id KL] <TensorType(int64, scalar)> ''   \n       | |     |Shape_i{1} [id KS] <TensorType(int64, scalar)> ''   \n       | |       |W [id Z] <CudaNdarrayType(float32, matrix)>\n       | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |Elemwise{sub,no_inplace} [id KR] <TensorType(int64, scalar)> ''   \n       | |TensorConstant{20} [id S] <TensorType(int8, scalar)>\n       | |Shape_i{1} [id KS] <TensorType(int64, scalar)> ''   \n       |TensorConstant{[ -1  20  20 512]} [id T] <TensorType(int64, vector)>\n\nInner graphs of the scan ops:\n\nforall_inplace,gpu,scan_fn&scan_fn}.3 [id BE] <TensorType(int32, matrix)> ''   \n >GpuElemwise{Composite{((tanh(i0) * scalar_sigmoid(i1)) + (i2 * scalar_sigmoid(i3)))},no_inplace} [id KT] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuSubtensor{::, int64:int64:} [id KU] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id KV] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, row)> [id KW] <CudaNdarrayType(float32, row)> -> [id JW]\n > | | |<CudaNdarrayType(float32, matrix)> [id KX] <CudaNdarrayType(float32, matrix)> -> [id FC]\n > | | |<CudaNdarrayType(float32, matrix)> [id KY] <CudaNdarrayType(float32, matrix)> -> [id ES]\n > | | |GpuGemm{inplace} [id KZ] <CudaNdarrayType(float32, matrix)> ''   \n > | |   |GpuDot22 [id LA] <CudaNdarrayType(float32, matrix)> ''   \n > | |   | |<CudaNdarrayType(float32, matrix)> [id LB] <CudaNdarrayType(float32, matrix)> -> [id DL]\n > | |   | |<CudaNdarrayType(float32, matrix)> [id LC] <CudaNdarrayType(float32, matrix)> -> [id JR]\n > | |   |TensorConstant{1.0} [id LD] <TensorType(float32, scalar)>\n > | |   |GpuAdvancedSubtensor1 [id LE] <CudaNdarrayType(float32, matrix)> ''   \n > | |   | |context embedding.W_copy0[cuda] [id LF] <CudaNdarrayType(float32, matrix)> -> [id EP]\n > | |   | |Elemwise{Cast{int64}} [id LG] <TensorType(int64, vector)> ''   \n > | |   |   |<TensorType(int32, vector)> [id LH] <TensorType(int32, vector)> -> [id DR]\n > | |   |<CudaNdarrayType(float32, matrix)> [id LI] <CudaNdarrayType(float32, matrix)> -> [id JM]\n > | |   |TensorConstant{1.0} [id LD] <TensorType(float32, scalar)>\n > | |Constant{2048} [id LJ] <int64>\n > | |Constant{3072} [id LK] <int64>\n > |GpuSubtensor{::, int64:int64:} [id LL] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id KV] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id LM] <int64>\n > | |Constant{1024} [id LN] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id LO] <CudaNdarrayType(float32, matrix)> -> [id BG]\n > |GpuSubtensor{::, int64:int64:} [id LP] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuElemwise{Add}[(0, 3)] [id KV] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{1024} [id LN] <int64>\n >   |Constant{2048} [id LJ] <int64>\n >GpuElemwise{Composite{tanh((scalar_sigmoid(i0) * i1))},no_inplace} [id LQ] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuSubtensor{::, int64:int64:} [id LR] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id KV] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{3072} [id LK] <int64>\n > | |Constant{4096} [id LS] <int64>\n > |GpuElemwise{Composite{((tanh(i0) * scalar_sigmoid(i1)) + (i2 * scalar_sigmoid(i3)))},no_inplace} [id KT] <CudaNdarrayType(float32, matrix)> ''   \n >ViewOp [id LT] <TensorType(int32, vector)> ''   \n > |Sum{axis=[1], acc_dtype=int64} [id LU] <TensorType(int32, vector)> ''   \n >   |Elemwise{gt,no_inplace} [id LV] <TensorType(bool, matrix)> ''   \n >     |RandomFunction{uniform}.1 [id LW] <TensorType(float32, col)> ''   \n >     | |<RandomStateType> [id LX] <RandomStateType> -> [id EO]\n >     | |MakeVector{dtype='int64'} [id LY] <TensorType(int64, vector)> ''   \n >     | | |Shape_i{0} [id LZ] <TensorType(int64, scalar)> ''   \n >     | | | |<CudaNdarrayType(float32, matrix)> [id LB] <CudaNdarrayType(float32, matrix)> -> [id DL]\n >     | | |TensorConstant{1} [id MA] <TensorType(int64, scalar)>\n >     | |TensorConstant{0.0} [id MB] <TensorType(float32, scalar)>\n >     | |TensorConstant{1.0} [id LD] <TensorType(float32, scalar)>\n >     |HostFromGpu [id MC] <TensorType(float32, matrix)> ''   \n >       |GpuSubtensor{::, :int64:} [id MD] <CudaNdarrayType(float32, matrix)> ''   \n >         |GpuCumsum{1} [id ME] <CudaNdarrayType(float32, matrix)> ''   \n >         | |GpuDimShuffle{0,1} [id MF] <CudaNdarrayType(float32, matrix)> ''   \n >         |   |GpuDnnSoftmax{tensor_format='bc01', mode='channel', algo='accurate'} [id MG] <CudaNdarrayType(float32, (False, False, True, True))> ''   \n >         |     |GpuContiguous [id MH] <CudaNdarrayType(float32, (False, False, True, True))> ''   \n >         |       |GpuDimShuffle{0,1,x,x} [id MI] <CudaNdarrayType(float32, (False, False, True, True))> ''   \n >         |         |GpuElemwise{Composite{((i0 + i1) / i2)}}[(0, 0)] [id MJ] <CudaNdarrayType(float32, matrix)> ''   \n >         |           |GpuDot22 [id MK] <CudaNdarrayType(float32, matrix)> ''   \n >         |           | |GpuElemwise{Composite{tanh((i0 + i1))}}[(0, 0)] [id ML] <CudaNdarrayType(float32, matrix)> ''   \n >         |           | | |GpuDot22 [id MM] <CudaNdarrayType(float32, matrix)> ''   \n >         |           | | | |GpuElemwise{Composite{tanh((scalar_sigmoid(i0) * i1))},no_inplace} [id LQ] <CudaNdarrayType(float32, matrix)> ''   \n >         |           | | | |decoder intermediate.W_copy0[cuda] [id MN] <CudaNdarrayType(float32, matrix)> -> [id EQ]\n >         |           | | |<CudaNdarrayType(float32, row)> [id MO] <CudaNdarrayType(float32, row)> -> [id KH]\n >         |           | |decoder next word probas.W_copy0[cuda] [id MP] <CudaNdarrayType(float32, matrix)> -> [id ER]\n >         |           |<CudaNdarrayType(float32, row)> [id MQ] <CudaNdarrayType(float32, row)> -> [id KF]\n >         |           |<CudaNdarrayType(float32, (True, True))> [id MR] <CudaNdarrayType(float32, (True, True))> -> [id KC]\n >         |Constant{-1} [id MS] <int64>\n >Sum{axis=[1], acc_dtype=int64} [id LU] <TensorType(int32, vector)> ''   \n >GpuDimShuffle{0,1} [id MF] <CudaNdarrayType(float32, matrix)> ''   \n >GpuElemwise{Composite{((tanh(i0) * scalar_sigmoid(i1)) + (i2 * scalar_sigmoid(i3)))},no_inplace} [id MT] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuSubtensor{::, int64:int64:} [id MU] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id MV] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, row)> [id KW] <CudaNdarrayType(float32, row)> -> [id JW]\n > | | |<CudaNdarrayType(float32, matrix)> [id KX] <CudaNdarrayType(float32, matrix)> -> [id FC]\n > | | |<CudaNdarrayType(float32, matrix)> [id KY] <CudaNdarrayType(float32, matrix)> -> [id ES]\n > | | |GpuGemm{inplace} [id MW] <CudaNdarrayType(float32, matrix)> ''   \n > | |   |GpuDot22 [id MX] <CudaNdarrayType(float32, matrix)> ''   \n > | |   | |<CudaNdarrayType(float32, matrix)> [id MY] <CudaNdarrayType(float32, matrix)> -> [id EK]\n > | |   | |<CudaNdarrayType(float32, matrix)> [id LC] <CudaNdarrayType(float32, matrix)> -> [id JR]\n > | |   |TensorConstant{1.0} [id LD] <TensorType(float32, scalar)>\n > | |   |GpuAdvancedSubtensor1 [id MZ] <CudaNdarrayType(float32, matrix)> ''   \n > | |   | |context embedding.W_copy0[cuda] [id LF] <CudaNdarrayType(float32, matrix)> -> [id EP]\n > | |   | |Elemwise{Cast{int64}} [id NA] <TensorType(int64, vector)> ''   \n > | |   |   |<TensorType(int32, vector)> [id NB] <TensorType(int32, vector)> -> [id EL]\n > | |   |<CudaNdarrayType(float32, matrix)> [id LI] <CudaNdarrayType(float32, matrix)> -> [id JM]\n > | |   |TensorConstant{1.0} [id LD] <TensorType(float32, scalar)>\n > | |Constant{2048} [id LJ] <int64>\n > | |Constant{3072} [id LK] <int64>\n > |GpuSubtensor{::, int64:int64:} [id NC] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id MV] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id LM] <int64>\n > | |Constant{1024} [id LN] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id ND] <CudaNdarrayType(float32, matrix)> -> [id EH]\n > |GpuSubtensor{::, int64:int64:} [id NE] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuElemwise{Add}[(0, 3)] [id MV] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{1024} [id LN] <int64>\n >   |Constant{2048} [id LJ] <int64>\n >GpuElemwise{Composite{tanh((scalar_sigmoid(i0) * i1))},no_inplace} [id NF] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuSubtensor{::, int64:int64:} [id NG] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id MV] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{3072} [id LK] <int64>\n > | |Constant{4096} [id LS] <int64>\n > |GpuElemwise{Composite{((tanh(i0) * scalar_sigmoid(i1)) + (i2 * scalar_sigmoid(i3)))},no_inplace} [id MT] <CudaNdarrayType(float32, matrix)> ''   \n >ViewOp [id NH] <TensorType(int32, vector)> ''   \n > |Elemwise{Cast{int32}} [id NI] <TensorType(int32, vector)> ''   \n >   |Argmax [id NJ] <TensorType(int64, vector)> 'argmax'   \n >Elemwise{Cast{int32}} [id NI] <TensorType(int32, vector)> ''   \n >RandomFunction{uniform}.0 [id LW] <RandomStateType> ''   \n\nforall_inplace,gpu,scan_fn}.1 [id FE] <CudaNdarrayType(float32, 3D)> ''   \n >GpuElemwise{Switch,no_inplace} [id NK] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuFromHost [id NL] <CudaNdarrayType(float32, col)> ''   \n > | |Elemwise{Cast{float32}} [id NM] <TensorType(float32, col)> ''   \n > |   |<TensorType(bool, col)> [id NN] <TensorType(bool, col)> -> [id HM]\n > |GpuElemwise{Composite{((scalar_sigmoid(i0) * i1) + (scalar_sigmoid(i2) * tanh(i3)))},no_inplace} [id NO] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuSubtensor{::, int64:int64:} [id NP] <CudaNdarrayType(float32, matrix)> ''   \n > | | |GpuGemm{no_inplace} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n > | | | |<CudaNdarrayType(float32, matrix)> [id NR] <CudaNdarrayType(float32, matrix)> -> [id GF]\n > | | | |TensorConstant{1.0} [id NS] <TensorType(float32, scalar)>\n > | | | |<CudaNdarrayType(float32, matrix)> [id NT] <CudaNdarrayType(float32, matrix)> -> [id IM]\n > | | | |<CudaNdarrayType(float32, matrix)> [id NU] <CudaNdarrayType(float32, matrix)> -> [id IZ]\n > | | | |TensorConstant{1.0} [id NS] <TensorType(float32, scalar)>\n > | | |Constant{1024} [id NV] <int64>\n > | | |Constant{2048} [id NW] <int64>\n > | |<CudaNdarrayType(float32, matrix)> [id NX] <CudaNdarrayType(float32, matrix)> -> [id HQ]\n > | |GpuSubtensor{::, int64:int64:} [id NY] <CudaNdarrayType(float32, matrix)> ''   \n > | | |GpuGemm{no_inplace} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n > | | |Constant{0} [id NZ] <int64>\n > | | |Constant{1024} [id NV] <int64>\n > | |GpuSubtensor{::, int64:int64:} [id OA] <CudaNdarrayType(float32, matrix)> ''   \n > |   |GpuGemm{no_inplace} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n > |   |Constant{2048} [id NW] <int64>\n > |   |Constant{3072} [id OB] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id NX] <CudaNdarrayType(float32, matrix)> -> [id HQ]\n >GpuElemwise{Composite{Switch(i0, tanh((i1 * scalar_sigmoid(i2))), i3)},no_inplace} [id OC] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuFromHost [id NL] <CudaNdarrayType(float32, col)> ''   \n > |GpuElemwise{Composite{((scalar_sigmoid(i0) * i1) + (scalar_sigmoid(i2) * tanh(i3)))},no_inplace} [id NO] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuSubtensor{::, int64:int64:} [id OD] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuGemm{no_inplace} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{3072} [id OB] <int64>\n > | |Constant{4096} [id OE] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id NT] <CudaNdarrayType(float32, matrix)> -> [id IM]\n\nStorage map footprint:\n - GpuAlloc{memset_0=True}.0, Shape: (2, 36071, 512), ElemSize: 4 Byte(s), TotalSize: 147746816 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.15, Shape: (2, 36071, 512), ElemSize: 4 Byte(s), TotalSize: 147746816 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.4, Shape: (21, 32, 36071), ElemSize: 4 Byte(s), TotalSize: 96958848 Byte(s)\n - GpuSubtensor{::int64}.0, Shape: (21, 32, 36071), ElemSize: 4 Byte(s), TotalSize: 96958848 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.33, Shape: (20, 32, 36071), ElemSize: 4 Byte(s), TotalSize: 92341760 Byte(s)\n - GpuElemwise{maximum,no_inplace}.0, Shape: (32, 20, 36071), ElemSize: 4 Byte(s), TotalSize: 92341760 Byte(s)\n - GpuSubtensor{int64:int64:int8}.0, Shape: (20, 32, 36071), ElemSize: 4 Byte(s), TotalSize: 92341760 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (20, 32, 36071), ElemSize: 4 Byte(s), TotalSize: 92341760 Byte(s)\n - context embedding.W, Shared Input, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - W, Shared Input, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - W, Shared Input, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - GpuDimShuffle{0,3,1,2}.0, Shape: (32, 1024, 20, 20), ElemSize: 4 Byte(s), TotalSize: 52428800 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (256, 36071), ElemSize: 4 Byte(s), TotalSize: 36936704 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (256, 36071), ElemSize: 4 Byte(s), TotalSize: 36936704 Byte(s)\n - decoder next word probas.W, Shared Input, Shape: (256, 36071), ElemSize: 4 Byte(s), TotalSize: 36936704 Byte(s)\n - GpuReshape{4}.0, Shape: (32, 20, 20, 512), ElemSize: 4 Byte(s), TotalSize: 26214400 Byte(s)\n - GpuJoin.0, Shape: (1024, 4096), ElemSize: 4 Byte(s), TotalSize: 16777216 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (4096, 1024), ElemSize: 4 Byte(s), TotalSize: 16777216 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (4096, 1024), ElemSize: 4 Byte(s), TotalSize: 16777216 Byte(s)\n - GpuJoin.0, Shape: (1024, 4096), ElemSize: 4 Byte(s), TotalSize: 16777216 Byte(s)\n - GpuJoin.0, Shape: (1024, 4096), ElemSize: 4 Byte(s), TotalSize: 16777216 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (20, 32, 4096), ElemSize: 4 Byte(s), TotalSize: 10485760 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.22, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.13, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuJoin.0, Shape: (512, 4096), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.21, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.12, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.23, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.11, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.14, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuJoin.0, Shape: (512, 4096), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.20, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (4096, 512), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.19, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.18, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - encoder_lstm.W_hid_to_cell, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_encoder_to_outgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.16, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - encoder_lstm.W_hid_to_forgetgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - encoder_lstm.W_hid_to_ingate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_encoder_to_forgetgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.17, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - encoder_lstm.W_hid_to_outgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_encoder_to_ingate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_out_to_ingate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_encoder_to_cell, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_out_to_cell, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_out_to_forgetgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_out_to_outgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.5, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.6, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,scan_fn}.1, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.1, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.1, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - GpuSubtensor{int64:int64:int64}.0, Shape: (20, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - GpuDimShuffle{0,2,1}.0, Shape: (20, 1024, 32), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (20, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - GpuSubtensor{int64:int64:int64}.0, Shape: (20, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.34, Shape: (20, 1024, 32), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - GpuSubtensor{int64:int64:int64}.0, Shape: (20, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - encoder_lstm.W_in_to_ingate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - encoder_lstm.W_in_to_forgetgate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - encoder_lstm.W_in_to_outgate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - decoder_lstm.W_emb_to_cell, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - decoder_lstm.W_emb_to_forgetgate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - encoder_lstm.W_in_to_cell, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - decoder_lstm.W_emb_to_outgate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - decoder_lstm.W_emb_to_ingate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - GpuJoin.0, Shape: (100, 4096), ElemSize: 4 Byte(s), TotalSize: 1638400 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (4096, 100), ElemSize: 4 Byte(s), TotalSize: 1638400 Byte(s)\n - GpuReshape{2}.0, Shape: (640, 512), ElemSize: 4 Byte(s), TotalSize: 1310720 Byte(s)\n - persona_based.emb.W, Shared Input, Shape: (3194, 100), ElemSize: 4 Byte(s), TotalSize: 1277600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (3194, 100), ElemSize: 4 Byte(s), TotalSize: 1277600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (3194, 100), ElemSize: 4 Byte(s), TotalSize: 1277600 Byte(s)\n - decoder intermediate.W, Shared Input, Shape: (1024, 256), ElemSize: 4 Byte(s), TotalSize: 1048576 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 256), ElemSize: 4 Byte(s), TotalSize: 1048576 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 256), ElemSize: 4 Byte(s), TotalSize: 1048576 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.26, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.25, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.24, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.27, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - W, Shared Input, Shape: (20, 1024, 3, 3), ElemSize: 4 Byte(s), TotalSize: 737280 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.35, Shape: (20, 32, 256), ElemSize: 4 Byte(s), TotalSize: 655360 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.32, Shape: (20, 256, 32), ElemSize: 4 Byte(s), TotalSize: 655360 Byte(s)\n - GpuDot22.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GpuDot22.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - decoder_lstm.W_persona_based.each_tick_to_cell, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - decoder_lstm.W_persona_based.each_tick_to_outgate, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - decoder_lstm.W_persona_based.each_tick_to_forgetgate, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - decoder_lstm.W_persona_based.each_tick_to_ingate, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 36071), ElemSize: 4 Byte(s), TotalSize: 288568 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.29, Shape: (2, 36071), ElemSize: 4 Byte(s), TotalSize: 288568 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 262144 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.31, Shape: (2, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 262144 Byte(s)\n - decoder next word probas.b, Shared Input, Shape: (36071,), ElemSize: 4 Byte(s), TotalSize: 144284 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (36071,), ElemSize: 4 Byte(s), TotalSize: 144284 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (36071,), ElemSize: 4 Byte(s), TotalSize: 144284 Byte(s)\n - GpuDimShuffle{x,0}.0, Shape: (1, 36071), ElemSize: 4 Byte(s), TotalSize: 144284 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (1024, 32), ElemSize: 4 Byte(s), TotalSize: 131072 Byte(s)\n - GpuSubtensor{int64}.0, Shape: (32, 1024), ElemSize: 4 Byte(s), TotalSize: 131072 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.6, Shape: (1, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 131072 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.5, Shape: (1, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 131072 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.30, Shape: (2, 32, 100), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 32, 100), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - GpuDimShuffle{x,0}.0, Shape: (1, 4096), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - W, Shared Input, Shape: (20, 20, 3, 3), ElemSize: 4 Byte(s), TotalSize: 14400 Byte(s)\n - W, Shared Input, Shape: (180, 20), ElemSize: 4 Byte(s), TotalSize: 14400 Byte(s)\n - GpuAdvancedSubtensor1.0, Shape: (32, 100), ElemSize: 4 Byte(s), TotalSize: 12800 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (100, 32), ElemSize: 4 Byte(s), TotalSize: 12800 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.10, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.7, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.8, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.9, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - Elemwise{Cast{int64}}.0, Shape: (640,), ElemSize: 8 Byte(s), TotalSize: 5120 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.b_forgetgate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.cell_init, Shared Input, Shape: (1, 1024), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.hid_init, Shared Input, Shape: (1, 1024), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.b_cell, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - decoder_lstm.b_to_outgate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.b_ingate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.b_outgate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - decoder_lstm.b_to_ingate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - decoder_lstm.b_to_forgetgate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - decoder_lstm.b_to_cell, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.3, Shape: (21, 32), ElemSize: 4 Byte(s), TotalSize: 2688 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.2, Shape: (21, 32), ElemSize: 4 Byte(s), TotalSize: 2688 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32), ElemSize: 4 Byte(s), TotalSize: 2688 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.2, Shape: (21, 32), ElemSize: 4 Byte(s), TotalSize: 2688 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32), ElemSize: 4 Byte(s), TotalSize: 2688 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (20, 32), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - InplaceDimShuffle{1,0}.0, Shape: (32, 20), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (20, 32), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - encoder phrase tokens, Input, Shape: (32, 20), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.8, Shape: (20, 32), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - GpuFromHost.0, Shape: (32, 20), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.28, Shape: (2, 256), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 256), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - decoder intermediate.b, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - GpuDimShuffle{x,0}.0, Shape: (1, 256), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - Elemwise{neq,no_inplace}.0, Shape: (20, 32, 1), ElemSize: 1 Byte(s), TotalSize: 640 Byte(s)\n - InplaceDimShuffle{0,x}.0, Shape: (32, 1), ElemSize: 8 Byte(s), TotalSize: 256 Byte(s)\n - Elemwise{Cast{int64}}.0, Shape: (32,), ElemSize: 8 Byte(s), TotalSize: 256 Byte(s)\n - W, Shared Input, Shape: (20, 2), ElemSize: 4 Byte(s), TotalSize: 160 Byte(s)\n - InplaceDimShuffle{x,0}.0, Shape: (1, 20), ElemSize: 8 Byte(s), TotalSize: 160 Byte(s)\n - personality idxs, Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.7, Shape: (1, 32), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - b, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - b, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - b, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - TensorConstant{[ -1  20  20 512]}, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{(2,) of 0}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(2,) of 2}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-20}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{204800}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((i0 - (i1 + i0 + i2)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{maximum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{4096}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{maximum(maximum(((i0 - Switch(i1, (i2 + i3), i2)) + i4), i5), maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8))) + i4), i5))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Identity}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i7 + i2), (i8 + i2), i4, i5), i4, (i7 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i7 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i7 + i2), (i8 + i2), i4, i5), i4, (i7 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i7 + i2), i4))) + i2), i6))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6), i5), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - b, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i1, i2, (i3 - i4), i5, i6, i7, i8), i2, i9), i2, i10), i9), i9, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i1, i2, (i3 - i4), i5, i6, i7, i8), i2, i9), i2, i10))) - i11) // i12)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i8, i9, i3), i4, i5), i3, i6, i7), i4, i6), i4, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i6), i4), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i8, i9, i3), i4, i5), i3, i6, i7), i4, i6), i4, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i6), i4), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i4))) + i7)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}(i1, (i2 + i3), i4, i5), i4, i1, i5), i4), i6), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}(i1, (i2 + i3), i4, i5), i4, i1, i5), i4), i6)) + i3)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5), i3), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5))) - i6) // i7)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{9}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{3072}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{mul,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{20}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{minimum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((i0 - i1) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1024}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{36071}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5), i3), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5))) - i6) // i7)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.89999998]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{10.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <TensorType(int32, scalar)>, Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.10000002]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[ 0.01]]]}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.899999976158}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Constant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[ 0.00099999]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuDimShuffle{x,x}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{1.00000001169e-07}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.999000012875}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{36071}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuElemwise{Composite{((i0 * sqrt((i1 - (i2 ** i3)))) / (i1 - (i4 ** i3)))},no_inplace}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.01]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.10000002]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.89999998]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[-1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[  1.00000001e-10]]]}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{9.99999974738e-06}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuDimShuffle{x}.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.00099999]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[ 0.]]]}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{sqr,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of 36069}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Constant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[  9.99999994e-09]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[  9.99999994e-09]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) of 36070}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.99900001]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.99900001]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{1024}, Shape: (), ElemSize: 2 Byte(s), TotalSize: 2.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{3}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1, 1) of 0}, Shape: (1, 1), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{lt,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{20}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1, 1) of True}, Shape: (1, 1), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{le,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{3}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 1685981947.0 Byte(s) 1.570 GB\n TotalSize inputs: 694709416.0 Byte(s) 0.647 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-3c2abb83eec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrespondent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeakers_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspeakers_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpg_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrespondent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mgen_train_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gen %.5f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Error allocating 52428800 bytes of device memory (CNMEM_STATUS_OUT_OF_MEMORY).\nApply node that caused the error: GpuContiguous(GpuDimShuffle{0,3,1,2}.0)\nToposort index: 539\nInputs types: [CudaNdarrayType(float32, 4D)]\nInputs shapes: [(32, 1024, 20, 20)]\nInputs strides: [(409600, 1, 20480, 1024)]\nInputs values: ['not shown']\nInputs type_num: ['']\nOutputs clients: [[GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0})]]\n\nDebugprint of the apply node: \nGpuContiguous [id A] <CudaNdarrayType(float32, 4D)> ''   \n |GpuDimShuffle{0,3,1,2} [id B] <CudaNdarrayType(float32, 4D)> ''   \n   |GpuJoin [id C] <CudaNdarrayType(float32, 4D)> ''   \n     |TensorConstant{3} [id D] <TensorType(int8, scalar)>\n     |GpuReshape{4} [id E] <CudaNdarrayType(float32, 4D)> ''   \n     | |GpuAlloc [id F] <CudaNdarrayType(float32, 4D)> ''   \n     | | |GpuDimShuffle{0,1,x,2} [id G] <CudaNdarrayType(float32, (False, False, True, False))> ''   \n     | | | |GpuReshape{3} [id H] <CudaNdarrayType(float32, 3D)> ''   \n     | | |   |GpuAdvancedSubtensor1 [id I] <CudaNdarrayType(float32, matrix)> ''   \n     | | |   | |W [id J] <CudaNdarrayType(float32, matrix)>\n     | | |   | |Elemwise{Cast{int64}} [id K] <TensorType(int64, vector)> ''   \n     | | |   |   |Reshape{1} [id L] <TensorType(int32, vector)> ''   \n     | | |   |     |encoder phrase tokens [id M] <TensorType(int32, matrix)>\n     | | |   |     |TensorConstant{(1,) of -1} [id N] <TensorType(int64, (True,))>\n     | | |   |MakeVector{dtype='int64'} [id O] <TensorType(int64, vector)> ''   \n     | | |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n     | | |     | |encoder phrase tokens [id M] <TensorType(int32, matrix)>\n     | | |     |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n     | | |     | |encoder phrase tokens [id M] <TensorType(int32, matrix)>\n     | | |     |Shape_i{1} [id R] <TensorType(int64, scalar)> ''   \n     | | |       |W [id J] <CudaNdarrayType(float32, matrix)>\n     | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n     | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n     | | |TensorConstant{20} [id S] <TensorType(int8, scalar)>\n     | | |Shape_i{1} [id R] <TensorType(int64, scalar)> ''   \n     | |TensorConstant{[ -1  20  20 512]} [id T] <TensorType(int64, vector)>\n     |GpuReshape{4} [id U] <CudaNdarrayType(float32, 4D)> ''   \n       |GpuAlloc [id V] <CudaNdarrayType(float32, 4D)> ''   \n       | |GpuDimShuffle{0,1,x,2} [id W] <CudaNdarrayType(float32, (False, False, True, False))> ''   \n       | | |GpuReshape{3} [id X] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |GpuAdvancedSubtensor1 [id Y] <CudaNdarrayType(float32, matrix)> ''   \n       | |   | |W [id Z] <CudaNdarrayType(float32, matrix)>\n       | |   | |Elemwise{Cast{int64}} [id BA] <TensorType(int64, vector)> ''   \n       | |   |   |Reshape{1} [id BB] <TensorType(int32, vector)> ''   \n       | |   |     |InplaceDimShuffle{1,0} [id BC] <TensorType(int32, matrix)> ''   \n       | |   |     | |Subtensor{int64:int64:int8} [id BD] <TensorType(int32, matrix)> ''   \n       | |   |     |   |forall_inplace,gpu,scan_fn&scan_fn}.3 [id BE] <TensorType(int32, matrix)> ''   \n       | |   |     |   | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | |GpuIncSubtensor{InplaceSet;:int64:} [id BG] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | |GpuAllocEmpty [id BH] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id BI] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i7 + i2), (i8 + i2), i4, i5), i4, (i7 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i7 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i7 + i2), (i8 + i2), i4, i5), i4, (i7 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i7 + i2), i4))) + i2), i6))}} [id BJ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6), i5), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6))}} [id BK] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{le,no_inplace} [id BL] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{sub,no_inplace} [id BM] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}} [id BN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{le,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i4, i2), i4, i2))}} [id BP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{lt,no_inplace} [id BQ] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |Elemwise{Identity} [id BR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | | | | | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id BT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | |Elemwise{sub,no_inplace} [id BV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id BW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id BZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id BW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Identity} [id BR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |Elemwise{Identity} [id BR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(i0, Switch(LT((i1 + i2), i3), i3, (i1 + i2)), Switch(LT(i4, i2), i4, i2))}} [id BP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id BT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{sub,no_inplace} [id BV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}} [id CB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |   |Elemwise{le,no_inplace} [id BO] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |   |TensorConstant{0} [id CC] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |   |Elemwise{Composite{Switch(LT((i0 + i1), i2), i2, (i0 + i1))}} [id BT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |   |Elemwise{sub,no_inplace} [id BV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}} [id BN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id BZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{add,no_inplace} [id CD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id BW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1), i4), i1), i5)}} [id CB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{sub,no_inplace} [id CE] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i1, i2, (i3 - i4), i5, i6, i7, i8), i2, i9), i2, i10), i9), i9, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i1, i2, (i3 - i4), i5, i6, i7, i8), i2, i9), i2, i10))) - i11) // i12)}} [id CG] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6), i5), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6))}} [id BK] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{le,no_inplace} [id BL] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{add,no_inplace} [id CD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i1), i1, Composite{Switch(GE(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, minimum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4))}} [id BN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{sub,no_inplace} [id BM] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{sub,no_inplace} [id CH] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |TensorConstant{-2} [id CI] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id BZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id CK] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{lt,no_inplace} [id CL] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id CM] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{le,no_inplace} [id CN] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{sub,no_inplace} [id CO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{add,no_inplace} [id CQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id CR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   |Elemwise{le,no_inplace} [id CS] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i5, i6), i5, i6))}} [id CT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | |Elemwise{lt,no_inplace} [id BQ] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | | |Elemwise{lt,no_inplace} [id BQ] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | | | |Elemwise{Identity} [id BR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id CW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | | |Elemwise{add,no_inplace} [id CX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | |   |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | |   |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | | |Elemwise{Identity} [id BR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | | |Elemwise{sub,no_inplace} [id CY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id CW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id CW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id CZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |   |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id CX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10)}} [id DA] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id CQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i6, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id CR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |Elemwise{le,no_inplace} [id CS] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |   |Elemwise{add,no_inplace} [id CZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |Elemwise{Composite{Switch(i0, Switch(LT(Composite{((i0 + i1) - i2)}(i1, i2, i3), i4), i4, Composite{((i0 + i1) - i2)}(i1, i2, i3)), Switch(LT(i5, i6), i5, i6))}} [id CT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | |   |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}((i0 - i1), i2, i3), i2), i1)}} [id CW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |   |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id CP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |TensorConstant{0} [id CC] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id CM] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{sub,no_inplace} [id CE] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5), i3), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5))) - i6) // i7)}} [id DB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id CK] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   |Elemwise{lt,no_inplace} [id DC] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | |   | |Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}} [id DD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   | | |Elemwise{le,no_inplace} [id CN] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | |   | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |   | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | |   | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), (i4 - i5), maximum((i4 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i7), i3, i9), i7), i3), i3, i1), i3), i10)}} [id DA] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   | | |Elemwise{sub,no_inplace} [id CO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   | | |Elemwise{sub,no_inplace} [id CH] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   | | |Elemwise{switch,no_inplace} [id CV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |   |Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}} [id DD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |   |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |   |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |TensorConstant{1024} [id DE] <TensorType(int64, scalar)>\n       | |   |     |   | | |GpuFromHost [id DF] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | |Rebroadcast{0} [id DG] <TensorType(float32, 3D)> ''   \n       | |   |     |   | | |   |Alloc [id DH] <TensorType(float32, (True, False, False))> ''   \n       | |   |     |   | | |     |TensorConstant{0.0} [id DI] <TensorType(float32, scalar)>\n       | |   |     |   | | |     |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     |TensorConstant{1024} [id DJ] <TensorType(int16, scalar)>\n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |GpuIncSubtensor{InplaceSet;:int64:} [id DL] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | |GpuAllocEmpty [id DM] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}} [id DN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |Elemwise{Composite{((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i8, i9, i3), i4, i5), i3, i6, i7), i4, i6), i4, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i6), i4), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i8, i9, i3), i4, i5), i3, i6, i7), i4, i6), i4, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i6), i4), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i4))) + i7)}} [id DO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | |Elemwise{lt,no_inplace} [id CL] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id CM] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |Elemwise{add,no_inplace} [id DP] <TensorType(int32, scalar)> ''   \n       | |   |     |   | | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{1} [id DQ] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |Elemwise{lt,no_inplace} [id DC] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | |Elemwise{Composite{Switch(i0, i1, Switch(AND(LT((i2 + i3), i1), GT(i4, i1)), i5, minimum((i2 + i3), i6)))}} [id DD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |TensorConstant{1024} [id DE] <TensorType(int64, scalar)>\n       | |   |     |   | | |GpuFromHost [id DF] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |IncSubtensor{InplaceSet;:int64:} [id DR] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | |AllocEmpty{dtype='int32'} [id DS] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}} [id DN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |Rebroadcast{0} [id DT] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | | |Alloc [id DU] <TensorType(int32, row)> ''   \n       | |   |     |   | | |   |TensorConstant{(1, 1) of 36069} [id DV] <TensorType(int32, (True, True))>\n       | |   |     |   | | |   |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | |   |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |IncSubtensor{InplaceSet;:int64:} [id DW] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | |AllocEmpty{dtype='int32'} [id DX] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}} [id DY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | |Elemwise{Composite{((i0 - Switch(LT(i1, i2), i1, i2)) + i1)}} [id DZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |Elemwise{add,no_inplace} [id DP] <TensorType(int32, scalar)> ''   \n       | |   |     |   | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |Rebroadcast{0} [id DT] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |GpuIncSubtensor{InplaceSet;:int64:} [id EA] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | |GpuAllocEmpty [id EB] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}} [id DY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |TensorConstant{36071} [id EC] <TensorType(int64, scalar)>\n       | |   |     |   | | |GpuFromHost [id ED] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | |Rebroadcast{0} [id EE] <TensorType(float32, 3D)> ''   \n       | |   |     |   | | |   |Alloc [id EF] <TensorType(float32, (True, False, False))> ''   \n       | |   |     |   | | |     |TensorConstant{0.0} [id DI] <TensorType(float32, scalar)>\n       | |   |     |   | | |     |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     |TensorConstant{36071} [id EG] <TensorType(int32, scalar)>\n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |GpuIncSubtensor{InplaceSet;:int64:} [id EH] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | |GpuAllocEmpty [id EI] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | |TensorConstant{1024} [id DE] <TensorType(int64, scalar)>\n       | |   |     |   | | |GpuFromHost [id EJ] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | | |Alloc [id DH] <TensorType(float32, (True, False, False))> ''   \n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |DeepCopyOp [id EK] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | |GpuIncSubtensor{InplaceSet;:int64:} [id EH] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | |IncSubtensor{InplaceSet;:int64:} [id EL] <TensorType(int32, row)> ''   \n       | |   |     |   | | |AllocEmpty{dtype='int32'} [id EM] <TensorType(int32, row)> ''   \n       | |   |     |   | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |TensorConstant{(1, 1) of 36069} [id DV] <TensorType(int32, (True, True))>\n       | |   |     |   | | |Constant{1} [id DK] <int64>\n       | |   |     |   | |DeepCopyOp [id EN] <TensorType(int32, matrix)> ''   \n       | |   |     |   | | |IncSubtensor{InplaceSet;:int64:} [id DW] <TensorType(int32, matrix)> ''   \n       | |   |     |   | |<RandomStateType> [id EO] <RandomStateType>\n       | |   |     |   | |context embedding.W [id EP] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |decoder intermediate.W [id EQ] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |decoder next word probas.W [id ER] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |GpuDot22 [id ES] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | |GpuAdvancedSubtensor1 [id ET] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | |persona_based.emb.W [id EU] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | |Elemwise{Cast{int64}} [id EV] <TensorType(int64, vector)> ''   \n       | |   |     |   | | |   |personality idxs [id EW] <TensorType(int32, vector)>\n       | |   |     |   | | |GpuJoin [id EX] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | |   |decoder_lstm.W_persona_based.each_tick_to_ingate [id EY] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_persona_based.each_tick_to_forgetgate [id EZ] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_persona_based.each_tick_to_cell [id FA] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_persona_based.each_tick_to_outgate [id FB] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |GpuDot22 [id FC] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | |GpuSubtensor{int64} [id FD] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | |forall_inplace,gpu,scan_fn}.1 [id FE] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | |Elemwise{maximum,no_inplace} [id FF] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |Elemwise{Composite{minimum(maximum(maximum((i0 - i1), (i0 - i1)), ((i2 + i3) - i1)), i4)}} [id FG] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id FH] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{add,no_inplace} [id FI] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id FJ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{lt,no_inplace} [id FK] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id FL] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{le,no_inplace} [id FM] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |Elemwise{sub,no_inplace} [id FN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id FO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |Elemwise{add,no_inplace} [id FP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id FQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   |Elemwise{le,no_inplace} [id FR] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id FS] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | | |Elemwise{sub,no_inplace} [id FT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id FU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |     |TensorConstant{0} [id CC] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |   | |     |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id FU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id FV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |   | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | | |   |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11)}} [id FW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id FP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5), i4), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, i3))}(i0, i1, i2, i3), i1, i4), i1, i5))}} [id FQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{le,no_inplace} [id FR] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{add,no_inplace} [id FV] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id FS] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{sub,no_inplace} [id FX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | |   | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id FU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |   |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | |   |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id FO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id FO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |TensorConstant{0} [id CC] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id FL] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{add,no_inplace} [id FY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(i0, (i1 + i2), i1)}} [id FZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{lt,no_inplace} [id GA] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT((i0 - i1), i2), i3, Switch(GE((i0 - i1), i4), (i5 + i0), Switch(LE(i4, i2), (i5 + i0), i0)))}} [id GB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id GC] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | |Elemwise{add,no_inplace} [id FY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |Elemwise{sub,no_inplace} [id GD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |TensorConstant{-2} [id CI] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{sub,no_inplace} [id GE] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{add,no_inplace} [id FY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id GC] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |Elemwise{Composite{Switch(LT((i0 - i1), i2), i3, Switch(GE((i0 - i1), i4), (i5 + i0), Switch(LE(i4, i2), (i5 + i0), i0)))}} [id GB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{add,no_inplace} [id FY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | |GpuSubtensor{int64:int64:int8} [id GF] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | |GpuElemwise{add,no_inplace} [id GG] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | |GpuReshape{3} [id GH] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | | |GpuDot22 [id GI] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | | | | |GpuReshape{2} [id GJ] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | | | | | |GpuDimShuffle{1,0,2} [id GK] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | | | | | |GpuReshape{3} [id GL] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | | | | |   |GpuAdvancedSubtensor1 [id GM] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | | | | | |   | |context embedding.W [id EP] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | | | |   | |Elemwise{Cast{int64}} [id K] <TensorType(int64, vector)> ''   \n       | |   |     |   | | | | | | | | | |   |MakeVector{dtype='int64'} [id GN] <TensorType(int64, vector)> ''   \n       | |   |     |   | | | | | | | | | |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |     |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |     |Shape_i{1} [id GO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |       |context embedding.W [id EP] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | | | |MakeVector{dtype='int64'} [id GP] <TensorType(int64, vector)> ''   \n       | |   |     |   | | | | | | | | |   |Elemwise{mul,no_inplace} [id GQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |   | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |   | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |   |Shape_i{1} [id GO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |GpuJoin [id GR] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | | | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |   |encoder_lstm.W_in_to_ingate [id GS] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | |   |encoder_lstm.W_in_to_forgetgate [id GT] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | |   |encoder_lstm.W_in_to_cell [id GU] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | |   |encoder_lstm.W_in_to_outgate [id GV] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | | |MakeVector{dtype='int64'} [id GW] <TensorType(int64, vector)> ''   \n       | |   |     |   | | | | | | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |   |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |   |Elemwise{add,no_inplace} [id GX] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |     |Shape_i{1} [id GY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |     | |encoder_lstm.W_in_to_ingate [id GS] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | |     |Shape_i{1} [id GZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |     | |encoder_lstm.W_in_to_forgetgate [id GT] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | |     |Shape_i{1} [id HA] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |     | |encoder_lstm.W_in_to_cell [id GU] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | |     |Shape_i{1} [id HB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |       |encoder_lstm.W_in_to_outgate [id GV] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | | | | |GpuDimShuffle{x,x,0} [id HC] <CudaNdarrayType(float32, (True, True, False))> ''   \n       | |   |     |   | | | | | |   |GpuJoin [id HD] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | | | | | |     |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |     |encoder_lstm.b_ingate [id HE] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | | | | | |     |encoder_lstm.b_forgetgate [id HF] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | | | | | |     |encoder_lstm.b_cell [id HG] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | | | | | |     |encoder_lstm.b_outgate [id HH] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | | | | | |ScalarFromTensor [id HI] <int64> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{Switch(LE(i0, i1), i1, i2)}} [id HJ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |   |TensorConstant{0} [id CC] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | |ScalarFromTensor [id HK] <int64> ''   \n       | |   |     |   | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |Constant{1} [id HL] <int8>\n       | |   |     |   | | | | |Subtensor{int64:int64:int8} [id HM] <TensorType(bool, (False, False, True))> ''   \n       | |   |     |   | | | | | |Elemwise{neq,no_inplace} [id HN] <TensorType(bool, (False, False, True))> ''   \n       | |   |     |   | | | | | | |InplaceDimShuffle{1,0,x} [id HO] <TensorType(int32, (False, False, True))> ''   \n       | |   |     |   | | | | | | | |encoder phrase tokens [id M] <TensorType(int32, matrix)>\n       | |   |     |   | | | | | | |TensorConstant{(1, 1, 1) of 36070} [id HP] <TensorType(int32, (True, True, True))>\n       | |   |     |   | | | | | |ScalarFromTensor [id HI] <int64> ''   \n       | |   |     |   | | | | | |ScalarFromTensor [id HK] <int64> ''   \n       | |   |     |   | | | | | |Constant{1} [id HL] <int8>\n       | |   |     |   | | | | |GpuIncSubtensor{InplaceSet;:int64:} [id HQ] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | |GpuAllocEmpty [id HR] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}} [id HS] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{Composite{((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}(i1, (i2 + i3), i4, i5), i4, i1, i5), i4), i6), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}(i1, (i2 + i3), i4, i5), i4, i1, i5), i4), i6)) + i3)}} [id HT] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{maximum,no_inplace} [id FF] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{add,no_inplace} [id FI] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5), i3), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5))) - i6) // i7)}} [id HU] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}} [id FJ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{lt,no_inplace} [id HV] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |Elemwise{Composite{Switch(i0, i1, Switch(i2, i3, i4))}} [id HW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{le,no_inplace} [id FM] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | |Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}} [id HX] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |Elemwise{add,no_inplace} [id HY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | | |TensorConstant{-1} [id BU] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | | | | | | |Elemwise{Composite{Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{(i0 - Switch(LT(i1, i2), i2, i1))}(i0, Composite{(i0 - Switch(GE(i1, i2), i2, i1))}(i1, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i2, i3, (i4 - i5), i5, i6, i7, i8), i3, i9), i3, i10), i9), i3), i3, i1), i3), i11)}} [id FW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | | | | |Elemwise{sub,no_inplace} [id FN] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{sub,no_inplace} [id GD] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | | |Elemwise{minimum,no_inplace} [id HZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |   |Elemwise{add,no_inplace} [id HY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |   |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |Elemwise{Composite{Switch(i0, i1, Switch(i2, i3, i4))}} [id HW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{add,no_inplace} [id FY] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}} [id FH] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Shape_i{1} [id IA] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |encoder_lstm.cell_init [id IB] <CudaNdarrayType(float32, row)>\n       | |   |     |   | | | | | |Rebroadcast{0} [id IC] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | |GpuDimShuffle{x,0,1} [id ID] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | | | | |   |GpuGer{inplace} [id IE] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | |     |GpuAlloc{memset_0=True} [id IF] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | |     | |CudaNdarrayConstant{0.0} [id IG] <CudaNdarrayType(float32, scalar)>\n       | |   |     |   | | | | | |     | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |     | |Shape_i{1} [id IA] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |     |TensorConstant{1.0} [id IH] <TensorType(float32, scalar)>\n       | |   |     |   | | | | | |     |GpuDimShuffle{0} [id II] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | | | | | |     | |GpuAlloc [id IJ] <CudaNdarrayType(float32, col)> ''   \n       | |   |     |   | | | | | |     |   |CudaNdarrayConstant{1.0} [id IK] <CudaNdarrayType(float32, scalar)>\n       | |   |     |   | | | | | |     |   |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |     |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | |     |GpuDimShuffle{1} [id IL] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | | | | | |       |encoder_lstm.cell_init [id IB] <CudaNdarrayType(float32, row)>\n       | |   |     |   | | | | | |Constant{1} [id DK] <int64>\n       | |   |     |   | | | | |GpuIncSubtensor{InplaceSet;:int64:} [id IM] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | |GpuAllocEmpty [id IN] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | |Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}} [id IO] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | |Elemwise{Composite{maximum(maximum(((i0 - Switch(i1, (i2 + i3), i2)) + i4), i5), maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8))) + i4), i5))}} [id IP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{maximum,no_inplace} [id FF] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{lt,no_inplace} [id GA] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(LT((i0 - i1), i2), i3, Switch(GE((i0 - i1), i4), (i5 + i0), Switch(LE(i4, i2), (i5 + i0), i0)))}} [id GB] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{add,no_inplace} [id IQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Shape_i{1} [id Q] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{2} [id CJ] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{lt,no_inplace} [id FK] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}} [id FL] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |TensorConstant{-1} [id CA] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{sub,no_inplace} [id IR] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |Elemwise{add,no_inplace} [id IQ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | | |Elemwise{lt,no_inplace} [id HV] <TensorType(bool, scalar)> ''   \n       | |   |     |   | | | | | | | | |Elemwise{Composite{Switch(i0, i1, Switch(i2, i3, i4))}} [id HW] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | | | | | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   | | | | | | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | | |Shape_i{1} [id IS] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |   |encoder_lstm.hid_init [id IT] <CudaNdarrayType(float32, row)>\n       | |   |     |   | | | | | |Rebroadcast{0} [id IU] <CudaNdarrayType(float32, 3D)> ''   \n       | |   |     |   | | | | | | |GpuDimShuffle{x,0,1} [id IV] <CudaNdarrayType(float32, (True, False, False))> ''   \n       | |   |     |   | | | | | |   |GpuGer{inplace} [id IW] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | |     |GpuAlloc{memset_0=True} [id IX] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | | | |     | |CudaNdarrayConstant{0.0} [id IG] <CudaNdarrayType(float32, scalar)>\n       | |   |     |   | | | | | |     | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |     | |Shape_i{1} [id IS] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | | | | |     |TensorConstant{1.0} [id IH] <TensorType(float32, scalar)>\n       | |   |     |   | | | | | |     |GpuDimShuffle{0} [id II] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | | | | | |     |GpuDimShuffle{1} [id IY] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | | | | | |       |encoder_lstm.hid_init [id IT] <CudaNdarrayType(float32, row)>\n       | |   |     |   | | | | | |Constant{1} [id DK] <int64>\n       | |   |     |   | | | | |GpuJoin [id IZ] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | | |   |encoder_lstm.W_hid_to_ingate [id JA] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | |   |encoder_lstm.W_hid_to_forgetgate [id JB] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | |   |encoder_lstm.W_hid_to_cell [id JC] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | |   |encoder_lstm.W_hid_to_outgate [id JD] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | | |ScalarFromTensor [id JE] <int64> ''   \n       | |   |     |   | | |   |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id JF] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     |Elemwise{Composite{Switch(i0, (i1 + i2), i1)}} [id FZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     |Elemwise{maximum,no_inplace} [id JG] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     | |Elemwise{Composite{minimum(maximum(maximum((i0 - i1), (i0 - i1)), ((i2 + i3) - i1)), i4)}} [id FG] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |     | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |     |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |     |Elemwise{Composite{maximum(maximum(((i0 - Switch(i1, (i2 + i3), i2)) + i4), i5), maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8))) + i4), i5))}} [id IP] <TensorType(int64, scalar)> ''   \n       | |   |     |   | | |GpuJoin [id JH] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | |   |decoder_lstm.W_encoder_to_ingate [id JI] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_encoder_to_forgetgate [id JJ] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_encoder_to_cell [id JK] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |   |decoder_lstm.W_encoder_to_outgate [id JL] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |GpuJoin [id JM] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |decoder_lstm.W_emb_to_ingate [id JN] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_emb_to_forgetgate [id JO] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_emb_to_cell [id JP] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_emb_to_outgate [id JQ] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |GpuJoin [id JR] <CudaNdarrayType(float32, matrix)> ''   \n       | |   |     |   | | |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   | | |decoder_lstm.W_out_to_ingate [id JS] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_out_to_forgetgate [id JT] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_out_to_cell [id JU] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | | |decoder_lstm.W_out_to_outgate [id JV] <CudaNdarrayType(float32, matrix)>\n       | |   |     |   | |GpuDimShuffle{x,0} [id JW] <CudaNdarrayType(float32, row)> ''   \n       | |   |     |   | | |GpuJoin [id JX] <CudaNdarrayType(float32, vector)> ''   \n       | |   |     |   | |   |TensorConstant{0} [id BS] <TensorType(int8, scalar)>\n       | |   |     |   | |   |decoder_lstm.b_to_ingate [id JY] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | |   |decoder_lstm.b_to_forgetgate [id JZ] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | |   |decoder_lstm.b_to_cell [id KA] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | |   |decoder_lstm.b_to_outgate [id KB] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | |GpuDimShuffle{x,x} [id KC] <CudaNdarrayType(float32, (True, True))> ''   \n       | |   |     |   | | |GpuFromHost [id KD] <CudaNdarrayType(float32, scalar)> ''   \n       | |   |     |   | |   |<TensorType(float32, scalar)> [id KE] <TensorType(float32, scalar)>\n       | |   |     |   | |GpuDimShuffle{x,0} [id KF] <CudaNdarrayType(float32, row)> ''   \n       | |   |     |   | | |decoder next word probas.b [id KG] <CudaNdarrayType(float32, vector)>\n       | |   |     |   | |GpuDimShuffle{x,0} [id KH] <CudaNdarrayType(float32, row)> ''   \n       | |   |     |   |   |decoder intermediate.b [id KI] <CudaNdarrayType(float32, vector)>\n       | |   |     |   |ScalarFromTensor [id KJ] <int64> ''   \n       | |   |     |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id KK] <TensorType(int64, scalar)> ''   \n       | |   |     |   |   |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id KL] <TensorType(int64, scalar)> ''   \n       | |   |     |   |   | |TensorConstant{1} [id BY] <TensorType(int64, scalar)>\n       | |   |     |   |   | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   |   |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   |   |Elemwise{maximum,no_inplace} [id KM] <TensorType(int64, scalar)> ''   \n       | |   |     |   |     |Elemwise{Composite{((i0 - Switch(LT(i1, i2), i1, i2)) + i1)}} [id DZ] <TensorType(int64, scalar)> ''   \n       | |   |     |   |     |TensorConstant{2} [id KN] <TensorType(int8, scalar)>\n       | |   |     |   |ScalarFromTensor [id KO] <int64> ''   \n       | |   |     |   | |Elemwise{Composite{(((i0 - i1) - i2) + i3)}} [id KP] <TensorType(int64, scalar)> ''   \n       | |   |     |   |   |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |   |     |   |   |<TensorType(int32, scalar)> [id BF] <TensorType(int32, scalar)>\n       | |   |     |   |   |TensorConstant{1} [id CF] <TensorType(int8, scalar)>\n       | |   |     |   |   |Elemwise{maximum,no_inplace} [id KM] <TensorType(int64, scalar)> ''   \n       | |   |     |   |Constant{1} [id HL] <int8>\n       | |   |     |TensorConstant{(1,) of -1} [id N] <TensorType(int64, (True,))>\n       | |   |MakeVector{dtype='int64'} [id KQ] <TensorType(int64, vector)> ''   \n       | |     |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |     |Elemwise{sub,no_inplace} [id KR] <TensorType(int64, scalar)> ''   \n       | |     | |Elemwise{add,no_inplace} [id BX] <TensorType(int64, scalar)> ''   \n       | |     | |Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}} [id KL] <TensorType(int64, scalar)> ''   \n       | |     |Shape_i{1} [id KS] <TensorType(int64, scalar)> ''   \n       | |       |W [id Z] <CudaNdarrayType(float32, matrix)>\n       | |Shape_i{0} [id P] <TensorType(int64, scalar)> ''   \n       | |Elemwise{sub,no_inplace} [id KR] <TensorType(int64, scalar)> ''   \n       | |TensorConstant{20} [id S] <TensorType(int8, scalar)>\n       | |Shape_i{1} [id KS] <TensorType(int64, scalar)> ''   \n       |TensorConstant{[ -1  20  20 512]} [id T] <TensorType(int64, vector)>\n\nInner graphs of the scan ops:\n\nforall_inplace,gpu,scan_fn&scan_fn}.3 [id BE] <TensorType(int32, matrix)> ''   \n >GpuElemwise{Composite{((tanh(i0) * scalar_sigmoid(i1)) + (i2 * scalar_sigmoid(i3)))},no_inplace} [id KT] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuSubtensor{::, int64:int64:} [id KU] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id KV] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, row)> [id KW] <CudaNdarrayType(float32, row)> -> [id JW]\n > | | |<CudaNdarrayType(float32, matrix)> [id KX] <CudaNdarrayType(float32, matrix)> -> [id FC]\n > | | |<CudaNdarrayType(float32, matrix)> [id KY] <CudaNdarrayType(float32, matrix)> -> [id ES]\n > | | |GpuGemm{inplace} [id KZ] <CudaNdarrayType(float32, matrix)> ''   \n > | |   |GpuDot22 [id LA] <CudaNdarrayType(float32, matrix)> ''   \n > | |   | |<CudaNdarrayType(float32, matrix)> [id LB] <CudaNdarrayType(float32, matrix)> -> [id DL]\n > | |   | |<CudaNdarrayType(float32, matrix)> [id LC] <CudaNdarrayType(float32, matrix)> -> [id JR]\n > | |   |TensorConstant{1.0} [id LD] <TensorType(float32, scalar)>\n > | |   |GpuAdvancedSubtensor1 [id LE] <CudaNdarrayType(float32, matrix)> ''   \n > | |   | |context embedding.W_copy0[cuda] [id LF] <CudaNdarrayType(float32, matrix)> -> [id EP]\n > | |   | |Elemwise{Cast{int64}} [id LG] <TensorType(int64, vector)> ''   \n > | |   |   |<TensorType(int32, vector)> [id LH] <TensorType(int32, vector)> -> [id DR]\n > | |   |<CudaNdarrayType(float32, matrix)> [id LI] <CudaNdarrayType(float32, matrix)> -> [id JM]\n > | |   |TensorConstant{1.0} [id LD] <TensorType(float32, scalar)>\n > | |Constant{2048} [id LJ] <int64>\n > | |Constant{3072} [id LK] <int64>\n > |GpuSubtensor{::, int64:int64:} [id LL] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id KV] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id LM] <int64>\n > | |Constant{1024} [id LN] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id LO] <CudaNdarrayType(float32, matrix)> -> [id BG]\n > |GpuSubtensor{::, int64:int64:} [id LP] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuElemwise{Add}[(0, 3)] [id KV] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{1024} [id LN] <int64>\n >   |Constant{2048} [id LJ] <int64>\n >GpuElemwise{Composite{tanh((scalar_sigmoid(i0) * i1))},no_inplace} [id LQ] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuSubtensor{::, int64:int64:} [id LR] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id KV] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{3072} [id LK] <int64>\n > | |Constant{4096} [id LS] <int64>\n > |GpuElemwise{Composite{((tanh(i0) * scalar_sigmoid(i1)) + (i2 * scalar_sigmoid(i3)))},no_inplace} [id KT] <CudaNdarrayType(float32, matrix)> ''   \n >ViewOp [id LT] <TensorType(int32, vector)> ''   \n > |Sum{axis=[1], acc_dtype=int64} [id LU] <TensorType(int32, vector)> ''   \n >   |Elemwise{gt,no_inplace} [id LV] <TensorType(bool, matrix)> ''   \n >     |RandomFunction{uniform}.1 [id LW] <TensorType(float32, col)> ''   \n >     | |<RandomStateType> [id LX] <RandomStateType> -> [id EO]\n >     | |MakeVector{dtype='int64'} [id LY] <TensorType(int64, vector)> ''   \n >     | | |Shape_i{0} [id LZ] <TensorType(int64, scalar)> ''   \n >     | | | |<CudaNdarrayType(float32, matrix)> [id LB] <CudaNdarrayType(float32, matrix)> -> [id DL]\n >     | | |TensorConstant{1} [id MA] <TensorType(int64, scalar)>\n >     | |TensorConstant{0.0} [id MB] <TensorType(float32, scalar)>\n >     | |TensorConstant{1.0} [id LD] <TensorType(float32, scalar)>\n >     |HostFromGpu [id MC] <TensorType(float32, matrix)> ''   \n >       |GpuSubtensor{::, :int64:} [id MD] <CudaNdarrayType(float32, matrix)> ''   \n >         |GpuCumsum{1} [id ME] <CudaNdarrayType(float32, matrix)> ''   \n >         | |GpuDimShuffle{0,1} [id MF] <CudaNdarrayType(float32, matrix)> ''   \n >         |   |GpuDnnSoftmax{tensor_format='bc01', mode='channel', algo='accurate'} [id MG] <CudaNdarrayType(float32, (False, False, True, True))> ''   \n >         |     |GpuContiguous [id MH] <CudaNdarrayType(float32, (False, False, True, True))> ''   \n >         |       |GpuDimShuffle{0,1,x,x} [id MI] <CudaNdarrayType(float32, (False, False, True, True))> ''   \n >         |         |GpuElemwise{Composite{((i0 + i1) / i2)}}[(0, 0)] [id MJ] <CudaNdarrayType(float32, matrix)> ''   \n >         |           |GpuDot22 [id MK] <CudaNdarrayType(float32, matrix)> ''   \n >         |           | |GpuElemwise{Composite{tanh((i0 + i1))}}[(0, 0)] [id ML] <CudaNdarrayType(float32, matrix)> ''   \n >         |           | | |GpuDot22 [id MM] <CudaNdarrayType(float32, matrix)> ''   \n >         |           | | | |GpuElemwise{Composite{tanh((scalar_sigmoid(i0) * i1))},no_inplace} [id LQ] <CudaNdarrayType(float32, matrix)> ''   \n >         |           | | | |decoder intermediate.W_copy0[cuda] [id MN] <CudaNdarrayType(float32, matrix)> -> [id EQ]\n >         |           | | |<CudaNdarrayType(float32, row)> [id MO] <CudaNdarrayType(float32, row)> -> [id KH]\n >         |           | |decoder next word probas.W_copy0[cuda] [id MP] <CudaNdarrayType(float32, matrix)> -> [id ER]\n >         |           |<CudaNdarrayType(float32, row)> [id MQ] <CudaNdarrayType(float32, row)> -> [id KF]\n >         |           |<CudaNdarrayType(float32, (True, True))> [id MR] <CudaNdarrayType(float32, (True, True))> -> [id KC]\n >         |Constant{-1} [id MS] <int64>\n >Sum{axis=[1], acc_dtype=int64} [id LU] <TensorType(int32, vector)> ''   \n >GpuDimShuffle{0,1} [id MF] <CudaNdarrayType(float32, matrix)> ''   \n >GpuElemwise{Composite{((tanh(i0) * scalar_sigmoid(i1)) + (i2 * scalar_sigmoid(i3)))},no_inplace} [id MT] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuSubtensor{::, int64:int64:} [id MU] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id MV] <CudaNdarrayType(float32, matrix)> ''   \n > | | |<CudaNdarrayType(float32, row)> [id KW] <CudaNdarrayType(float32, row)> -> [id JW]\n > | | |<CudaNdarrayType(float32, matrix)> [id KX] <CudaNdarrayType(float32, matrix)> -> [id FC]\n > | | |<CudaNdarrayType(float32, matrix)> [id KY] <CudaNdarrayType(float32, matrix)> -> [id ES]\n > | | |GpuGemm{inplace} [id MW] <CudaNdarrayType(float32, matrix)> ''   \n > | |   |GpuDot22 [id MX] <CudaNdarrayType(float32, matrix)> ''   \n > | |   | |<CudaNdarrayType(float32, matrix)> [id MY] <CudaNdarrayType(float32, matrix)> -> [id EK]\n > | |   | |<CudaNdarrayType(float32, matrix)> [id LC] <CudaNdarrayType(float32, matrix)> -> [id JR]\n > | |   |TensorConstant{1.0} [id LD] <TensorType(float32, scalar)>\n > | |   |GpuAdvancedSubtensor1 [id MZ] <CudaNdarrayType(float32, matrix)> ''   \n > | |   | |context embedding.W_copy0[cuda] [id LF] <CudaNdarrayType(float32, matrix)> -> [id EP]\n > | |   | |Elemwise{Cast{int64}} [id NA] <TensorType(int64, vector)> ''   \n > | |   |   |<TensorType(int32, vector)> [id NB] <TensorType(int32, vector)> -> [id EL]\n > | |   |<CudaNdarrayType(float32, matrix)> [id LI] <CudaNdarrayType(float32, matrix)> -> [id JM]\n > | |   |TensorConstant{1.0} [id LD] <TensorType(float32, scalar)>\n > | |Constant{2048} [id LJ] <int64>\n > | |Constant{3072} [id LK] <int64>\n > |GpuSubtensor{::, int64:int64:} [id NC] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id MV] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{0} [id LM] <int64>\n > | |Constant{1024} [id LN] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id ND] <CudaNdarrayType(float32, matrix)> -> [id EH]\n > |GpuSubtensor{::, int64:int64:} [id NE] <CudaNdarrayType(float32, matrix)> ''   \n >   |GpuElemwise{Add}[(0, 3)] [id MV] <CudaNdarrayType(float32, matrix)> ''   \n >   |Constant{1024} [id LN] <int64>\n >   |Constant{2048} [id LJ] <int64>\n >GpuElemwise{Composite{tanh((scalar_sigmoid(i0) * i1))},no_inplace} [id NF] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuSubtensor{::, int64:int64:} [id NG] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuElemwise{Add}[(0, 3)] [id MV] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{3072} [id LK] <int64>\n > | |Constant{4096} [id LS] <int64>\n > |GpuElemwise{Composite{((tanh(i0) * scalar_sigmoid(i1)) + (i2 * scalar_sigmoid(i3)))},no_inplace} [id MT] <CudaNdarrayType(float32, matrix)> ''   \n >ViewOp [id NH] <TensorType(int32, vector)> ''   \n > |Elemwise{Cast{int32}} [id NI] <TensorType(int32, vector)> ''   \n >   |Argmax [id NJ] <TensorType(int64, vector)> 'argmax'   \n >Elemwise{Cast{int32}} [id NI] <TensorType(int32, vector)> ''   \n >RandomFunction{uniform}.0 [id LW] <RandomStateType> ''   \n\nforall_inplace,gpu,scan_fn}.1 [id FE] <CudaNdarrayType(float32, 3D)> ''   \n >GpuElemwise{Switch,no_inplace} [id NK] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuFromHost [id NL] <CudaNdarrayType(float32, col)> ''   \n > | |Elemwise{Cast{float32}} [id NM] <TensorType(float32, col)> ''   \n > |   |<TensorType(bool, col)> [id NN] <TensorType(bool, col)> -> [id HM]\n > |GpuElemwise{Composite{((scalar_sigmoid(i0) * i1) + (scalar_sigmoid(i2) * tanh(i3)))},no_inplace} [id NO] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuSubtensor{::, int64:int64:} [id NP] <CudaNdarrayType(float32, matrix)> ''   \n > | | |GpuGemm{no_inplace} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n > | | | |<CudaNdarrayType(float32, matrix)> [id NR] <CudaNdarrayType(float32, matrix)> -> [id GF]\n > | | | |TensorConstant{1.0} [id NS] <TensorType(float32, scalar)>\n > | | | |<CudaNdarrayType(float32, matrix)> [id NT] <CudaNdarrayType(float32, matrix)> -> [id IM]\n > | | | |<CudaNdarrayType(float32, matrix)> [id NU] <CudaNdarrayType(float32, matrix)> -> [id IZ]\n > | | | |TensorConstant{1.0} [id NS] <TensorType(float32, scalar)>\n > | | |Constant{1024} [id NV] <int64>\n > | | |Constant{2048} [id NW] <int64>\n > | |<CudaNdarrayType(float32, matrix)> [id NX] <CudaNdarrayType(float32, matrix)> -> [id HQ]\n > | |GpuSubtensor{::, int64:int64:} [id NY] <CudaNdarrayType(float32, matrix)> ''   \n > | | |GpuGemm{no_inplace} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n > | | |Constant{0} [id NZ] <int64>\n > | | |Constant{1024} [id NV] <int64>\n > | |GpuSubtensor{::, int64:int64:} [id OA] <CudaNdarrayType(float32, matrix)> ''   \n > |   |GpuGemm{no_inplace} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n > |   |Constant{2048} [id NW] <int64>\n > |   |Constant{3072} [id OB] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id NX] <CudaNdarrayType(float32, matrix)> -> [id HQ]\n >GpuElemwise{Composite{Switch(i0, tanh((i1 * scalar_sigmoid(i2))), i3)},no_inplace} [id OC] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuFromHost [id NL] <CudaNdarrayType(float32, col)> ''   \n > |GpuElemwise{Composite{((scalar_sigmoid(i0) * i1) + (scalar_sigmoid(i2) * tanh(i3)))},no_inplace} [id NO] <CudaNdarrayType(float32, matrix)> ''   \n > |GpuSubtensor{::, int64:int64:} [id OD] <CudaNdarrayType(float32, matrix)> ''   \n > | |GpuGemm{no_inplace} [id NQ] <CudaNdarrayType(float32, matrix)> ''   \n > | |Constant{3072} [id OB] <int64>\n > | |Constant{4096} [id OE] <int64>\n > |<CudaNdarrayType(float32, matrix)> [id NT] <CudaNdarrayType(float32, matrix)> -> [id IM]\n\nStorage map footprint:\n - GpuAlloc{memset_0=True}.0, Shape: (2, 36071, 512), ElemSize: 4 Byte(s), TotalSize: 147746816 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.15, Shape: (2, 36071, 512), ElemSize: 4 Byte(s), TotalSize: 147746816 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.4, Shape: (21, 32, 36071), ElemSize: 4 Byte(s), TotalSize: 96958848 Byte(s)\n - GpuSubtensor{::int64}.0, Shape: (21, 32, 36071), ElemSize: 4 Byte(s), TotalSize: 96958848 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.33, Shape: (20, 32, 36071), ElemSize: 4 Byte(s), TotalSize: 92341760 Byte(s)\n - GpuElemwise{maximum,no_inplace}.0, Shape: (32, 20, 36071), ElemSize: 4 Byte(s), TotalSize: 92341760 Byte(s)\n - GpuSubtensor{int64:int64:int8}.0, Shape: (20, 32, 36071), ElemSize: 4 Byte(s), TotalSize: 92341760 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (20, 32, 36071), ElemSize: 4 Byte(s), TotalSize: 92341760 Byte(s)\n - context embedding.W, Shared Input, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - W, Shared Input, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - W, Shared Input, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (36071, 512), ElemSize: 4 Byte(s), TotalSize: 73873408 Byte(s)\n - GpuDimShuffle{0,3,1,2}.0, Shape: (32, 1024, 20, 20), ElemSize: 4 Byte(s), TotalSize: 52428800 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (256, 36071), ElemSize: 4 Byte(s), TotalSize: 36936704 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (256, 36071), ElemSize: 4 Byte(s), TotalSize: 36936704 Byte(s)\n - decoder next word probas.W, Shared Input, Shape: (256, 36071), ElemSize: 4 Byte(s), TotalSize: 36936704 Byte(s)\n - GpuReshape{4}.0, Shape: (32, 20, 20, 512), ElemSize: 4 Byte(s), TotalSize: 26214400 Byte(s)\n - GpuJoin.0, Shape: (1024, 4096), ElemSize: 4 Byte(s), TotalSize: 16777216 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (4096, 1024), ElemSize: 4 Byte(s), TotalSize: 16777216 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (4096, 1024), ElemSize: 4 Byte(s), TotalSize: 16777216 Byte(s)\n - GpuJoin.0, Shape: (1024, 4096), ElemSize: 4 Byte(s), TotalSize: 16777216 Byte(s)\n - GpuJoin.0, Shape: (1024, 4096), ElemSize: 4 Byte(s), TotalSize: 16777216 Byte(s)\n - GpuElemwise{add,no_inplace}.0, Shape: (20, 32, 4096), ElemSize: 4 Byte(s), TotalSize: 10485760 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.22, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.13, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuJoin.0, Shape: (512, 4096), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.21, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.12, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.23, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.11, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.14, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuJoin.0, Shape: (512, 4096), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.20, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (4096, 512), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024, 1024), ElemSize: 4 Byte(s), TotalSize: 8388608 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.19, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.18, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - encoder_lstm.W_hid_to_cell, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_encoder_to_outgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.16, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - encoder_lstm.W_hid_to_forgetgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - encoder_lstm.W_hid_to_ingate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_encoder_to_forgetgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.17, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - encoder_lstm.W_hid_to_outgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 512, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_encoder_to_ingate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_out_to_ingate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_encoder_to_cell, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_out_to_cell, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_out_to_forgetgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - decoder_lstm.W_out_to_outgate, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 1024), ElemSize: 4 Byte(s), TotalSize: 4194304 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.5, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.6, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,scan_fn}.1, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.1, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.1, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - forall_inplace,gpu,scan_fn}.0, Shape: (21, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2752512 Byte(s)\n - GpuSubtensor{int64:int64:int64}.0, Shape: (20, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - GpuDimShuffle{0,2,1}.0, Shape: (20, 1024, 32), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (20, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - GpuSubtensor{int64:int64:int64}.0, Shape: (20, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.34, Shape: (20, 1024, 32), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - GpuSubtensor{int64:int64:int64}.0, Shape: (20, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 2621440 Byte(s)\n - encoder_lstm.W_in_to_ingate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - encoder_lstm.W_in_to_forgetgate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - encoder_lstm.W_in_to_outgate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - decoder_lstm.W_emb_to_cell, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - decoder_lstm.W_emb_to_forgetgate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - encoder_lstm.W_in_to_cell, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - decoder_lstm.W_emb_to_outgate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - decoder_lstm.W_emb_to_ingate, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (512, 1024), ElemSize: 4 Byte(s), TotalSize: 2097152 Byte(s)\n - GpuJoin.0, Shape: (100, 4096), ElemSize: 4 Byte(s), TotalSize: 1638400 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (4096, 100), ElemSize: 4 Byte(s), TotalSize: 1638400 Byte(s)\n - GpuReshape{2}.0, Shape: (640, 512), ElemSize: 4 Byte(s), TotalSize: 1310720 Byte(s)\n - persona_based.emb.W, Shared Input, Shape: (3194, 100), ElemSize: 4 Byte(s), TotalSize: 1277600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (3194, 100), ElemSize: 4 Byte(s), TotalSize: 1277600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (3194, 100), ElemSize: 4 Byte(s), TotalSize: 1277600 Byte(s)\n - decoder intermediate.W, Shared Input, Shape: (1024, 256), ElemSize: 4 Byte(s), TotalSize: 1048576 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 256), ElemSize: 4 Byte(s), TotalSize: 1048576 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (1024, 256), ElemSize: 4 Byte(s), TotalSize: 1048576 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.26, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.25, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.24, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.27, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 100, 1024), ElemSize: 4 Byte(s), TotalSize: 819200 Byte(s)\n - W, Shared Input, Shape: (20, 1024, 3, 3), ElemSize: 4 Byte(s), TotalSize: 737280 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.35, Shape: (20, 32, 256), ElemSize: 4 Byte(s), TotalSize: 655360 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.32, Shape: (20, 256, 32), ElemSize: 4 Byte(s), TotalSize: 655360 Byte(s)\n - GpuDot22.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - GpuDot22.0, Shape: (32, 4096), ElemSize: 4 Byte(s), TotalSize: 524288 Byte(s)\n - decoder_lstm.W_persona_based.each_tick_to_cell, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - decoder_lstm.W_persona_based.each_tick_to_outgate, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - decoder_lstm.W_persona_based.each_tick_to_forgetgate, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - decoder_lstm.W_persona_based.each_tick_to_ingate, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - <CudaNdarrayType(float32, matrix)>, Shared Input, Shape: (100, 1024), ElemSize: 4 Byte(s), TotalSize: 409600 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 36071), ElemSize: 4 Byte(s), TotalSize: 288568 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.29, Shape: (2, 36071), ElemSize: 4 Byte(s), TotalSize: 288568 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 262144 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.31, Shape: (2, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 262144 Byte(s)\n - decoder next word probas.b, Shared Input, Shape: (36071,), ElemSize: 4 Byte(s), TotalSize: 144284 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (36071,), ElemSize: 4 Byte(s), TotalSize: 144284 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (36071,), ElemSize: 4 Byte(s), TotalSize: 144284 Byte(s)\n - GpuDimShuffle{x,0}.0, Shape: (1, 36071), ElemSize: 4 Byte(s), TotalSize: 144284 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (1024, 32), ElemSize: 4 Byte(s), TotalSize: 131072 Byte(s)\n - GpuSubtensor{int64}.0, Shape: (32, 1024), ElemSize: 4 Byte(s), TotalSize: 131072 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.6, Shape: (1, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 131072 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.5, Shape: (1, 32, 1024), ElemSize: 4 Byte(s), TotalSize: 131072 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.30, Shape: (2, 32, 100), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 32, 100), ElemSize: 4 Byte(s), TotalSize: 25600 Byte(s)\n - GpuDimShuffle{x,0}.0, Shape: (1, 4096), ElemSize: 4 Byte(s), TotalSize: 16384 Byte(s)\n - W, Shared Input, Shape: (20, 20, 3, 3), ElemSize: 4 Byte(s), TotalSize: 14400 Byte(s)\n - W, Shared Input, Shape: (180, 20), ElemSize: 4 Byte(s), TotalSize: 14400 Byte(s)\n - GpuAdvancedSubtensor1.0, Shape: (32, 100), ElemSize: 4 Byte(s), TotalSize: 12800 Byte(s)\n - GpuDimShuffle{1,0}.0, Shape: (100, 32), ElemSize: 4 Byte(s), TotalSize: 12800 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.10, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.7, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.8, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.9, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 1024), ElemSize: 4 Byte(s), TotalSize: 8192 Byte(s)\n - Elemwise{Cast{int64}}.0, Shape: (640,), ElemSize: 8 Byte(s), TotalSize: 5120 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.b_forgetgate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.cell_init, Shared Input, Shape: (1, 1024), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.hid_init, Shared Input, Shape: (1, 1024), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.b_cell, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - decoder_lstm.b_to_outgate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.b_ingate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - encoder_lstm.b_outgate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - decoder_lstm.b_to_ingate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - decoder_lstm.b_to_forgetgate, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - decoder_lstm.b_to_cell, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (1024,), ElemSize: 4 Byte(s), TotalSize: 4096 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.3, Shape: (21, 32), ElemSize: 4 Byte(s), TotalSize: 2688 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.2, Shape: (21, 32), ElemSize: 4 Byte(s), TotalSize: 2688 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32), ElemSize: 4 Byte(s), TotalSize: 2688 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.2, Shape: (21, 32), ElemSize: 4 Byte(s), TotalSize: 2688 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (21, 32), ElemSize: 4 Byte(s), TotalSize: 2688 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (20, 32), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - InplaceDimShuffle{1,0}.0, Shape: (32, 20), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - Subtensor{int64:int64:int64}.0, Shape: (20, 32), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - encoder phrase tokens, Input, Shape: (32, 20), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.8, Shape: (20, 32), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - GpuFromHost.0, Shape: (32, 20), ElemSize: 4 Byte(s), TotalSize: 2560 Byte(s)\n - forall_inplace,gpu,grad_of_scan_fn}.28, Shape: (2, 256), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - GpuAlloc{memset_0=True}.0, Shape: (2, 256), ElemSize: 4 Byte(s), TotalSize: 2048 Byte(s)\n - decoder intermediate.b, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - GpuDimShuffle{x,0}.0, Shape: (1, 256), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - <CudaNdarrayType(float32, vector)>, Shared Input, Shape: (256,), ElemSize: 4 Byte(s), TotalSize: 1024 Byte(s)\n - Elemwise{neq,no_inplace}.0, Shape: (20, 32, 1), ElemSize: 1 Byte(s), TotalSize: 640 Byte(s)\n - InplaceDimShuffle{0,x}.0, Shape: (32, 1), ElemSize: 8 Byte(s), TotalSize: 256 Byte(s)\n - Elemwise{Cast{int64}}.0, Shape: (32,), ElemSize: 8 Byte(s), TotalSize: 256 Byte(s)\n - W, Shared Input, Shape: (20, 2), ElemSize: 4 Byte(s), TotalSize: 160 Byte(s)\n - InplaceDimShuffle{x,0}.0, Shape: (1, 20), ElemSize: 8 Byte(s), TotalSize: 160 Byte(s)\n - personality idxs, Input, Shape: (32,), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - forall_inplace,gpu,scan_fn&scan_fn}.7, Shape: (1, 32), ElemSize: 4 Byte(s), TotalSize: 128 Byte(s)\n - b, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - b, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - b, Shared Input, Shape: (20,), ElemSize: 4 Byte(s), TotalSize: 80 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - TensorConstant{[ -1  20  20 512]}, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (4,), ElemSize: 8 Byte(s), TotalSize: 32 Byte(s)\n - MakeVector{dtype='int64'}.0, Shape: (3,), ElemSize: 8 Byte(s), TotalSize: 24 Byte(s)\n - TensorConstant{(2,) of 0}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(2,) of 2}, Shape: (2,), ElemSize: 8 Byte(s), TotalSize: 16 Byte(s)\n - TensorConstant{(1,) of -1}, Shape: (1,), ElemSize: 8 Byte(s), TotalSize: 8 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-20}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{204800}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((i0 - (i1 + i0 + i2)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{maximum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(i0, i1, maximum(minimum((i2 + i3), i4), i5))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{4096}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{maximum(maximum(((i0 - Switch(i1, (i2 + i3), i2)) + i4), i5), maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i11, i12, i3), i8, i9), i3, i13, i4), i8, i13), i8, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i13), i8), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), i5, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i6, i7, i3, i8, i9, i10) + i4), i8))) + i4), i5))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Identity}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(i0, i1), (i0 + i2), (i0 - i1)) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{maximum(maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i1 + i2), (i3 + i2), i4, i5), i4, (i1 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i1 + i2), i4))) + i2), i6), maximum(((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i7 + i2), (i8 + i2), i4, i5), i4, (i7 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i7 + i2), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((i7 + i2), (i8 + i2), i4, i5), i4, (i7 + i2), i5), i4), Composite{Switch(LT(i0, i1), i1, i0)}((i7 + i2), i4))) + i2), i6))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6), i5), i7, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, maximum(i2, (i3 - i4)))}(i0, i1, i2, i3, i4), i1, i5), i1, i6))}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - b, Shared Input, Shape: (2,), ElemSize: 4 Byte(s), TotalSize: 8 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{Switch(LT(i0, i1), i1, i0)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i1, i2, (i3 - i4), i5, i6, i7, i8), i2, i9), i2, i10), i9), i9, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(LT(i0, i1), (i0 + i2), i0)}(Composite{Switch(i0, i1, Switch(AND(LT(i2, i1), GT(i3, i1)), i4, maximum((i5 + i6), i2)))}(i1, i2, (i3 - i4), i5, i6, i7, i8), i2, i9), i2, i10))) - i11) // i12)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{0}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i8, i9, i3), i4, i5), i3, i6, i7), i4, i6), i4, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i6), i4), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i4)), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), Composite{((((i0 - Switch(GE(i1, i2), i2, i1)) - i3) // i4) + i4)}(Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i8, i9, i3), i4, i5), i3, i6, i7), i4, i6), i4, (Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i6), i4), Composite{Switch(LT(i0, i1), i1, i0)}((Composite{Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4), i2), (i2 - i5), Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i0, i1, i2), i3, i4))}(i1, i2, i3, i4, i5, i6) + i7), i4))) + i7)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((i0 - Switch(LT(Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}(i1, (i2 + i3), i4, i5), i4, i1, i5), i4), i6), Composite{Switch(LT(i0, i1), i1, i0)}(Composite{Switch(LT(i0, i1), (i2 - i3), i0)}(Composite{((i0 - (Switch(LT(i1, i2), i2, i1) - i3)) - i3)}(i1, (i2 + i3), i4, i5), i4, i1, i5), i4), i6)) + i3)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5), i3), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5))) - i6) // i7)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(Switch(LT(maximum(i0, i1), i2), (maximum(i0, i1) + i3), (maximum(i0, i1) - i2)) + i3)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{9}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{sub,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{3072}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{mul,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{20}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{add,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{minimum,no_inplace}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{((i0 - i1) + i2)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1024}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{36071}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - ScalarFromTensor.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{-2}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Elemwise{Composite{(((i0 - Switch(GE(Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5), i3), i3, Composite{Switch(LT(i0, i1), i2, i0)}(Composite{Switch(i0, (i1 + i2), i1)}(i1, i2, i3), i4, i5))) - i6) // i7)}}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Constant{-1}, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - Shape_i{1}.0, Shape: (), ElemSize: 8 Byte(s), TotalSize: 8.0 Byte(s)\n - <TensorType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.89999998]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{10.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <TensorType(int32, scalar)>, Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.10000002]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[ 0.01]]]}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.899999976158}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Constant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{0.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[ 0.00099999]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuDimShuffle{x,x}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{1.00000001169e-07}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{0.999000012875}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{36071}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuElemwise{Composite{((i0 * sqrt((i1 - (i2 ** i3)))) / (i1 - (i4 ** i3)))},no_inplace}.0, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - <CudaNdarrayType(float32, scalar)>, Shared Input, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[ 0.01]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.10000002]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.89999998]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[-1.]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[  1.00000001e-10]]]}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{9.99999974738e-06}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - GpuDimShuffle{x}.0, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.00099999]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[[ 0.]]]}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - GpuElemwise{sqr,no_inplace}.0, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1) of 36069}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - Constant{1.0}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - CudaNdarrayConstant{[[  9.99999994e-09]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[  9.99999994e-09]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{(1, 1, 1) of 36070}, Shape: (1, 1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[[ 0.99900001]]}, Shape: (1, 1), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - CudaNdarrayConstant{[ 0.99900001]}, Shape: (1,), ElemSize: 4 Byte(s), TotalSize: 4 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 4 Byte(s), TotalSize: 4.0 Byte(s)\n - TensorConstant{1024}, Shape: (), ElemSize: 2 Byte(s), TotalSize: 2.0 Byte(s)\n - TensorConstant{-1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{0}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{3}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1, 1) of 0}, Shape: (1, 1), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - TensorConstant{2}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{lt,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{20}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{Composite{AND(LT(i0, i1), GT(i2, i1))}}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{(1, 1) of True}, Shape: (1, 1), ElemSize: 1 Byte(s), TotalSize: 1 Byte(s)\n - Constant{1}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - Elemwise{le,no_inplace}.0, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n - TensorConstant{3}, Shape: (), ElemSize: 1 Byte(s), TotalSize: 1.0 Byte(s)\n TotalSize: 1685981947.0 Byte(s) 1.570 GB\n TotalSize inputs: 694709416.0 Byte(s) 0.647 GB\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'."
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    for _ in range(1):\n",
    "        for bx, by, respondent in generate_data(data_rows, speakers_list=speakers_list, n_iter=3, max_len=seq_len):\n",
    "            err = pg_trainer.train_step(bx, respondent, 20)\n",
    "            gen_train_errors.append(err)\n",
    "        print(\"Gen %.5f\"%err)\n",
    "    for _ in range(6):\n",
    "        for bx, by, respondent in generate_data(data_rows, speakers_list=speakers_list, n_iter=8, max_len=seq_len):\n",
    "            err, infoloss = conv_discriminator.train_step(bx, by, respondent, 20, sample_c(respondent))\n",
    "            discr_train_errors.append(err)\n",
    "            info_train_errors.append(infoloss)\n",
    "        print(\"Discr %.5f\"%err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA74AAAEICAYAAAB4cihAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nImrS2PAlIiIiIiKiJu3/A2nsWAl8Bp7+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2423f467d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Information\")\n",
    "plot_smoothed(info_train_errors, n=1000);\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Generator loss\")\n",
    "plot_smoothed(gen_train_errors, n=100)\n",
    "# plt.plot(gen_train_errors)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Discriminator loss\")\n",
    "plot_smoothed(discr_train_errors, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['friend', 'timmy'],\n",
       " [\"you ' re the best friend in the whole world ! i ' m afraid you don ' t know\",\n",
       "  'timmy !'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_in_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['tom', 'son', 'butters', 'timmy'],\n",
       " [\"tom , i ' m standing in south park , where the address has been reported and rapido\",\n",
       "  'thank you all . hey , this is a very simple answer , son . truth or human organization is',\n",
       "  \"ah i ' m token ' s friend . i ' m butters ' private friend in the world he\",\n",
       "  '_UNK_ timmy !'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_in_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(7.384118961709744)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.get_perplexity_fn(bx, respondent, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('test_batches.pcl', 'rb') as f:\n",
    "    test_batches = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2423f50550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2423f12090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outs = []\n",
    "real_outs = []\n",
    "for bx, by, respondent in test_batches:\n",
    "    outs.append(get_discr_out_on_fake(bx, respondent, 20))\n",
    "    real_outs.append(get_discr_out_on_real(bx, by))\n",
    "outs = np.concatenate(outs)\n",
    "real_outs = np.concatenate(real_outs)\n",
    "plt.hist(outs, bins=100);\n",
    "plt.show()\n",
    "plt.hist(real_outs, bins=100);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98963281250000001"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(len(outs) * [0] + len(real_outs) * [1], np.concatenate([outs, real_outs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0768643\n",
      "GENERATED:  oho kay , others , you don ' t want to learn all your stupid stuff like that .\n",
      "0.374519\n",
      "GENERATED:  my name is billy , and i feel like i ' m deep inside some space ship . if i\n",
      "3.82923e-09\n",
      "GENERATED:  jesus christ . it was a real disease .\n",
      "0.00285682\n",
      "GENERATED:  skeeter . u - uh . it looks like the red mega man ' s pet won by a shark\n",
      "0.0367845\n",
      "GENERATED:  my name is cameron , and this is my name . . . my b - b - bu -\n",
      "1.01067e-08\n",
      "GENERATED:  this is earth day world\n",
      "1.73698e-10\n",
      "GENERATED:  my name is randy marsh . my name is sharon .\n",
      "2.36476e-16\n",
      "GENERATED:  hyeah !\n",
      "9.39646e-10\n",
      "GENERATED:  kyle broflovski . he ' s a very smart boy .\n",
      "4.76818e-11\n",
      "GENERATED:  peter\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    name_id = 439\n",
    "    name_batch =  phrase_to_matrix([[\"Hello\", \"Hello\", \"What is your name ? \"]], max_len=20)\n",
    "    #att_seqs = attention_discriminator.get_attention_fake(name_batch, [name_id], 20)\n",
    "    gen_answer, gen_reward = test_discr_fn(name_batch, [name_id], 20)\n",
    "    gen_answer = ' '.join(phrase_from_idx(gen_answer[0], crop_by_eos=True))\n",
    "    print gen_reward[0, 1]\n",
    "    print \"GENERATED: \", gen_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is stan marsh . i ' m from the future .\n",
      "kyle broflovski .\n",
      "my name is randy marsh . i ' m a man from a long line . i ' m a\n",
      "kyle broflovski .\n",
      "my name is randy marsh . i ' m from the future .\n"
     ]
    }
   ],
   "source": [
    "temperature.set_value(np.float32(0.5))\n",
    "for i in range(5):\n",
    "    print(generator.reply([\"Hello!\", \"Hello\", \"What is your name ?\"], 439))\n",
    "    \n",
    "temperature.set_value(np.float32(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.89896e-10\n",
      "what ? _EOS_ ( no , fuck you ! she ' s my girl ! ) _EOS_ you ' re\n",
      "REAL:  this must be decided at the _UNK_ in _UNK_ !\n",
      "GENERATED:  i ' m just an ignorant asshole like you .\n",
      "2.31016e-13\n",
      "my god , you ' re right . _EOS_ _EOS_ how ' s it goin ' , fat ass ?\n",
      "REAL:  i haven ' t made any money yet .\n",
      "GENERATED:  wait , what a bunch of five - darra\n",
      "0.00412678\n",
      "\" give a hoot , don ' t pollute , \" m ' kay . _EOS_ hi , i '\n",
      "REAL:  alright kids , time to split up and go into the forest . let ' s divide you all up\n",
      "GENERATED:  please , give me a call . i ' ve got some chili fudge in your mom ' s office\n",
      "3.03877e-14\n",
      "whoa . . . _EOS_ i have been sent from japan to serve as your personal robot . _EOS_ you\n",
      "REAL:  yes . i will be your new best friend .\n",
      "GENERATED:  now drive faster !\n",
      "3.49266e-06\n",
      "all right , let ' s get the hell out of here ! _EOS_ _EOS_ aah ! run , dude\n",
      "REAL:  k ' plagh ! k ' plagh !\n",
      "GENERATED:  did he ever do that ? do you think he knows what it means ? !\n",
      "0.410501\n",
      "that ' s better . _EOS_ don ' t call _EOS_ uh , hello ? we are having a bake\n",
      "REAL:  wow , what a great audience . i just flew into south park . boy , are my crutches tired\n",
      "GENERATED:  nono , w - why did you come up and pick up the pan ? i gotta figure you out\n",
      "5.05004e-06\n",
      "my god , it ' s beautiful . it never fails to amaze me how i manage to overcome adversity\n",
      "REAL:  uhhh , i ' m not sure ; i never made one this big .\n",
      "GENERATED:  we are in\n",
      "2.09762e-05\n",
      "here we see the constellation called , \" the big dipper \" . if i project a drawing of a\n",
      "REAL:  \n",
      "GENERATED:  ,\n",
      "1.65728e-05\n",
      "well those aren ' t left hands . _EOS_ ohhh . _EOS_ nope , this isn ' t our man\n",
      "REAL:  ( hey ! help ! )\n",
      "GENERATED:  oh . watch kyle .\n",
      "0.0348084\n",
      "we ' re going to have to rethink cities ! _EOS_ now , it is easily operated using four flexigrip\n",
      "REAL:  . . . there we go . now , the final flexigrip is directly in front of the driver so\n",
      "GENERATED:  but our best is to make sure that veteran monitors are in control of something very dangerous !\n",
      "0.0528677\n",
      "oh yeah . there he is . that ' s jeffy . _EOS_ that don ' t look like a\n",
      "REAL:  hey , he - is that the only song he ' ll dance to ?\n",
      "GENERATED:  dude , i don ' t get it now . all i know was , he lived a long time\n",
      "0.0950333\n",
      "young man , i am the adult here , and i say you go _EOS_ look : you can stay\n",
      "REAL:  nononono ! you\n",
      "GENERATED:  hello , eric . you ' re a little confused . . . ' cause i was to stop by\n",
      "0.00143945\n",
      "kenny ! what ' s it doing ? _EOS_ this says \" maximum . \" _EOS_ we ' re bastards\n",
      "REAL:  dude , i told you something was up with this place !\n",
      "GENERATED:  nobody move ! this isn ' t gonna stop until we ' ve reached the union !\n",
      "0.0173899\n",
      "yes . yeh - yes she did . _EOS_ okay , and she ' s telling me there ' s\n",
      "REAL:  must be from somewhere else in the audience , then . uh , d ' uh , money ? is\n",
      "GENERATED:  hey uh , wait a minute . shouldn ' t you check out your future self ?\n",
      "6.27372e-07\n",
      "gaaah ! _EOS_ kyle ! _EOS_ yeah , it was the craziest thing . i hid myself on a plane\n",
      "REAL:  so dude , did cartman ' s idea work ?\n",
      "GENERATED:  okay , come on . i ' ll kill him .\n",
      "0.0681706\n",
      "_EOS_ it just so happens that mr . twig is far more stable than mr . hat could ever be\n",
      "REAL:  how\n",
      "GENERATED:  that ' s true . thank god for the cut - up girls at last year ' s eve .\n",
      "0.000371413\n",
      "it ' s finally over , cartman . you lost ! _EOS_ yeah . and now you can take that\n",
      "REAL:  boys , as president of the united states , i want to commend you for stopping the rebel uprising .\n",
      "GENERATED:  ow ! hey , wait a minute , does this mean i ' ll cheat .\n",
      "0.111369\n",
      "oh it ' s so good to have you acting like yourself again , sweetie . _EOS_ well , come\n",
      "REAL:  it ' s still in baggage claims !\n",
      "GENERATED:  ike , i ' m sorry i didn ' t do drugs , okay , you guys . you can\n",
      "2.93571e-08\n",
      "god did ! when he killed my wife ! _EOS_ all right , the person who had head lice needs\n",
      "REAL:  okay , whoever you are , you are now not only a _UNK_ , you ' re a liar !\n",
      "GENERATED:  b - b - bu - _UNK_ ! screw that ! i screwed up !\n",
      "0.00269585\n",
      "you in here , peter ? _EOS_ oh hay , paul . come on in and meet the broflovskis _EOS_\n",
      "REAL:  hello .\n",
      "GENERATED:  well sure . you got nothing against people from joining our cartoons . all they ever do is just dumb\n",
      "1.50049e-07\n",
      "yes , john travolta and tom cruise are big scientologist ' s . do you believe me nooow ? _EOS_\n",
      "REAL:  l . ron ?\n",
      "GENERATED:  ooo , _UNK_ - i ' m sorry .\n",
      "0.025702\n",
      "( well yep , that ' s what i think . ) _EOS_ yeah , maybe you ' re right\n",
      "REAL:  go ahead . we don ' t wanna be in their stupid commercial .\n",
      "GENERATED:  whoa . i told you , i don ' t wanna see how much you lose your time , jenner\n",
      "0.160668\n",
      "i kept the crap in my office , nursed it , fed it biddy . and soon biddy made him\n",
      "REAL:  that ' s why he ' s able to do so much , try to help so many people ,\n",
      "GENERATED:  dad , i know , but i don ' t know what else to do . he ' s just\n",
      "3.79884e-07\n",
      "so what ? ! _EOS_ so he got hiv like fifty years ago , and he ' s still totally\n",
      "REAL:  my god . . .\n",
      "GENERATED:  look , kid , i didn ' t know\n",
      "0.0248293\n",
      "kyle ! ! _EOS_ _UNK_ - _EOS_ please ! i didn ' t help the terrorists get into imaginationland !\n",
      "REAL:  that is for the council of nine to decide !\n",
      "GENERATED:  uhh , in the france - raising college - equipment , cows take us all in order to get our\n",
      "1.31472e-06\n",
      "oohh , you look great , hon . mommy ' s fat little piggy . _EOS_ _UNK_ ! _EOS_ okay\n",
      "REAL:  \n",
      "GENERATED:  okay , now that one little boy is shakey ' s\n",
      "3.4945e-25\n",
      "very funny ! _EOS_ hi , uh , i ' m a pepper , and i ' m wondering if\n",
      "REAL:  yeah .\n",
      "GENERATED:  heh kawaii ?\n",
      "1.42e-06\n",
      "are you joking ? ! _EOS_ well , you are a little late , like , i dunno , maybe\n",
      "REAL:  sounds good . now get the fuck out of here .\n",
      "GENERATED:  are you seriously askin ' me anything ? !\n",
      "0.204692\n",
      "there it is ! _EOS_ that ' s kenny with branches on his head . _EOS_ cartman , jakovasaurs are\n",
      "REAL:  well , what does that have to do with me being all the way out . . . ? wait\n",
      "GENERATED:  no , uh i don ' t know what to do . it ' s just a little cold .\n",
      "0.0639676\n",
      "kewl , nascar ! sweet ! _EOS_ \" [ _UNK_ ] \" oh , fuck my ass ! _EOS_ eric\n",
      "REAL:  all that work . . . all the effort i put in . . . i still wasn ' t\n",
      "GENERATED:  okay . i made a deal with kyle . hey ! come on ! we ' re not pirates ,\n",
      "1.36576e-05\n",
      "we ' re just having a hard time finding him . _EOS_ slash is not hard to find ! he\n",
      "REAL:  mr . peters , can i call you back ? our company accountant needs me . yes , he is\n",
      "GENERATED:  yeah . )\n",
      "1.35268e-07\n",
      "what ? _EOS_ using stem cells is like playing god . you should leave nature alone . _EOS_ and go\n",
      "REAL:  i ' m saying that sometimes you need to just live with the cards you ' re dealt , christopher\n",
      "GENERATED:  are you having a real laugh ?\n"
     ]
    }
   ],
   "source": [
    "gen_answers, gen_rewards = test_discr_fn(one_batch[0], one_batch[2], 20)\n",
    "gen_answers = [' '.join(phrase_from_idx(gen_answers[j], crop_by_eos=True)) for j in range(len(one_batch[1]))]\n",
    "answers =  [' '.join(phrase_from_idx(one_batch[1][j], crop_by_eos=True)) for j in range(len(one_batch[1]))]\n",
    "discr_reward = gen_rewards[:, 1]\n",
    "#att_seqs = attention_discriminator.get_attention_real(one_batch[0], one_batch[1])\n",
    "for i in range(one_batch[0].shape[0]):\n",
    "    print discr_reward[i]\n",
    "    print ' '.join(phrase_from_idx(one_batch[0][i]))\n",
    "    print \"REAL: \", answers[i]\n",
    "    print \"GENERATED: \", gen_answers[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.learning.generic import get_values_for_actions\n",
    "\n",
    "class conv_log_gan_trainer:    \n",
    "    \n",
    "    rewards = T.log(conv_discriminator.output_on_fake[:, 1])\n",
    "    baseline = T.log(conv_discriminator.output_on_greedy_fake[:, 1])\n",
    "\n",
    "    advantage = rewards - baseline\n",
    "\n",
    "    policy = T.maximum(generator.probs, 1e-10)\n",
    "    log_policy = T.log(policy)\n",
    "    \n",
    "    #policy gradient\n",
    "    J = log_policy * advantage[:,None]\n",
    "    \n",
    "    loss = -J.mean()\n",
    "    \n",
    "    \n",
    "    #regularize with negative entropy\n",
    "    entropy = -T.sum(policy * log_policy, axis=-1)\n",
    "\n",
    "    loss -= 0.01 * entropy.mean()\n",
    "\n",
    "    grads = T.grad(loss, generator.weights)\n",
    "    grads = lasagne.updates.total_norm_constraint(grads, 10)\n",
    "\n",
    "    updates = lasagne.updates.adam(grads, model.weights, learning_rate=1e-5) \n",
    "\n",
    "    train_step = theano.function([encoder.input_sequence],loss,\n",
    "                                 updates = model.auto_updates+model.greedy_auto_updates+updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions, policy = generator.out[:, :-1], generator.probs[:, :-1]\n",
    "policy = T.maximum(policy, 1e-10)\n",
    "\n",
    "def one_step_reward(step_idx, gen_out):\n",
    "    return get_output(conv_discriminator.discr, \n",
    "                                            {conv_discriminator.question: encoder.input_phrase,\n",
    "                                             conv_discriminator.answer: gen_out[:, :step_idx+1], \n",
    "                                          })[:, 1]\n",
    "\n",
    "def one_step_reward_and_value(step_idx, gen_out):\n",
    "    assert False, \"Implement me\"\n",
    "    #output_on_fake = get_output(discr, {question: encoder.input_phrase, answer: generator.out})\n",
    "    #output_on_real = get_output(discr, {question: encoder.input_phrase, answer: reference_answers_var})\n",
    "    curr_reward, state_value = get_output([conv_discriminator.l_prob, baseline_discriminator.l_prob], \n",
    "                                            {discriminator.l_in: generator.out[:, :step_idx+1], \n",
    "                                            discriminator.l_mask: get_mask_from_end_indicator(\n",
    "                                                                       T.eq(generator.out[:, :step_idx+1], EOS_ix)),\n",
    "                                           baseline_discriminator.l_in: gen_out[:, :step_idx+1], \n",
    "                                            baseline_discriminator.l_mask: get_mask_from_end_indicator(\n",
    "                                                                           T.eq(gen_out[:, :step_idx+1], EOS_ix))\n",
    "                                          })\n",
    "    \n",
    "    return (curr_reward[:, 1], state_value[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rewards, scan_updates = theano.scan(one_step_reward, sequences=[theano.tensor.arange(seq_len)],\n",
    "                                       non_sequences=[actions])\n",
    "rewards = rewards.T[:, :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.learning import reinforce\n",
    "\n",
    "reinforce_loss = reinforce.get_elementwise_objective(policy, actions, rewards).mean()\n",
    "gen_updates = lasagne.updates.adam(reinforce_loss, generator.weights, learning_rate=0.001)\n",
    "train_pg_step = theano.function([encoder.input_phrase, person_id_var, generator.n_steps],\n",
    "                                rewards.mean(), updates=generator.recurrence.get_automatic_updates() + gen_updates,\n",
    "                              allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 20), (32, 20), (32,))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx.shape, by.shape, respondent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "perplexity_values = []\n",
    "for bx, by, respondent in generate_data(data_rows, speakers_list=speakers_list, n_iter=100, max_len=seq_len):\n",
    "    perplexity_values.append(generator.get_perplexity_fn(bx, respondent, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "test_batches = [[bx, by, respondent] for bx, by, respondent in \n",
    "                generate_data(data_rows, speakers_list=speakers_list, n_iter=100, max_len=seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('test_batches.pcl', 'wb') as f:\n",
    "#     pickle.dump(test_batches, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('test_batches.pcl', 'rb') as f:\n",
    "    test_batches = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perplexity_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bx, by, respondent in test_batches:\n",
    "    perplexity_values.append(generator.get_perplexity_fn(bx, respondent, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.436289622399606"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(perplexity_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "persona_based_loss = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_train_errors = []\n",
    "discr_train_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1266"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_ix['Mother']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mother_phrases_idxs = []\n",
    "for i, idx in enumerate(speakers_list):\n",
    "    if idx == 1266:\n",
    "        mother_phrases_idxs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3079,\n",
       " 3082,\n",
       " 3084,\n",
       " 6993,\n",
       " 9316,\n",
       " 25085,\n",
       " 25089,\n",
       " 26662,\n",
       " 26664,\n",
       " 26666,\n",
       " 26668,\n",
       " 26670,\n",
       " 26675,\n",
       " 48338,\n",
       " 48340,\n",
       " 60755,\n",
       " 62422,\n",
       " 72981,\n",
       " 72983,\n",
       " 74786]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mother_phrases_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3076,  3079,  3081,  6990,  9313, 25082, 25086, 26659, 26661,\n",
       "       26663, 26665, 26667, 26672, 48335, 48337, 60752, 62419, 72978,\n",
       "       72980, 74783])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(mother_phrases_idxs) - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mother_contexts = [[data_rows[idx-3], data_rows[idx-2], data_rows[idx-1]] for idx in mother_phrases_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT\n",
      "_UNK_ . could you have them turn up the light s a little , please ? [ the waiter goes away ] _EOS_\n",
      "oh , look at it , gerald . all the new families moving in . [ a new mexican restaurant - _UNK_ _UNK_ - is having its grand opening across the street ] our little town is all grown up . _EOS_\n",
      "where ' s that other taco plate ? we need it now . _EOS_\n",
      "ANSWER\n",
      "OUR: you want us to tell you what we want to do ?\n",
      "REAL: i ' m a little overwhelmed . _EOS_\n",
      "CONTEXT\n",
      "i ' m a little overwhelmed . _EOS_\n",
      "i know . but we ' ve put everything into moving here and starting this business , and we have to be impressive . [ walks up to the boy and gets down on one knee ] _UNK_ , you must help your mama however you can . we ' re not going back to that miserable place ! _EOS_\n",
      "i don ' t wanna go back either . _EOS_\n",
      "ANSWER\n",
      "OUR: i ' m not sure .\n",
      "REAL: okay , done . _EOS_\n",
      "CONTEXT\n",
      "i don ' t wanna go back either . _EOS_\n",
      "okay , done . _EOS_\n",
      "great ! [ rises and goes for the plates ] we really have to impress this customer . he ' s the local food critic . [ rushes the plates out to the dining area ] _EOS_\n",
      "ANSWER\n",
      "OUR: well , we ' re not going to be part of the family now , so we ' re not\n",
      "REAL: another one ? _EOS_\n",
      "CONTEXT\n",
      "get out ! _EOS_\n",
      "you son of a bitch ! rip it down ! get out ! _EOS_\n",
      "you lied to me , mother . you said it was the _EOS_\n",
      "ANSWER\n",
      "OUR: i told you , i ' m not a big deal . i ' m not a _UNK_ .\n",
      "REAL: _UNK_ , yes , but - _EOS_\n",
      "CONTEXT\n",
      "_EOS_\n",
      "yea ! / hooray ! / summer ! _EOS_\n",
      "_EOS_\n",
      "ANSWER\n",
      "OUR: well , it was just a dream .\n",
      "REAL: oh golly , kevin , honey . _EOS_\n",
      "CONTEXT\n",
      "you ' re not gonna make my daughter part of your cult ! _EOS_\n",
      "your daughter could die tomorrow , and then what ? ! _EOS_\n",
      "you ' re just a stupid little fat kid who thinks that - - _EOS_\n",
      "ANSWER\n",
      "OUR: hey , uh , guys , can we get to the clubhouse ?\n",
      "REAL: stephen ? _EOS_\n",
      "CONTEXT\n",
      "the lord has spoken again - uh ! o , forgive us , lord , for our sins - uh ! _EOS_\n",
      "forgive us , lord . _EOS_\n",
      "let us pray . _EOS_\n",
      "ANSWER\n",
      "OUR: we are not afraid to die . we are not .\n",
      "REAL: stephen ? _EOS_\n",
      "CONTEXT\n",
      "huh , where are we goin ' ? _EOS_\n",
      "we ' re gon ' tuh take cartman ' s kidney . _EOS_\n",
      "_EOS_\n",
      "ANSWER\n",
      "OUR: you ' re a good boy , stan .\n",
      "REAL: _EOS_\n",
      "CONTEXT\n",
      "_EOS_\n",
      "_EOS_\n",
      "mom . . . do you ever have those heavy flow days ? _EOS_\n",
      "ANSWER\n",
      "OUR: i think it ' s time for me to go to sleep .\n",
      "REAL: oh absolutely sweetheart , everybody does . _EOS_\n",
      "CONTEXT\n",
      "mom . . . do you ever have those heavy flow days ? _EOS_\n",
      "oh absolutely sweetheart , everybody does . _EOS_\n",
      "mom , remember the movie _EOS_\n",
      "ANSWER\n",
      "OUR: no !\n",
      "REAL: oh honey what you need is a more absorbent tampon . _EOS_\n",
      "CONTEXT\n",
      "mom , remember the movie _EOS_\n",
      "oh honey what you need is a more absorbent tampon . _EOS_\n",
      "like what ? _EOS_\n",
      "ANSWER\n",
      "OUR: it ' s alright .\n",
      "REAL: well , what ' s the most absorbent thing in the world ? _EOS_\n",
      "CONTEXT\n",
      "like what ? _EOS_\n",
      "well , what ' s the most absorbent thing in the world ? _EOS_\n",
      "well . . . cherokee hair i guess . _EOS_\n",
      "ANSWER\n",
      "OUR: yeah , i think we should go see the kids .\n",
      "REAL: _EOS_\n",
      "CONTEXT\n",
      "_EOS_\n",
      "_EOS_\n",
      "you were right mom ! all natural cherokee hair tampons really did the trick . _EOS_\n",
      "ANSWER\n",
      "OUR: _UNK_ - -\n",
      "REAL: and when you ' re done using them _EOS_\n",
      "CONTEXT\n",
      "oho , gingers , yes . our cute little red - haired rascals . _EOS_\n",
      "i ' m sorry , but i don ' t understand . you both have dark hair and brown eyes . _EOS_\n",
      "yes , we ' ve learned that the ginger gene is recessive in both our families ' dna . actually , the odds of us having a red - haired freckled child were only one in four . and still it happened . three times . what are the odds ? _EOS_\n",
      "ANSWER\n",
      "OUR: and what about our kids ?\n",
      "REAL: a lot of people carry the ginger gene and don ' t know . _EOS_\n",
      "CONTEXT\n",
      "yes , we ' ve learned that the ginger gene is recessive in both our families ' dna . actually , the odds of us having a red - haired freckled child were only one in four . and still it happened . three times . what are the odds ? _EOS_\n",
      "a lot of people carry the ginger gene and don ' t know . _EOS_\n",
      "each one of them ' s a blessing . _EOS_\n",
      "ANSWER\n",
      "OUR: this is an important message for us .\n",
      "REAL: oh yes , each one of them ' s a blessing . _EOS_\n",
      "CONTEXT\n",
      "so nice to see _UNK_ chinese peopull _UNK_ . as you can see , we are chinese peopull ourselves . _EOS_\n",
      "_UNK_ fong ting tong . _EOS_\n",
      "ting ton _UNK_ . _EOS_\n",
      "ANSWER\n",
      "OUR: and we ' re done with our lives . we ' re all in danger .\n",
      "REAL: what are they doing ? _EOS_\n",
      "CONTEXT\n",
      "no wait . _EOS_\n",
      "come on , hurry up . _EOS_\n",
      "i can ' t run . you go ahead , i ' ll catch up with ya . _EOS_\n",
      "ANSWER\n",
      "OUR: so , uh , you ' re gonna go for a ride ?\n",
      "REAL: here davey . _EOS_\n",
      "CONTEXT\n",
      "how do we do that ? _EOS_\n",
      "we get a bus . . . and then we . . . throw eric cartman under it . _EOS_\n",
      "_EOS_\n",
      "ANSWER\n",
      "OUR: _UNK_ !\n",
      "REAL: yes ? _EOS_\n",
      "CONTEXT\n",
      "_EOS_\n",
      "yes ? _EOS_\n",
      "hi . does a vernon _UNK_ live here ? _EOS_\n",
      "ANSWER\n",
      "OUR: _UNK_ - _UNK_ .\n",
      "REAL: yes , vernon ' s around somewhere . _EOS_\n",
      "CONTEXT\n",
      "awkwaaard ! _EOS_\n",
      "and this june , funnybot shows off his range by playing every role in . . . _EOS_\n",
      "pass me the potatoes , mother . _EOS_\n",
      "ANSWER\n",
      "OUR: oh , my god .\n",
      "REAL: pass them yourself . _EOS_\n"
     ]
    }
   ],
   "source": [
    "temperature.set_value(0.5)\n",
    "for i in range(len(mother_contexts)):\n",
    "    phrases = [' '.join(map(tokens.__getitem__, mother_contexts[i][j])) for j in range(3)]\n",
    "    print 'CONTEXT'\n",
    "    for j in range(3):\n",
    "        print phrases[j]\n",
    "    print 'ANSWER'\n",
    "    print 'OUR:', generator.reply(phrases, 1266)\n",
    "    print 'REAL:', ' '.join(map(tokens.__getitem__, data_rows[mother_phrases_idxs[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTEXT\n",
      "_UNK_ . could you have them turn up the light s a little , please ? [ the waiter goes away ] _EOS_\n",
      "oh , look at it , gerald . all the new families moving in . [ a new mexican restaurant - _UNK_ _UNK_ - is having its grand opening across the street ] our little town is all grown up . _EOS_\n",
      "where ' s that other taco plate ? we need it now . _EOS_\n",
      "ANSWER\n",
      "OUR: hey , you can ' t just leave the kids alone . it ' s the last time i came\n",
      "REAL i ' m a little overwhelmed . _EOS_\n",
      "CONTEXT\n",
      "i ' m a little overwhelmed . _EOS_\n",
      "i know . but we ' ve put everything into moving here and starting this business , and we have to be impressive . [ walks up to the boy and gets down on one knee ] _UNK_ , you must help your mama however you can . we ' re not going back to that miserable place ! _EOS_\n",
      "i don ' t wanna go back either . _EOS_\n",
      "ANSWER\n",
      "OUR: what ? clyde ? clyde ? clyde ? clyde ? timmy ! you have to come out of the closet\n",
      "REAL okay , done . _EOS_\n",
      "CONTEXT\n",
      "i don ' t wanna go back either . _EOS_\n",
      "okay , done . _EOS_\n",
      "great ! [ rises and goes for the plates ] we really have to impress this customer . he ' s the local food critic . [ rushes the plates out to the dining area ] _EOS_\n",
      "ANSWER\n",
      "OUR: what ' s ridiculous about him ? [ turns around ] why would somebody die ? !\n",
      "REAL another one ? _EOS_\n",
      "CONTEXT\n",
      "get out ! _EOS_\n",
      "you son of a bitch ! rip it down ! get out ! _EOS_\n",
      "you lied to me , mother . you said it was the _EOS_\n",
      "ANSWER\n",
      "OUR: kids , you know what , uh ? i ' m gonna go get the child you sneak in to\n",
      "REAL _UNK_ , yes , but - _EOS_\n",
      "CONTEXT\n",
      "_EOS_\n",
      "yea ! / hooray ! / summer ! _EOS_\n",
      "_EOS_\n",
      "ANSWER\n",
      "OUR: how am i supposed to be the new neighbors that moved by city by two months ago ?\n",
      "REAL oh golly , kevin , honey . _EOS_\n",
      "CONTEXT\n",
      "you ' re not gonna make my daughter part of your cult ! _EOS_\n",
      "your daughter could die tomorrow , and then what ? ! _EOS_\n",
      "you ' re just a stupid little fat kid who thinks that - - _EOS_\n",
      "ANSWER\n",
      "OUR: fine ! you ' ll do it , eric !\n",
      "REAL stephen ? _EOS_\n",
      "CONTEXT\n",
      "the lord has spoken again - uh ! o , forgive us , lord , for our sins - uh ! _EOS_\n",
      "forgive us , lord . _EOS_\n",
      "let us pray . _EOS_\n",
      "ANSWER\n",
      "OUR: here he is , inspector butters here .\n",
      "REAL stephen ? _EOS_\n",
      "CONTEXT\n",
      "huh , where are we goin ' ? _EOS_\n",
      "we ' re gon ' tuh take cartman ' s kidney . _EOS_\n",
      "_EOS_\n",
      "ANSWER\n",
      "OUR: of course he is . the new ms . choksondik ed department records on the -\n",
      "REAL _EOS_\n",
      "CONTEXT\n",
      "_EOS_\n",
      "_EOS_\n",
      "mom . . . do you ever have those heavy flow days ? _EOS_\n",
      "ANSWER\n",
      "OUR: mom , i need to talk to you .\n",
      "REAL oh absolutely sweetheart , everybody does . _EOS_\n",
      "CONTEXT\n",
      "mom . . . do you ever have those heavy flow days ? _EOS_\n",
      "oh absolutely sweetheart , everybody does . _EOS_\n",
      "mom , remember the movie _EOS_\n",
      "ANSWER\n",
      "OUR: you should at this , you stand by . you must go to the bathroom , for instance . [\n",
      "REAL oh honey what you need is a more absorbent tampon . _EOS_\n",
      "CONTEXT\n",
      "mom , remember the movie _EOS_\n",
      "oh honey what you need is a more absorbent tampon . _EOS_\n",
      "like what ? _EOS_\n",
      "ANSWER\n",
      "OUR: mom , do you know what it is ?\n",
      "REAL well , what ' s the most absorbent thing in the world ? _EOS_\n",
      "CONTEXT\n",
      "like what ? _EOS_\n",
      "well , what ' s the most absorbent thing in the world ? _EOS_\n",
      "well . . . cherokee hair i guess . _EOS_\n",
      "ANSWER\n",
      "OUR: then it was for the sex club .\n",
      "REAL _EOS_\n",
      "CONTEXT\n",
      "_EOS_\n",
      "_EOS_\n",
      "you were right mom ! all natural cherokee hair tampons really did the trick . _EOS_\n",
      "ANSWER\n",
      "OUR: if you ' re gonna get kenny or your friend to go for somethin ' real quick , then you\n",
      "REAL and when you ' re done using them _EOS_\n",
      "CONTEXT\n",
      "oho , gingers , yes . our cute little red - haired rascals . _EOS_\n",
      "i ' m sorry , but i don ' t understand . you both have dark hair and brown eyes . _EOS_\n",
      "yes , we ' ve learned that the ginger gene is recessive in both our families ' dna . actually , the odds of us having a red - haired freckled child were only one in four . and still it happened . three times . what are the odds ? _EOS_\n",
      "ANSWER\n",
      "OUR: now , listen ! we have muhammad gone under and we are going to give muhammad to them . it\n",
      "REAL a lot of people carry the ginger gene and don ' t know . _EOS_\n",
      "CONTEXT\n",
      "yes , we ' ve learned that the ginger gene is recessive in both our families ' dna . actually , the odds of us having a red - haired freckled child were only one in four . and still it happened . three times . what are the odds ? _EOS_\n",
      "a lot of people carry the ginger gene and don ' t know . _EOS_\n",
      "each one of them ' s a blessing . _EOS_\n",
      "ANSWER\n",
      "OUR: there ' s nothing more we can do , kyle . if we don ' t go to milk cows\n",
      "REAL oh yes , each one of them ' s a blessing . _EOS_\n",
      "CONTEXT\n",
      "so nice to see _UNK_ chinese peopull _UNK_ . as you can see , we are chinese peopull ourselves . _EOS_\n",
      "_UNK_ fong ting tong . _EOS_\n",
      "ting ton _UNK_ . _EOS_\n",
      "ANSWER\n",
      "OUR: see the hot one , does the ?\n",
      "REAL what are they doing ? _EOS_\n",
      "CONTEXT\n",
      "no wait . _EOS_\n",
      "come on , hurry up . _EOS_\n",
      "i can ' t run . you go ahead , i ' ll catch up with ya . _EOS_\n",
      "ANSWER\n",
      "OUR: now , come on ! this is stupid ! get out of here !\n",
      "REAL here davey . _EOS_\n",
      "CONTEXT\n",
      "how do we do that ? _EOS_\n",
      "we get a bus . . . and then we . . . throw eric cartman under it . _EOS_\n",
      "_EOS_\n",
      "ANSWER\n",
      "OUR: kids eat well in the future .\n",
      "REAL yes ? _EOS_\n",
      "CONTEXT\n",
      "_EOS_\n",
      "yes ? _EOS_\n",
      "hi . does a vernon _UNK_ live here ? _EOS_\n",
      "ANSWER\n",
      "OUR: what is your name ?\n",
      "REAL yes , vernon ' s around somewhere . _EOS_\n",
      "CONTEXT\n",
      "awkwaaard ! _EOS_\n",
      "and this june , funnybot shows off his range by playing every role in . . . _EOS_\n",
      "pass me the potatoes , mother . _EOS_\n",
      "ANSWER\n",
      "OUR: that ' s it , kenny ! you have to leave now !\n",
      "REAL pass them yourself . _EOS_\n"
     ]
    }
   ],
   "source": [
    "temperature.set_value(0.5)\n",
    "for i in range(len(mother_contexts)):\n",
    "    phrases = [' '.join(map(tokens.__getitem__, mother_contexts[i][j])) for j in range(3)]\n",
    "    print 'CONTEXT'\n",
    "    for j in range(3):\n",
    "        print phrases[j]\n",
    "    print 'ANSWER'\n",
    "    print 'OUR:', generator.reply(phrases, 1266)\n",
    "    print 'REAL', ' '.join(map(tokens.__getitem__, data_rows[mother_phrases_idxs[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temperature.set_value(0.5)\n",
    "for i in range(len(mother_contexts)):\n",
    "    phrases = [' '.join(map(tokens.__getitem__, mother_contexts[i][j])) for j in range(3)]\n",
    "    print 'CONTEXT'\n",
    "    for j in range(3):\n",
    "        print phrases[j]\n",
    "    print 'ANSWER'\n",
    "    print 'OUR:', generator.reply(phrases, 1266)\n",
    "    print 'REAL', ' '.join(map(tokens.__getitem__, data_rows[mother_phrases_idxs[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14726, 20, 18026, 501, 17596, 21478, 19, 0],\n",
       "       [21005, 11, 9040, 19, 0], [1648, 21063, 16, 0],\n",
       "       [1, 11, 33406, 11, 4475, 10, 0],\n",
       "       [20971, 12744, 11, 16499, 11, 14299, 19, 0], [28501, 16, 0],\n",
       "       [28501, 16, 0], [0], [20971, 645, 29290, 11, 10417, 8960, 19, 0],\n",
       "       [20971, 14299, 32704, 33467, 20205, 15711, 501, 19655, 651, 29541, 19, 0],\n",
       "       [32627, 11, 32704, 20, 25698, 29957, 19723, 651, 30032, 15024, 29957, 33159, 16, 0],\n",
       "       [0], [1528, 32736, 33467, 20, 24193, 9040, 31664, 29972, 0],\n",
       "       [501, 17818, 20924, 22094, 4926, 29957, 12546, 12374, 1528, 9026, 20, 29407, 16710, 19, 0],\n",
       "       [20971, 33406, 11, 9518, 21063, 20924, 29972, 20, 25698, 501, 3492, 19, 0],\n",
       "       [32704, 1885, 30015, 8981, 16, 0], [13955, 7782, 19, 0],\n",
       "       [33406, 16, 0], [33406, 11, 31917, 20, 25698, 1970, 27800, 19, 0],\n",
       "       [21814, 29972, 33481, 19, 0]], dtype=object)"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rows[mother_phrases_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i ' m a little overwhelmed . _EOS_\n",
      "okay , done . _EOS_\n",
      "another one ? _EOS_\n",
      "_UNK_ , yes , but - _EOS_\n",
      "oh golly , kevin , honey . _EOS_\n",
      "stephen ? _EOS_\n",
      "stephen ? _EOS_\n",
      "_EOS_\n",
      "oh absolutely sweetheart , everybody does . _EOS_\n",
      "oh honey what you need is a more absorbent tampon . _EOS_\n",
      "well , what ' s the most absorbent thing in the world ? _EOS_\n",
      "_EOS_\n",
      "and when you ' re done using them _EOS_\n",
      "a lot of people carry the ginger gene and don ' t know . _EOS_\n",
      "oh yes , each one of them ' s a blessing . _EOS_\n",
      "what are they doing ? _EOS_\n",
      "here davey . _EOS_\n",
      "yes ? _EOS_\n",
      "yes , vernon ' s around somewhere . _EOS_\n",
      "pass them yourself . _EOS_\n"
     ]
    }
   ],
   "source": [
    "for row in data_rows[mother_phrases_idxs]:\n",
    "    print ' '.join(map(tokens.__getitem__, row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
